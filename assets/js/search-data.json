{
  
    
        "post0": {
            "title": "Device Code Flow in Azure AD using Python's requests module and MSAL",
            "content": "Repo: https://github.com/ankitbko/python-requests-msal. . If you have created any Python application that required integration with Azure Active Directory you would have most likely used an excellent library from Azure AD team called MSAL for Python. However there is no easy way to integrate it with requests library which is a very popular HTTP library for Python. . I have written a sample application and reusable class to integrate Python requests library with MSAL to get AD token using Device Code Flow. Device Code Flow is typically used in a client side applications such as CLI. Therefore I have also implemented a TokenCache serialization/deserialization logic to persist the token in file system. This is similar to how Azure CLI persists the token in ~/.azure folder. . Feel free to copy and use auth.py and rest_service.py in your own project. The files depends upon following PyPI - . msal | requests | . Initialize DeviceCodeFlowTokenAuth by passing auth_config object to it. auth_config must have . client_id: Azure AD Application ID | authority: Azure AD authority | scope: Scope to send while requesting for token | . Pass the initialized DeviceCodeFlowTokenAuth to RestService. RestService will use it to set Authorization token before sending request. . In addition to above, change _DEFAULT_TOKEN_CACHE_DIR in DeviceCodeFlowTokenAuth to any folder of your choosing where you would like the token to be chached. More details below. . How does it work . DeviceCodeFlowTokenAuth accepts configuration which contains client_id, authority and scope to get access token. It first checks if a valid access token or refresh token is present in cache. The in-memory cache is serialized and stored as a file named token in a folder specified by _DEFAULT_TOKEN_CACHE_DIR variable in home folder (default ~/.myapp). . The code will try to read the token from the folder above and populate its TokenCache. If valid access token exist it will use it. Otherwise if a valid refresh token exists it will use it to get a fresh access token and save it in the cache. If neither of them are valid it will initiate device code flow to fetch fresh tokens. The device code flow will print the code generated to console. .",
            "url": "https://ankitbko.github.io/blog/2020/08/device-code-flow-using-msal-in-python/",
            "relUrl": "/2020/08/device-code-flow-using-msal-in-python/",
            "date": " • Aug 17, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Modernizing a legacy application",
            "content": "This blog was co-authored by Srikantan Sankaran. You can follow him on twitter and on his blog. . There are huge number of applications still running on on-premise data centers that were written more than a decade ago. With emergence of cloud and the advantages it brings, there is a demand to migrate these applications to cloud and in process modernize them to utilize features that cloud provides in order to optimize performance and cost. This is more prevalent in line of business (LOB) applications that every business requires to function (and large business have 100s of them). These applications were written ages ago using latest technology available at that time but are now obsolete. . Recently I had an opportunity to work on modernizing a legacy LOB application comprising of ASP.NET WebForms, WCF service and Entity Framework. In this post, I’ll share my learnings and present an approach to tackle such kind of migrations. For this post I will only focus on migrating the APIs and not the UI as approach there is completely different. . Strategies for moving to cloud . There are two approaches to moving to cloud - . Lift and Shift : Lift and Shift as name suggests means running as-is application in cloud either as PaaS or IaaS service. Although this is perfectly viable solution given that your cloud provider supports running these existing technologies, you do miss out on cloud features and is typically not the most optimized way of running your application on cloud. There are numerous article and documentations on which technologies are supported by different cloud service so we will leave it at that. | Modernizing: The second approach of modernizing is much more interesting. Here we would like to refactor the application using new technologies to better utilize the cloud infrastructure. But in process we want to avoid rewriting the application from scratch and reuse the existing code as much as possible. | . Approach for modernizing legacy application . Lets be clear of our vision - Modernize the application while reusing the existing code and incorporate the current software engineering best practices. . I found that migrating the application in a incremental manner worked best. This means we take a single use case from the application, investigate, migrate and test it and repeat the process. If you are migrating a web API which does bunch of things target to migrate single use case end to end first as this will allow you to setup the infrastructure around the new application and have better understanding of the complexity which will eventually help in estimating the effort required to migrate other use cases. This also have additional benefit of having an option of splitting the application per use case into serverless platform like Azure Functions or AWS Lambda. There are two phases involved in migration of single use case - . Investigation phase (Top-Down): Start out with the outermost layer of the application and drill down into inner layers to understand the flow. Most of the legacy application follow typical N layer design i.e view/service layer, business logic layer followed by data access layer. In this scenario outermost layer is view* or service layer and innermost is data access/repository layer. Our objective here is to have the understanding of how the application is structured and find out all the dependencies of a function. For example if there is a function Foo in outer layer, we need to find is what all dependencies/functions that needs to be migrated before we can migrate Foo. In this way we end up creating a mental map or a tree of dependencies of every function. . | Execution phase (Bottom-Up): Once we have the dependency tree mapped out, we start migrating the innermost dependency (leaf node in dependency tree) and work our way upwards. Actual migration steps will depend upon what is the target technology and the extent of rework required to make the existing code work. . | I will showcase the approach by modernizing a legacy WCF .NET application which I found in code project and deploying it into Azure. However the approach explained above can be used for any kind of application and any cloud provider. The sample application is part of an article by Wusheng Hu written in 2012. The article is very well written and showcases the architecture and technologies prevalent almost a decade ago and I recommend you to give it a read. The source code for this is here . Northwind Application . Our legacy application resides in legacy folder of the repo. The application uses Northwind database to perform basic CRUD operations. I have cleaned it up and removed unnecessary projects. To keep it simple we will only be focusing on the service layer and not the client. The service layer contains a WCF service and a data access layer which uses Entity Framework 4 to connect to a SQL Server. The application targets .NET Framework 4.0. . When we think of final desirable state in Azure there are multiple options available to us. We can either deploy it in App Service, Azure Kubernetes Service or even develop it as Azure Functions app. Therefore we would like the final version to be able to support any of these and not be coupled with a single cloud service. Thus we will migrate the class libraries to .NET Standard and WCF to ASP.NET Core. Since .NET Core is cross platform we get flexibility of dockerizing our application and deploying it in any cloud service that we wish. Having said that, Azure Functions would require few other changes but overall our code would be cloud-ready. For this blog we will keep it simple and just develop it as ASP.NET Core service. . Setup . I am using Visual Studio 2019 16.4.4 version for this migration. Run the Northwind.sql script and create the database in SQL Server. You can use SQL Server express for this. Then edit the Web.config file in GH.Northwind.Business.Host project and edit the connection string as required. . Thats it, try starting the Host project and it should launch the WCF service. Navigate to /northwindSvr.svc/GetCustomers and you should get back a JSON response. . We will be targeting .NET Core 3.0 so download it from here. . .NET Portability Analyzer . .NET Portability Analyzer is a great tool to find potential issues we will face in migrating our application to .NET Core. The tool provides detailed report on how ready is our application to be ported to different runtime. The tool is also available as Visual Studio Extension which we will use to analyze our solution so have it installed. . Configure the tool by right clicking on solution and selecting Portability Analyzer Settings. Under Target Platform only tick .NET Core + Platform Extensions 3.1 and .NET Standard 2.1. Select “Excel” under Output formats to generate excel report. . . Right-click on the solution and select Analyze Assembly Portability. The generated excel report contains 3 sheet - Portability Summary, Details and Missing Assemblies. Portability Summary gives portability percentage for each assembly which gives us rough idea on how much effort would be required to port each assembly. . . Going into Details tab we see what type used in current application is not supported. You would notice most of the unsupported type are either from System.Data or System.ServiceModel namespace. System.Data namespace corresponds to EntityFramework 4 while System.ServiceModel is used by WCF. With EntityFramework there has been significant changes that we will get to shortly. Meanwhile we would be completely dropping the WCF and its associated types. . . Investigation Phase . Here we will broaden our understanding of the the GetCustomer use case and find out all the dependencies of this flow. Delving into the code we see that WCF contracts are defined in GH.Northwind.Business.Interfaces and implemented in GH.Northwind.Business class library. Meanwhile GH.Northwind.Business.Host acts as our hosting project. A single ASP.NET Core project may replace these three projects. . NorthwindSvr.cs in GH.Northwind.Business contains the service implementation. Its static constructor immediately catches our attention which sets up a Service Locater for dependency injection. It also does some AutoMapper configuration. . We are interested in public List&lt;CustomerDto&gt; GetCustomers() method which returns list of CustomerDto. This method calls a static method PersistSvr.GetAll and maps the result using AutoMapper. Going into aforementioned method we see it resolves the type IPersistence&lt;T&gt; from the Service Locater and calls its GetAll method. Looking at the registration we find there is a CustomerPrst class which derives from PersistenceBase&lt;T&gt; base class which hosts our GetAll method. This seems like an implementation of a repository pattern. PersistenceBase&lt;T&gt; contains a static property of type DbContext which is used for database operation. The context itself is created in WCF contract static constructor using connection string read from Web.config. . This essentially completes our investigation phase and we now have understanding of the application. The flow is NorthwindSvr -&gt; PersistSvr -&gt; CustomerPrst -&gt; PersistenceBase. We need to start migrating functions in reverse order. . Execution Phase . The code for modernized application is in “modern” folder. . Migrating Entity Framework . The current project uses Entity Framework 4 which does not support .NET Standard. We have two options - either go with EF Core or EF6.4. What we would want to use will depend primarily upon the features that we need. EF Docs contains helpful feature comparison between EF Core and EF6.4. In our scenario both of them would work so we would go ahead with EF Core which has slightly better tooling support at the moment. . We start with creating a new .NET Standard class project named Modern.NW.Persistence and target .NET Standard 2.0. EF Core does not support database first approach and .edmx. EricEJ’s EF Core Power Tools is useful tool to scaffold the context and entities. Once installed, right-click on the project -&gt; EF Core Power Tools -&gt; Reverse Engineer. Select the database and make sure “Use EF Core 3.x” checkbox is ticked. Select same tables that are in our edmx file. In the next screen you can change the context name and folder location of generated classes. Select the options as required and click “OK”. . . We want to maintain the existing design and structure as much as possible so we keep the repository pattern implementation same. Based on your project you may decide to change this implementation or even redesign this layer. We start by copy pasting the IPersistence.cs and PersistenceBase.cs from old solution to new solution. We no longer need BusinessEntityBase that derives from IValidatableObject as validation should happen at a layer above and not in the repository. In PersistenceBase we convert static properties to instance properties and inject them through the constructor. This means even the DbContext is injected. We will manage the lifetime of the DbContext from outer layer and set it to per request as recommended by EF. In .NET Core we want to use dependency injection at all possible place. Next port the CustomerPrst class which derives from PersistenceBase and constructor inject the parameters required by its base class. . One of the major changes that is present is .NET Framework 4.5+ is the Task Parallel Library. TPL allows us to asynchronously execute the code and wait for it without blocking the thread. This means our request thread will not be blocked for the duration of database call and will be available to serve other requests. Entity Framework exposes an async version of most of its methods which must be awaited by the caller. If there exist an async alternative of a method then use it. Go over the repository and replace the EF calls with it’s async counterpart. This will have overarching changes as all such methods must be changed to async and return Task. This change will bubble up across the application as signature of all the methods in the method chain will need to be changed. Even though this change will be big, it will result in massive performance gain by our application. . This completes our data access layer migration. . Migrating WCF . We start by creating a ASP.NET Core 3.0 Web API project and referencing our persistence project. So as to not make this blog post about ASP.NET Core 3 tutorial, I will skip the basics and assume you are already familiar with it. Everything that you would need to know is available in official documentation. Install AutoMapper and AutoMapper.Extensions.Microsoft.DependencyInjection nuget packages . If we were to mimic the WCF service we will end up having a single controller containing all the actions. Instead we may want to refactor and modularize the API and create a proper RESTful APIs. So lets start with creating a Customer controller. We no longer need PersistSvr class to resolve the dependency from service locater. We implement inversion of control through dependency injection and ASP.NET Core comes with DI inbuilt. So we inject the IPersistence in our controller through constructor to use it to get the customers. . private readonly IPersistence&lt;Customer&gt; repository; private readonly IMapper mapper; private readonly ILogger&lt;CustomerController&gt; logger; public CustomerController( IPersistence&lt;Customer&gt; repository, IMapper mapper, ILogger&lt;CustomerController&gt; logger) { this.repository = repository; this.mapper = mapper; this.logger = logger; } . We will need to migrate the data contracts from existing application which were used return the result from WCF. Since they are just POCO classes just copy pasting them would work. They are present in DTO folder in GH.Northwind.Business.Interfaces. We move them to a new folder called Models in our ASP.NET Core Web API project. Remove all the DataContract and DataMember attributes as we no longer need them. . We create a Get action method that returns Task&lt;ActionResult&lt;IEnumerable&lt;CustomerDto&gt;&gt;&gt; and call our repository from there. . [HttpGet] public async Task&lt;ActionResult&lt;IEnumerable&lt;CustomerDto&gt;&gt;&gt; Get() { try { var customers = await this.repository.GetAll().ToListAsync(); return Ok(customers.Select(customer =&gt; mapper.Map&lt;CustomerDto&gt;(customer))); } catch (Exception ex) { this.logger.LogError(ex, ex.Message); return StatusCode(500); } } . Its time to setup the DI container. Open Startup.cs and configure DbContext, container and AutoMapper in ConfigureServices method. . public void ConfigureServices(IServiceCollection services) { services.AddControllers(); services.AddDbContext&lt;NorthwindContext&gt;(options =&gt; options.UseSqlServer(Configuration.GetConnectionString(&quot;NorthwindEntities&quot;))); services.AddScoped&lt;IPersistence&lt;Customer&gt;, CustomerPrst&gt;(); services.AddAutoMapper(config =&gt; { config.CreateMap&lt;Customer, CustomerDto&gt;(); }, typeof(Startup)); } . We read the connection string from User Secrets. It is bad practice to have secrets in appsettings.json. Instead a secret management service like Azure Key Vault should be used. For deployment environment you could use Secret Manager tool which comes with dotnetcore. Right click on the WebApi project and select “Manage User Secret”. Create a ConnectionStrings json object and have the NorthwindEntities connection string over there. . { &quot;ConnectionStrings&quot;: { &quot;NorthwindEntities&quot;: &quot;data source=(localdb) MSSQLLocalDB;initial catalog=Northwind;integrated security=True;multipleactiveresultsets=True;App=EntityFramework&quot; } } . Run the API project and navigate to /api/customer and you should get the response back. You could add Application Insights for monitoring by right clicking on the API project and Add -&gt; Application Insights Telemetry. This would enable the logs to flow into application insights without any additional code changes. . It is time to migrate any test cases for this use case. The approach for test case migration will be similar. Once migrated ensure all the test cases pass and the output from the legacy system and the modernized application match each other. . We have successfully migrated a single use case from our legacy application into ASP.NET Core. This project is ready to be deployed into variety of cloud services or dockerized and become available as a container. It is scalable and cloud ready. . Modernizing Database . Although this post was meant to focus on the application side, I feel that I wouldn’t be doing you justice if I don’t talk about database migration also. Database migration in itself is a huge topic and a candidate for its own blog so here I will only touch upon few aspects of it. . Cloud provides us with wide variety of databases to choose from. Usually legacy application has some RDBMS as the database and today’s cloud provider provides most of them as PaaS service. Migration strategy of database depends upon individual project needs. You may choose to move the database to one of the PaaS offering from the cloud or you may choose to re-engineer into NoSQL. . In my project we moved an on-premise SQL Server to Azure SQL Server and I will briefly mention about two aspect of the migration - database itself and SQL Server Jobs. . Migration of database . Migration of the SQL Server database to Azure SQL Database was done with the help of Database Migration Assistant tool. The tool generates assessment reports that provide recommendations to guide you through the changes required prior to performing a migration. The report will also contain what features used in your current database is no longer supported at the target environment. This will help you to understand the feature parity between source and target and assist you to make informed decision about the migration. It also has ability to perform the migration itself. . Migration of SQL Jobs . Here again there are multiple strategies that can be adopted. I used following two services for our use cases - . Azure Elastic Jobs is a job scheduling service that execute custom jobs on one or many Azure SQL Databases. Elastic Database Jobs provide the ability to run one or more T-SQL scripts in parallel, across a large number of databases, on a schedule or on-demand. This service is in preview as of writing this blog and so there are few limitations. It does not yet integrates with Azure Monitor so monitoring and telemetry are difficult to get to. So if a job fails there is no out of the box feature to trigger something else. The job history are stored in a table which needs to be monitored for such kind of failures. . | Azure Data Factory is the cloud-based ETL and data integration service. ADF can be used to create workflows using Stored Procedures and can also be integrated with Azure Logic Apps which provides a lot of flexibility. You can also send any HTTP request from ADF to trigger services or perform other operations. . | . Conclusion . Modernization of legacy application is inevitable. Sooner or later they will be replaced by newer technology. As technology is growing at incredible pace, having a migration strategy is important. I tried to put forward learnings from my own experience and presented a generic approach to modernize any application. If you have any questions or suggestions leave it below. .",
            "url": "https://ankitbko.github.io/blog/2020/02/migrating-legacy-application-to-cloud/",
            "relUrl": "/2020/02/migrating-legacy-application-to-cloud/",
            "date": " • Feb 17, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Electron-Forge + React + TypeScript = Awesome!",
            "content": "Recently I wanted start a new project on Electron and chose React to design UI. Having no prior experience in developing Electron App, I sat down to do some research. The Electron Documentation states two ways to start an electron project, Boilerplate or CLI, with a slight lean towards CLI. . The documentation mentions React support with both the processes through Electron-Forge(CLI) or electron-react-boilerplate. Electron-Forge is similar to create-react-app (CRA) in terms of scaffolding the base solution and getting a ready-to-run application setup correctly. Having had an excellent experience with CRA before, I chose to start my project using electron-forge. . Although Electron docs mentions electron-forge has ready to use templates for React, at the time of writing electron-forge documentation does not list any React template nor any guide on how to setup React or TypeScript. Moreover there was surprisingly little information available on the web regarding this. Luckily I found excellent blog by Ju Hae Lee that helped me with setting up TypeScript+React electron App using Babel. Babel is a great package in itself and I would recommend everyone to go through this excellent article on how Babel and TypeScript works together. To summarize, the way Babel works is by removing TypeScript and converting TypeScript into regular Javascript. This increases compile speed dramatically (one major complain from TypeScript) at the cost forgoing type checking at build time. There are workarounds (like type-checking during test) that are described in more details in the article above and I would recommend everyone to read it. You may or may not like this approach depending upon your project and team configuration. I, myself, wanted to maintain TypeScript’s type checking during build time and so decided to not configure babel. If you want to use Babel I would recommend you read Ju Lee’s blog. . Getting started with Electron-Forge . There are two ways to setup electron-forge - vanilla installation or using a template. We will setup using Webpack template (the only available template at the time of writing). . npx create-electron-app my-app --template=webpack . Setup TypeScript . Install typescript . Next we are going to setup TypeScript. Run the following script - . yarn add --dev typescript ts-loader fork-ts-checker-webpack-plugin . We use ts-loader as loader for webpack and fork-ts-checker-webpack-plugin for faster builds. fork-ts-checker-webpack-plugin will run the typescript type checker in a separate process significantly increasing build time. . Create tsconfig.json . Since we are not using Babel, we will need to create config file for TypeScript. Create a tsconfig.json file in the root folder with following content. . { &quot;compilerOptions&quot;: { &quot;target&quot;: &quot;es5&quot;, &quot;lib&quot;: [&quot;dom&quot;, &quot;dom.iterable&quot;, &quot;esnext&quot;], &quot;allowJs&quot;: true, &quot;skipLibCheck&quot;: true, &quot;esModuleInterop&quot;: true, &quot;allowSyntheticDefaultImports&quot;: true, &quot;strict&quot;: true, &quot;forceConsistentCasingInFileNames&quot;: true, &quot;module&quot;: &quot;esnext&quot;, &quot;moduleResolution&quot;: &quot;node&quot;, &quot;resolveJsonModule&quot;: true, &quot;isolatedModules&quot;: true, &quot;noEmit&quot;: true, &quot;jsx&quot;: &quot;react&quot; }, &quot;include&quot;: [&quot;src&quot;] } . Webpack changes . Next we need to modify webpack configurations to load TypeScript files. . Add the following to webpack.rules.js | . { test: / .tsx?$/, exclude: /(node_modules|.webpack)/, loaders: [{ loader: &#39;ts-loader&#39;, options: { transpileOnly: true } }] } . Create a new file called webpack.plugins.js in the root folder and put the following content. Note that I have passed async: false as an option to fork-ts-checker-webpack-plugin. This will fail the build process if there is any type error. In case this slows down the build performance you can change it to async: true. | . const ForkTsCheckerWebpackPlugin = require(&#39;fork-ts-checker-webpack-plugin&#39;); module.exports = [ new ForkTsCheckerWebpackPlugin({ async: false }) ]; . Import this newly created plugin in the webpack.renderer.config.js. | . const rules = require(&#39;./webpack.rules&#39;); const plugins = require(&#39;./webpack.plugins&#39;); rules.push({ test: / .css$/, use: [{ loader: &#39;style-loader&#39; }, { loader: &#39;css-loader&#39; }] }); module.exports = { // Put your normal webpack config below here module: { rules }, plugins: plugins }; . Setup React . Install react using following script or by modifying package.json | . yarn add react react-dom @types/react @types/react-dom . Next we will create App.tsx file under src folder which will serve as entrypoint to renderer process. | . import * as React from &#39;react&#39;; import * as ReactDOM from &#39;react-dom&#39;; ReactDOM.render(&lt;div&gt;hello world from React! &lt;/div&gt;, document.getElementById(&#39;root&#39;)); . Since we don’t have root element in our HTML, modify the index.html accordingly. . &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot; /&gt; &lt;title&gt;Hello World!&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=&quot;root&quot;&gt;&lt;/div&gt; &lt;/body&gt; &lt;/html&gt; . Next change the entrypoint under the forge field for renderer in package.json to point to our app.tsx file. | . { ///... other stuffs &quot;config&quot;: { &quot;forge&quot;: { ///... other stuffs &quot;plugins&quot;: [ [ &quot;@electron-forge/plugin-webpack&quot;, { &quot;mainConfig&quot;: &quot;./webpack.main.config.js&quot;, &quot;renderer&quot;: { &quot;config&quot;: &quot;./webpack.renderer.config.js&quot;, &quot;entryPoints&quot;: [ { &quot;html&quot;: &quot;./src/index.html&quot;, &quot;js&quot;: &quot;./src/app.tsx&quot;, &quot;name&quot;: &quot;main_window&quot; } ] } } ] ] } } } . Now run the application using yarn start and React should render correctly. . Optional - setup TypeScript for Main process . We only setup TypeScript in renderer as that is most likely place where usually development happens. However if you want to use TypeScript for developing main process you will need to make some additional changes . Main.js to Main.ts . First rename Main.js to Main.ts. Then replace the content in the file with the one below | . import { app, BrowserWindow } from &#39;electron&#39;; declare var MAIN_WINDOW_WEBPACK_ENTRY: any; // Handle creating/removing shortcuts on Windows when installing/uninstalling. if (require(&#39;electron-squirrel-startup&#39;)) { // eslint-disable-line global-require app.quit(); } // Keep a global reference of the window object, if you don&#39;t, the window will // be closed automatically when the JavaScript object is garbage collected. let mainWindow: any; const createWindow = () =&gt; { // Create the browser window. mainWindow = new BrowserWindow({ width: 800, height: 600 }); // and load the index.html of the app. mainWindow.loadURL(MAIN_WINDOW_WEBPACK_ENTRY); // Open the DevTools. mainWindow.webContents.openDevTools(); // Emitted when the window is closed. mainWindow.on(&#39;closed&#39;, () =&gt; { // Dereference the window object, usually you would store windows // in an array if your app supports multi windows, this is the time // when you should delete the corresponding element. mainWindow = null; }); }; // This method will be called when Electron has finished // initialization and is ready to create browser windows. // Some APIs can only be used after this event occurs. app.on(&#39;ready&#39;, createWindow); // Quit when all windows are closed. app.on(&#39;window-all-closed&#39;, () =&gt; { // On OS X it is common for applications and their menu bar // to stay active until the user quits explicitly with Cmd + Q if (process.platform !== &#39;darwin&#39;) { app.quit(); } }); app.on(&#39;activate&#39;, () =&gt; { // On OS X it&#39;s common to re-create a window in the app when the // dock icon is clicked and there are no other windows open. if (mainWindow === null) { createWindow(); } }); // In this file you can include the rest of your app&#39;s specific main process // code. You can also put them in separate files and import them here. . We have only changed 3 lines of code. First is to replace require statement with import statement. Then declare a global variable MAIN_WINDOW_WEBPACK_ENTRY as it will be initialized by webpack and contain URL for our HTML. The last step is to fix build error by explicitly setting type of variable mainWindow to any. . Lastly change the webpack.main.config.js to include plugin and modify the entrypoint to main.ts. | . const plugins = require(&#39;./webpack.plugins&#39;); module.exports = { /** * This is the main entry point for your application, it&#39;s the first file * that runs in the main process. */ entry: &#39;./src/main.ts&#39;, // Put your normal webpack config below here module: { rules: require(&#39;./webpack.rules&#39;) }, plugins: plugins }; . Thats all that is needed to get started with Electron-Forge and React + Typescript. . UPDATE Many people are facing issue while importing other files. This is because of missing extensions configuration in webpack. In both webpack.renderer.config.js and webpack.main.config.js include below configuration - . resolve: { extensions: [&#39;.js&#39;, &#39;.ts&#39;, &#39;.jsx&#39;, &#39;.tsx&#39;, &#39;.css&#39;] }, . Thanks for a lot of people in the comments below on bringing this to my attention. .",
            "url": "https://ankitbko.github.io/blog/2019/08/electron-forge-with-react-and-typescript/",
            "relUrl": "/2019/08/electron-forge-with-react-and-typescript/",
            "date": " • Aug 26, 2019"
        }
        
    
  
    
        ,"post3": {
            "title": "Transferring chat to a human agent using Microsoft Bot Framework",
            "content": "Source Code: Human Handover Bot . One of the frequent questions which I am asked is how to transfer chat to a human from the bot. It is especially necessary if your bot is in space of customer service. Chat bots are not meant to (or atleast, not mature enough currently) to completely replace humans. Many a times chat bot will fail to answer satisfactorily or user would just want to talk to a human from the start. When this happens the chatbot should transfer the chats to a human agent or a customer care representative. But how can we achieve that? . In this article, I will give an overview on how we can integrate a live chat into our bot using Microsoft Bot Framework. Microsoft Bot Framework is highly extensible and lets us do this easily. The source code is available over at my github repo. . High Level Overview . Our bot would be central piece to whole solution. Apart from performing all it’s normal functionality, our bot would also act as a proxy between user and agent. So, what is required to create this feature and who are the actors involved? . Actors Involved . Bot: Well, we have our bot (duh!). | Users: Users are our customers who would be using our bot. Our users can be on any channel which are supported by Bot Framework. | Agent: Agents are humans who would chat with our users. Our agent will also need a chat window. For this we will use Bot Framework Web Chat as a dashboard for our agents. | . Running the bot . Let us first run the bot and see how it works. Nothing helps better in understanding than running the code and seeing it first hand. . To run the bot, follow the steps - . Create a Luis app by importing LuisModel AgentTransfer.json. The bot uses Luis to understand if user wants to talk to an agent. If you don’t want to use Luis, I have included an EchoDialog class which would also work. You will need to modify the code to start EchoDialog instead of TransferLuisDialog when message arrives (left as exercise to the reader). If you do this, go to step 3. . | Get the ModelId and SubscriptionKey of the Luis App and paste it into LuisModel attribute in TransferLuisDialog.cs. . | Run the solution by pressing F5. By default, it should start at port 3979. If not, note the port it runs on and stop debugging. . | We will use ngrok to debug the bot locally. Download and run ngrok using command ngrok.exe http --host-header=rewrite &lt;port number&gt;. Copy the Forwarding URL (https) which is genrated by ngrok. . | Register a new bot in Bot Framework Portal using URL generated by ngrok. Copy the Microsoft App Id and App Password and paste it in web.config. . | Agent Dashboard uses Direct Line as a channel. So, enable direct line and keep its Secret Key handy. . | Run the solution once again. . | To open Agent Dashboard go to http://localhost:3979/agentdashboard/index.html?s=DIRECTLINE_SECRET_KEY. Change the port number accordingly if it is not 3979. Notice the query string ?s=. Enter the Direct Line secret key as the value of the query string. . You will get the page similar to below. . . Click on Connect button to register yourself as an agent. If you get successfully registered, the heading in the page will change to show the “Connected” status. This makes the agent available for chat. . Use any other channel (skype or web chat at bot portal) to simulate a user. Currently there is only one Luis intent AgentTransfer which is triggered by typing “Connect me with customer care”. Enter it to start talking with agent. Using emulator will not work. . If you are using EchoDialog, agent transfer can be achieved by typing anything starting with letter ‘a’. Typing anything else will just echo back. . Once user has initiated the conversation with an agent, any messages user sends will be delivered to the agent (instead of being handled by bot) and vice versa. . To stop conversation with user, click on Stop Conversation with User button on agent dashboard. Click on Disconnect to remove agent from available pool. . We will see how each of these works shortly, but first let us understand some of the concepts involved in it. . Building Blocks . Let us understand what we did while running the code. We will divide the flow into logical groups - . Initiating Transfer: A user can initiate a transfer to an agent anytime. Initiation is successful if an agent is available for chat. A user can only talk to one agent at a time. Once initiated, all the messages from user will be routed to the agent instead of being handled by current Dialog. . | Agent Availability: An agent is termed available if he is not already in an exisiting conversation with a user. This effectively means that an agent can only talk to one user at a time. In other words, Agent and User have 1:1 mapping. . | Agent User Mapping: We established that an agent and a user have 1:1 mapping. Since we have to route messages to and fro, we must maintain this mapping somewhere. . | Message Routing: Message is routed by fetching the Agent User Mapping and sending the current message to it’s counterpart. For example, if a user sends a message, we fetch the agent associated with that user, and send the message text to the agent. Same applies the other way around. . | Stopping Conversation: Stopping the conversation should prevent bot from routing any further messages to and fro agent and user. This effectively means that we remove the Agent User Mapping. Stopping the conversation will also make the agent available once again. . | Disconnecting Agent: Disconnecting an agent means we remove the agent from availability pool. No further initiation can happen with this agent. . | . Solution Structure . This is a pretty lengthy explaination so I suggest you keep the solution open and follow as I explain each classes. . . The most important pieces of code which I want to highlight are . Agent folder contains everything related to agent management and routing implementation. | AgentDashboard folder contains index.html which has Web Chat control embedded. We will use this page for agent to chat. How it works we will see later. | Scorable folder contains two IScorable implementations which serves as middleware to route messages. We will get into its details later. | AgentModule class contains Autofac registrations for our project. | . There are five key interfaces in our solution, all lying in Agent folder. They are - . IAgentProvider: Contains methods for Adding, Removing and getting Next Available agent. When agent connects, we add the agent to availability pool by using AddAgent method. Similarly, RemoveAgent method is used to remove the agent. GetNextAvailableAgent method should get the next available agent from availability pool and remove the agent from the pool in an atomic way, so that same agent is not returned twice. . | IUserToAgent: As the name suggests, is used to send messages from user to agent. It’s method SendToAgentAsync does exactly that. It contains two other methods - IntitiateConversationWithAgentAsync to initate a transfer for first time and AgentTransferRequiredAsync to check if routing is required. . | IAgentToUser: Contains a single method SendToUserAsync to send the message from agent to user. . | IAgentUserMapping: Contains methods for adding, removing and fetching the Agent User Mapping. . | IAgentService: Acts as a business class mainly for registering agent, unregistering agent and stopping a conversation. In addtion it contains other methods to check if agent is in existing conversation and whether the message is from an actual/valid agent. . | . Apart from the interfaces, there are two scorables in Scorable folder. Scorable in Bot Framework acts as a middleware to the incoming messages. Using Scorable we can intercept message and take decisions before it is sent to the waiting dialog. We have following scorables in place - . AgentToUserScorable: Intercepts messages coming from agent and routes it to user if agent is in conversation with user. . | UserToAgentScorable: Intercepts messages coming from user and routes it to agent if user is in conversation with agent. . | . Availability Pool . When an agent connects we add him to availability pool. InMemoryAgentStore which derives from IAgentProvider, maintains this pool using an in-memory ConcurrentDictionary. We are not worried about the implementation detail; however, it mimics a “queue” therefore guaranteeing that an agent is only fetched once. . In an actual production scenario, you would maintain this list using an out-proc data store such as RabbitMQ and implement IAgentProvider to to interface with that. . Agent Registration . Agent registration is done through RegisterAgentAsync(IActivity activity, CancellationToken cancellationToken) of AgentService. This method is called when agent clicks on “Connect” button in the dashboard. AgentService is a concrete implementation of IAgentService. . RegisterAgentAsync method first adds a new instance of Agent in to the availability pool using IAgentProvider AddAgent(Agent agent) method. . Once this is successful, it adds a metadata to the agent’s UserData store. We use this metadata information to identify whether the incoming message is from an agent or a user. . In a production use case this is not importnat as your agent would most likely require to logging in, and therefore you can identify them by passing a valid token (or in any other way depending upon your requirments). I added the metadata to keep things simple for this sample. . Disconnecting Agent . When agent clicks on Disconnect button on dashboard, we just remove the agent from availability pool by calling UnregisterAgentAsync(IActivity activity ...) method in IAgentService. The same method also clears the metadata information which was stored in agent’s store. . In a production scenario, you would not allow agent to disconnect if he is already in a conversation with a user. However, in this sample I have not implemented this. . Agent User Mapping . Agent User Mapping is a crucial piece in our overall design. Methods for Setting and Getting this mapping is present in IAgentUserMapping interface. BotStateMappingStorage implements this interface and provides implementation of proper storage of these mapping. The mapping is not stored in memory. Instead it is stored in Bot State Service. . To give a brief background, Microsoft Bot Framework provides three stores to store user state. These are . User Data Store: To store data specific to a user. . | Conversation Store: To store data specific to a conversation. . | Private Conversation Store: To store data specific to a user in a conversation . | . We utilize these to store Agent User Mapping in following ways - . The Agent which the user is talking to is stored in User’s Private Conversation Store. . | The User which the agent is talking to is stored in Agent’s Private Conversation Store. . | . This clever design (😄) makes the Agent User Mapping storage distributed and moves the responsibility of maintaining it to Bot State Service. . But what do we save in the states? We save the address of the agnet and the user respectively. More specifically we save the ConversationReference of the user and agent. ConversationReference can then be used to route message to the receiver on proper channel. We have two classes named Agent and User each having a property of type ConversationReference. We store Agent and User class instances into User and Agent store respectively. . Initiating Conversation . When a user wants to connect to the agent, we call IntitiateConversationWithAgentAsync of IUserToAgent. The method first checks if there are any available agent and fetches the next agent from availability pool. Once we get an agent, we create Agent User Mapping and store it into the states as described in previous section. . Message Routing . Message is routed by fetching the Agent User Mapping. When a message arrives, we retrieve the state associated with the sender. Since our Agent User Mapping is maintained in the state, we get that information too. . User to Agent Route . When user sends a message UserToAgentScorable checks if the message needs to be routed to an agent or not. This check is done by calling AgentTransferRequiredAsync method in IUserToAgent. . AgentTransferRequiredAsync method just checks if the user has the agent mapping in its store. If we find Agent class in its store, it means that the user is in the conversation with an agent. The scorable will then route the message to the agent by calling SendToAgentAsync method in IUserToAgent. . SendToAgentAsync will use the ConversationReference of agent to create a new Activity and send it to agent through Bot Connector. . Due to our implemetnation of Scorable, we are not modifying the DialogStack of the user. This means that when the conversation with agent is stopped, the user returns to same state (Dialog) he was with the bot before the transfer. . Agent to User Route . Agent to user flow is also very similar to the above. When a message arrives, AgentToUserScorable first check if the sender is an agent. It does so by checking the metadata information which we store when registering the agent. Depending upon your requirements, you would have your own logic of checking if the Activity is from an actual agent. . Once we get a message from a valid agent, we then check if the agent is already in an existing conversation. This is done in similar way as described in last section. If we get a valid User in agent’s store, AgentToUserScorable will route the message to the user by calling SendToUserAsync method in IAgentToUser. . Stopping Conversation . Stopping a conversation simply means removing the Agent User Mapping. If this mapping is removed, no further messages would be routed from either user or agent. The implementation of it is done in AgentService class. In this sample only an agent can stop the conversation bbby clicking “Stop Conversation with User” button in dashboard. . Agent Dashboard . As mentioned before, we use Bot Framework Web Chat as a channel for agent. But instead of just using an &lt;iframe&gt;, we directly reference the javascript. I have included botchat.js and botchat.css in the solution by building the Bot Framework Web Chat project. Directly referencing the web chat allows us to use its advanced features which we will see below. . To give a short introduction, Web Chat uses Redux architecture to manage its state. It uses DirectLineJs to connect with the Direct Line API. DirectLineJs uses RxJs to create an Observable which we could subscribe to receive events. . First, we create DirectLine instance. Notice the direct line secret is passed through query string parameter. . var botConnection = new BotChat.DirectLine({ secret: params[&#39;s&#39;], token: params[&#39;t&#39;], domain: params[&#39;domain&#39;], webSocket: params[&#39;webSocket&#39;] &amp;&amp; params[&#39;webSocket&#39;] === &quot;true&quot; }); . Next, we use call BotChat.App passing the Direct Line instance we created above. . BotChat.App({ botConnection: botConnection, user: user, bot: bot }, document.getElementById(&quot;BotChatGoesHere&quot;)); . Tip: You can specify an id and a name in user object. These values will be reflected in From field in Activity which is received by out bot. . Now here comes the interesting part. The two buttons in the page do not make ajax calls to any controller explicitly. Instead they use DirectLineJs to send a message to our bot. These messages are different than messages sent when user types something in the chat window. These messages have different type. . If you have noticed, our Activity class has a Type field. A normal chat message Activity has Type = &quot;message&quot;. You might be aware that there are messages with different types such as conversationUpdate, typing, ping etc. Messages of some of these types are sent by Bot Framework itself such as conversationUpdate is sent when a memeber is added or removed from conversation. . There is another type called event which represents an external event. As of now, Bot Framework by default does not send any messaages of type event. This is left for us developers to use depending upon our requiremnts. We can create a message of type event and sent it to our bot. The bot would recieve it as a normal Activity which would have all the relevant fields populated such as From, Recipient, Conversation etc. . In this example, on button clicks we send messages of type event. For connect button we send message of type event and name=&quot;connect&quot;. Similarly, for disconnect we send message with name=&quot;disconnect&quot;. . const connect = () =&gt; { var name; if(!connected) name = &quot;connect&quot; else name = &quot;disconnect&quot; botConnection .postActivity({type: &quot;event&quot;, value: &quot;&quot;, from: user, name: name}) .subscribe(connectionSuccess); }; . To send messages we use postActivity method of botConnection. We then subscribe to it so we can get back the status whether it was successful or not. . Stop Conversation button works in exactly same way. . const stopConversation = () =&gt; { botConnection .postActivity({type: &quot;event&quot;, value: &quot;&quot;, from: user, name: &quot;stopConversation&quot;}) .subscribe(id =&gt; console.log(&quot;success&quot;)); }; . In our bot, we handle these messages in HandleSystemMessage method in MessageController class. . else if (message.Type == ActivityTypes.Event) { using (var scope = DialogModule.BeginLifetimeScope(Conversation.Container, message)) { var cancellationToken = default(CancellationToken); var agentService = scope.Resolve&lt;IAgentService&gt;(); switch (message.AsEventActivity().Name) { case &quot;connect&quot;: await agentService.RegisterAgentAsync(message, cancellationToken); break; case &quot;disconnect&quot;: await agentService.UnregisterAgentAsync(message, cancellationToken); break; case &quot;stopConversation&quot;: await StopConversation(agentService, message, cancellationToken); await agentService.RegisterAgentAsync(message, cancellationToken); break; default: break; } } } . This is how agent connects and disconnects from out bot. Using direct line to send these “event” messages, we get full context of who has raised the event. It also eliminates the need of creating any “supporting” endpoints just so that we can send some events to the bot. . Almost Done . This completes my tutorial on creating a bot to transfer chats to a human. I have explained all the major concepts involved in achieving this. I have tried to make the code as extensible as possible, nonetheless it could serve as a reference if you want to achieve the same thing. . I cannot close this article without mentioning one of the major shortcoming of this approach. Web Chat channel or Direct Line does not send any event if the client disconnects. If an agent losses the connectivity or closes the dashboard, we do not receive any event regarding this. This means that there is no way of knowing if the agnet is online. It is specially a problem if the agent is in a conversation with the user and suddenly there is a network failure at his end. Ideally in this scenario I would want to re-route the user to next available agent. But since we don’t receive any connectivity information from Direct Line by default, it is left to us to implement a solution. . Let me know your thoughts on this in comments below and ask any questions that you may have. By the way do share the blog if you liked it. .",
            "url": "https://ankitbko.github.io/blog/2017/03/human-handover-bot/",
            "relUrl": "/2017/03/human-handover-bot/",
            "date": " • Mar 28, 2017"
        }
        
    
  
    
        ,"post4": {
            "title": "Skype for Business bot using UCWA",
            "content": "I had recently written a post on how to create a Skype for Business chatbot. In that I used Lync 2013 SDK to intercept messages and pass to bot. However I mentioned in my post that there is a better way to achieve the same by using Unified Communications Web API 2.0(UCWA). Since then I had received a lot of request to write a post on how to do the same. Though I had the code available with me(thanks to Om Shrivastava, my colleague), I did not post it because it was is a very bad shape(you will see). But since there was a lot of demand for it and after discussing with my readers(thank you Dan Williams and Hitesh), I finally got down to do some cleaning up. You can find the source code here. The source code is based on Tam Huynh UCWA Sample, a really well written sample which I then made a mess of. . What is UCWA and why should I care? . From Microsoft’s own words: . Microsoft Unified Communications Web API 2.0 is a REST API that exposes Skype for Business Server 2015 instant messaging (IM) and presence capabilities. . Ok, so it is set of APIs, but why can’t I just keep on using Lync 2013 SDK for my bot as I created previously?. . Well, using Lync 2013 SDK has one major demerit. It requires the bot to run on the system where Skype For Business(SFB)/Lync 2013 is installed and running. That means you are tied down to a machine which would also create problems with scaling. Plus you are dependent upon 4 years old SDK which is no more recommended by Microsoft. . UCWA solves all these problems. Using UCWA, we now no longer need a SFB client running on the system. Bot can be deployed anywhere and scaled independently. . UCWA has a lot of capabilities. However what interests us most is how to send messages and receive messages. Each of these tasks require us to send series of HTTP requests in order to UCWA endpoints. I recommend you read through the above links to understand how it works. . Getting Started . Before even delving into code, you need to set up a lot of things. When developing UCWA applications you need to target either Skype For Business Online or Skype for Business Server(On-Premise). Both have different setup procedure. I recommend you to read through MSDN documentation to understand the differences. In this article and the accompanying code, I would only work with Skype For Business Online. This is primarily because I don’t have an on-premise installation. . The pre-requisite to this is that you must have Office 365 subscription and access to Azure Active Directory to which O365 is linked. Also for setting up you would need to grant permission to our app in Azure Active Directory, which only AD admin can do. Also create two users in Active Directory, one which bot would sign in as and other to test sending message to bot. . Once you have these things ready, the next step is to create an application in Azure Active Directory. I recommend you follow Tam Huynh’s excellent guide. . Once you have the app in azure AD properly setup, keep TenantID, app’s ClientID and app’s RedirectURI handy as we would need them in the code. . Understanding the solution structure . The code itself is just a Console Application. The solution contains 4 folders: . The Bot folder contains the Dialog class and an implementation of IBotToUser. All these classes are related to Bot Framework. I have used EchoDialog from the bot framework sample which echoes back the initial message with a count. | UcwaSfbo folder mostly contains classes as it is from Tam Huynh’s sample except for UcwaReciveMessage.cs and UcwaSendMessage.cs. As name suggests, these two classes are used to receive and send messages to SFB. | Utilities.cs contains some some convenience methods. | Data folder contains auto generated classes that represents UCWA JSON responses. | . . Code Smell . Data folder is a mess. All these classes were auto-generated based on responses from UCWA APIs. Therefore there are lot of duplicate classes. I tried to clean up some of it but couldn’t get time to see it through. UcwaReciveMessage.cs and UcwaSendMessage.cs are also not very well written. It was hastily written as a first attempt to get a PoC on UCWA. Once you get the understanding of what is happening, I would suggest you rewrite them for your own applications. . Setting up the code . Open Program.cs and you would see some static strings. Replace the values of tenantId, clientId and redirectUri to what you copied before. hardcodedUsername and hardcodedPassword are credentials for the user that you would want the bot to sign in as. If you don’t want to hardcode the credentials, that is fine too as we will see later. destinationAddress is not used so you could leave it as it is. . Go to App.config and enter a valid MicrosoftAppId and MicrosoftAppPassword for an existing registration of bot in bot framework portal. It is required as we would be using Bot State Service to store the conversation state. . Once done run the sample and you would be greeted by a console message to choose a login style. If you are running the project for first time after creating the AD app, choose dialog option. This is needed as you would be asked to provide some consent, which requires a web page so console login doesn’t work. This only needs to be done once. Next time you could just use console option and bot would sign in using hardcoded credentials which we defined before. If you don’t want to hardcode, your only choice to proceed is through dialog option. . If the program started successfully you would see json responses in the console. Login to Skype for Business as the other user and send the message to the bot. The bot should echo back what you typed. Great!! Our bot is working as expected. . Under the hood . Once the bot signs in using the credentials provided, it polls the UCWA for incoming messages. As mentioned before, you need to send series of requests to UCWA in specific order for this to work. All this is handled in UcwaReciveMessage.cs class. When you send a message to the bot, the message is actually received in GetIM_Step03_Events method. Once I get the message I create the Activity object with minimum information required. . string SendMessageUrl = item1._embedded.message._links.messaging.href; var conversationId = item.href.Split(&#39;/&#39;).Last(); var fromId = item1._embedded.message._links.contact.href.Split(&#39;/&#39;).Last(); Activity activity = new Activity() { From = new ChannelAccount { Id = fromId, Name = fromId }, Conversation = new ConversationAccount { Id = conversationId }, Recipient = new ChannelAccount { Id = &quot;Bot&quot; }, ServiceUrl = &quot;https://skype.botframework.com&quot;, ChannelId = &quot;skype&quot;, ChannelData = SendMessageUrl }; activity.Text = message; . The conversationId and fromId are extracted from the JSON response. These are required as the conversation state are stored using these key. SendMessageUrl is required to reply to user. We store it in the ChannelData property of Activity. . Once activity object is properly initialized, we jump start the bot and pass the activity object as the incoming message. Instead of starting the bot here, or if you have an existing bot, you could use Direct Line API to send the message to the bot. . using (var scope = Microsoft.Bot.Builder.Dialogs.Conversation .Container.BeginLifetimeScope(DialogModule.LifetimeScopeTag, builder =&gt; Configure(builder))) { scope.Resolve&lt;IMessageActivity&gt; (TypedParameter.From((IMessageActivity)activity)); DialogModule_MakeRoot.Register (scope, () =&gt; new EchoDialog()); var postToBot = scope.Resolve&lt;IPostToBot&gt;(); await postToBot.PostAsync(activity, CancellationToken.None); } . In the Configure method I register my custom implementation of IBotToUser. . private static void Configure(ContainerBuilder builder) { builder.RegisterType&lt;BotToUserLync&gt;() .As&lt;IBotToUser&gt;() .InstancePerLifetimeScope(); } . BotToUserLync reads the ChannelData property of the Activity and calls SendIM_Step05 method of UcwaSendMessage which sends a request to UCWA to reply to the user. . Conclusion . Using UCWA is easy once you understand how it works. However it is tiring process to write code against it. There are lot of steps to follow in particular order and lack of any SDK makes it more difficult. The present sample is not at all production ready. I would recommend you use this sample to understand what happens inside and implement a better(and cleaner) solution if you are developing it for a live environment. . I hope this article was helpful. If you have any questions, please post a comment below. .",
            "url": "https://ankitbko.github.io/blog/2017/02/Sykpe-For-Business-Bot-Using-UCWA/",
            "relUrl": "/2017/02/Sykpe-For-Business-Bot-Using-UCWA/",
            "date": " • Feb 26, 2017"
        }
        
    
  
    
        ,"post5": {
            "title": "Integrating CRIS with Microsoft Bot Framework",
            "content": "Couple of months ago I wrote an article on how to skype call a bot. Behind the scene, the bot used Bing Speech API to perform Speech-To-Text(STT) conversion to get plaintext output of what user spoke. It was all cool but I was fairly disappointed with accuracy of Bing Speech. It failed miserably when using domain specific terminology and also did not perform so well with my accent(Indian). Also it did not fair nicely in a noisy environment. . All of these issues goes away with new service called Custom Speech Service(CRIS) which Microsoft made it available as Public Preview earlier this month. You may be wondering what letter R and I stands for in CRIS. Well CRIS was earlier known as Custom Recognition Intelligent Service, but Microsoft renamed it to Custom Speech Service (though I believe the former sounded much cooler). . CRIS lets us create a customized language and acoustic model. What are these models? . Language Model: The language model decides what sequence of words are more likely to occur in a sentence. It does it by creating a probability distribution over over sequence of words. You train the language model by providing a plaintext file containing list of sentences which are similar to what user would speak. . | Acoustic Model: The acoustic model would break down a short fragment of audio and classify it into one of the phonemes. This can help the system to recognize domain specific words in a sentence such as “When did Neanderthal became extinct”. Acoustic models are trained by providing audio files of speech data and a text file of its corresponding transcript. The audio data should be as close to the environment where you expect your app/bot to be used most. For example, if you expect your user to use your bot on road, you should provide audio files of people speaking on road. Acoustic model can then learn the environment and would work much better. . | . More details about the models are available in the documentation. In this sample, we would only train the Language model and use the base acoustic model. . Getting Started . To use CRIS you would need to get a subscription from Azure. Don’t worry, CRIS is free till 5000 requests/month, so you could try it out. Once you get your subscription key, you need to add it to CRIS portal. Follow the guide to get it done. . We would be using the same source code that I created for skype call a bot post. We would just modify it to support CRIS. I recommend you go through the post first before continuing. Since we would be using the same code base, we would inherit all the bad designs which I described in previous post specially how the response is sent. I absolutely dislike the way I had done it. You are better off using some other way(preferably reactive programming) to achieve the same. In any case, the source code could be found here. . Training Language Model . As mentioned above, training data for Language model is just plaintext file. The file should contain list of utterances with one sentence per line. The sentences may not be complete sentences or grammatically correct as long as it accurately reflects what user would speak. There are some main requirements such as encoding, size limit etc which you can read in the documentation. . I have created a simple file for sample which you could find in CRIS folder in the code. Note that I have just added few sentences for example purpose. Feel free to extend it by adding more sentences. Also you could add part of sentence or words which you think user would most likely speak such as city names. . Once we have training data ready we need to import it in CRIS. Go to Language Data tab by clicking on Menu -&gt; Language Data and click on Import New. Enter the data name and select the text file to upload. . . Once the training data is uploaded it would be queued for processing. You could check the status of it by going to Language Data tab(it should redirect automatically). Wait till it status is shown as Complete. . Next we need to create a Language Model. Go to Language Model page and click on Create New. Give a name and description to your model. There are two types of base model - . Microsoft Conversational Model is optimized for recognizing speech spoken in conversational style. . | Microsoft Search and Dictation Model is appropriate for short commands, search queries etc. . | . We would be using the Conversational Model base model, since we expect our user to talk to our bot rather than give commands. Select the Language Data that we uploaded in previous step. Once form is filled click on Submit. . . Similar to previous step, the language model training would take some time. Wait till the status is Complete. . Once the model is successfully created, go to Deployments page and create a new deployment. In the form presented, select the base model as Microsoft Conversational Model and select our trained Language model. For Acoustic Model, select the default base model which is shown. . . Once the deployment is complete, you would be redirected to the Deployment Information page where you would need to copy the Url specified in WebSocket for ShortPhrase Mode. We would require the Url later in the code. . . Integrating CRIS with Bing Speech SDK . We would continue using the Bing Speech client library for STT. But instead of calling to Bing Speech API we would send the speech to our CRIS deployment. We only need to change how our DataRecognitionClient is created as shown below. . public string SubscriptionKey { get; } = &quot;CRIS SubscriptionKey&quot;; public string CrisUri { get; } = &quot;CRIS ShortPhrase Mode URL&quot;; public string AuthenticationUri { get; } = &quot;https://westus.api.cognitive.microsoft.com/sts/v1.0/issueToken&quot;; public void CreateDataRecoClient() { dataClient = SpeechRecognitionServiceFactory.CreateDataClient( SpeechRecognitionMode.ShortPhrase, DefaultLocale, SubscriptionKey, SubscriptionKey, CrisUri); dataClient.AuthenticationUri = AuthenticationUri; dataClient.OnResponseReceived += OnDataShortPhraseResponseReceivedHandler; } . Paste the deployment URI for Short Phrase which we copied from before in CrisUri and also enter the CRIS subscription key in SubscriptionKey. We would continue to use the ShortPhrase mode as we did before. The only difference now is that the speech is now sent to CRIS instead of Bing Speech API. Leave the AuthenticationUri as it is as it does not needs to be changed. . Apart from this there are no other changes required. You could run the bot as it is and it would work out. Check my previous post on how to run and test this bot. Do not forget to a valid LUIS subscription key in RentLuisDialog and change MicrosoftAppId, MicrosoftAppPassword and CallbackUrl appropriately. . Conclusion . I have been waiting for CRIS for a long time and it is finally available to use. It works so much better than Bing Speech API and looks really promising. However I don’t think that Calling Bot is matured enough yet. It looks a little sketchy and entire flow is not smooth, but it is still in preview so lets wait and watch. Meanwhile try out training Acoustic Model and let me know in the comments how did it work out. .",
            "url": "https://ankitbko.github.io/blog/2017/02/cris-with-bot-framework/",
            "relUrl": "/2017/02/cris-with-bot-framework/",
            "date": " • Feb 24, 2017"
        }
        
    
  
    
        ,"post6": {
            "title": "BusyBot - Chat Bot for Skype for Business",
            "content": "We use Skype for Business in our organization which is a fairly common IM applications used in enterprises. The most common distraction while working is popping up of Skype message. And then it takes even more time to reply and finish the conversation, because not replying to colleagues is just rude. So I thought why not create a bot that replies to the messages for me. Unfortunately, Microsoft Bot Framework does not support Skype for Business as one of the channels so I had to find another way to make it works. . Skype for Business has set of APIs called Unified Communications Web API which can enable us to integrate it with a bot, however it is unnecessarily complicated (it requires 5 HTTP calls to just send 1 message). So after searching a bit, I found that Lync 2013 SDK still works with Skype for Business (courtesy to my friend Om) and found an excellent starter code at Taha Amin’s Github Repo BotConnectorSkypeForBusiness. . Lync SDK is fairly straightforward to use. It is event-based and integrates easily with Bot Framework. The only limitation is that Lync 2013/Skype for Business should be already running. Using this I created a simple bot that would let me work in peace. Source code is over here . Dependency . The bot has an optional dependency on Redis server. Since the bot will not be talking to Microsoft Bot Connector in any way, we would need to store bot’s context somewhere ourself. I had earlier used locally running instance of Redis. However now I have commented out RedisStore and used InMemoryStore. To use Redis store uncomment the region in Program.cs and comment InMemory region. . You would also need Skype For Business running and signed in. . Features . So what does the bot do as of now? It accepts the incoming IM and - . Responds to greetings - Hi, Hello, Good Morning etc. | In case the person wants to call me or asks whether I am free - respond that I am busy and will talk later and set my status to Busy. | Ignore any other messages - Pretend I am busy | Exception Filter - Bot does not reply anything if sender is present in Exception List. I don’t want to reply to my manager that I am busy if he pings me. :) | . How to use . The bot is just a console application. The bot service is not hosted as Web Api, but runs within the console applications. First create a new LUIS application by importing the model json from LuisModel directory. Copy your LUIS model id and subscription key and paste it in LuisModel attribute in LyncLuisDialog.cs. . The exception list is located in App.config in the console project. Values are ; separated. . &lt;add key=&quot;ManagerList&quot; value=&quot;sip:name1@domain.com;sip:name2@domain.com&quot;/&gt; . Make sure your Skype for Business client is running and you are signed in and just start the console project. Ask your friend to ping you and see what happens. . How it works . Lync 2013 SDK is based on event driven programming. We just subscribe to right event instantMessageModality.InstantMessageReceived += InstantMessageReceived; and any messages will come to our InstantMessageReceived method. . private void InstantMessageReceived(object sender, MessageSentEventArgs e) { var text = e.Text.Replace(Environment.NewLine, string.Empty); var conversationService = new ConversationService((InstantMessageModality)sender); SendToBot(conversationService, text); } . Once we get the message text, we bootstrap our bot and pass the text as properly formatted Activity message. . private async void SendToBot(ConversationService conversationService, string text) { Activity activity = new Activity() { From = new ChannelAccount { Id = conversationService.ParticipantId, Name = conversationService.ParticipantName }, Conversation = new ConversationAccount { Id = conversationService.ConversationId }, Recipient = new ChannelAccount { Id = &quot;Bot&quot; }, ServiceUrl = &quot;https://skype.botframework.com&quot;, ChannelId = &quot;skype&quot;, }; activity.Text = text; using (var scope = Microsoft.Bot.Builder.Dialogs.Conversation .Container.BeginLifetimeScope(DialogModule.LifetimeScopeTag, builder =&gt; Configure(builder, conversationService))) { scope.Resolve&lt;IMessageActivity&gt; (TypedParameter.From((IMessageActivity)activity)); DialogModule_MakeRoot.Register (scope, () =&gt; new Dialogs.LyncLuisDialog(scope.Resolve&lt;PresenceService&gt;())); var postToBot = scope.Resolve&lt;IPostToBot&gt;(); await postToBot.PostAsync(activity, CancellationToken.None); } } . The bot then follows usual flow of sending the text to LUIS and determining the intent. Based on the context, it will then send it response back to - BotToUserLync class which implements IBotToUser. This allows us to catch the bot response and instead of sending it to the Bot Connector, we use Lync SDK once again to reply it to our counterpart. . The Exception Filter is managed in ManagerScorable which implements IScorable&lt;IActivity, double&gt;. Scorables are the way to intercept the bot pipeline and branch off with another logic based on requirements. In our case, we check if the incoming message was sent from anyone on the filter list and if it is then we just do nothing. I may write another post on Scorables and discuss about it a little more later. . Conclusion . That’s it. It took me a day to get it all done. The bot is very rudimentary but gets the job done. I now no longer have to reply toe very conversation when I am working. In any case, Skype for Business already saves all the conversation history so I can go over them once I get free. One day of work and lifetime of peace. :) . I hope this article was helpful. If you have any questions, please post a comment below. .",
            "url": "https://ankitbko.github.io/blog/2017/01/BusyBot-Sykpe-For-Business-Bot/",
            "relUrl": "/2017/01/BusyBot-Sykpe-For-Business-Bot/",
            "date": " • Jan 9, 2017"
        }
        
    
  
    
        ,"post7": {
            "title": "Skype Call your bot - Microsoft Bot Framework with Bing Speech",
            "content": "So over this past weekend, I was dead bored when I got this idea of calling a bot from Skype. Skype bot calling feature does exist(preview) but the samples which are available are only for simple IVR bot. So I thought why not integrate it with Bot Builder SDK, so that same bot can text and answer call at same time. So the basic idea is that the bot should follow the same flow irrespective whether the user texts or calls. Great idea to past time, after some initial trouble, I did manage to get it done(not neatly though). So why not write a blog about it. Source code is available over my github repo. . I developed this sample over weekend just to find out whether it could be done or not. It is not a very cleanly written sample and there is a design flaw due to which the bot cannot be scaled out. I will address this design issue and also explain how we can make it scalable. Nonetheless, I decided to write down this blog because it provides a nice insight into Skype Calling Bot and also how to intercept the responses from Bot by implementing IBotToUser interface. . For this fun project, we will use the Bot Builder Calling SDK which is now part of Bot Framework, to make a call to our bot. Once we get the audio stream of the caller, we will use Bing Speech API for Speech-to-Text conversion. After we receive the text, we will just pass it to our bot and our bot will behave in the same way as it does for text input. The trick here is to not let our bot reply back to user through bot connector, but to intercept the reply messages and pass it onto Skype Calling APIs which manages Text-to-Speech conversion and would speak back to the user. The plan is to utilize feature rich Bot Builder SDK to build our bot and plugin the voice calling functionality on top of it, without having to modify any of the bot logic. . Fair Warning: This is going to be a long post. Before getting into details, I will give a brief overview of Bot Builder Calling SDK and Bing Speech SDK. . Bot Builder Calling SDK . Bot Builder Calling SDK is just a nice client package to call Skype Calling APIs. I recommend you read through the API documentation to understand how calling works through Skype. I will just explain it briefly here. . When a call arrive to Skype Bot Platform, it would notify our bot by calling our bot’s HTTPS endpoint. Once we receive this notification, we(our bot) can reply back by providing a list of actions called workflow to execute. So for the initial call notification, we can either reply back by Answer or Reject action. The Skype Bot Platform will then execute the workflow and return us the result of last action executed. The SDK will raise an appropriate Event which we can subscribe to and handle the action outcome in our code. For example, on initial call notification, sdk will raise OnIncomingCallReceived event. On each event, we have opportunity to send another workflow to the user. In fact it is mandatory to return list of actions otherwise the sdk will throw an error and the call would get disconnected. The below image, which I shamelessly copied from official documentation, explains how Skype calling works. . . Bing Speech API . We will use Bing Speech API for Speech-to-Text(STT) conversion. Microsoft team has released a thin C# client library for STT conversion using Bing Speech API. The samples are available on github and the library is available over nuget. For some reason they have different libraries for x64 and x86. Make sure you use the correct one depending upon your system. . The first thing to do is get a Speech API subscription key (free) by signing up for Cognitive Services. The STT sdk also works on event based model. In simple terms, the audio stream is sent to Speech API, which then returns the recognized text which is available in the argument OnResponseReceived event which is raised. The Speech API also returns partially converted text, but in our case we ignore them. . Putting it all together . But before that, we need to get develop a bot which works text inputs. I have gone ahead and created a very simple bot using FormFlow which allows user to rent a car. LUIS is used for text classification which returns the intent as Rent and entities such as PickLocation and Pickup Date and Time. Following which I just pass the entities to the FormFlow which takes care of asking appropriate questions and filling out rest of the form. Simple. . . To integrate Skype call, there are few complication - . There are 2 layers of event based models which needs to be wired together - Skype Calling SDK and Bing Speech SDK. | The STT output needs to be supplied to the Bot Builder in correct format. Our bot expects an IMessageActivity instance with properly filled in IDs such as Conversation ID, Channel ID etc so that it can fetch correct state from State Service. | The response from the bot needs to be intercepted and somehow returned back to event based model of Skype SDK. | . We will address each of them one by one. . To start with we create a project from Calling Bot Template. The template creates a very basic IVR bot with a CallingController which receives the request from Skype Bot Platform and a SimpleCallingBot class which derives from ICallingBot which handles all the events which are raised by the Calling Bot SDK. The template also have a MessageController with default bot implementation. . Next create a new class RentCarCallingBot and derive it with ICallingBot. I have used SimpleCallingBot as a reference therefore you will see basic structure and few methods are same. In the constructor we subscribe to the events which will be raised when a workflow is completed. . public RentCarCallingBot(ICallingBotService callingBotService) { if (callingBotService == null) throw new ArgumentNullException(nameof(callingBotService)); this.CallingBotService = callingBotService; CallingBotService.OnIncomingCallReceived += OnIncomingCallReceived; CallingBotService.OnPlayPromptCompleted += OnPlayPromptCompleted; CallingBotService.OnRecordCompleted += OnRecordCompleted; CallingBotService.OnHangupCompleted += OnHangupCompleted; } . We subscribe to only 4 events - . OnIncomingCallReceived: Is fired when a call arrives at Skype Bot Platform. This is the same event which I explained earlier. Here we can either accept or reject the call. | OnPlayPromptCompleted: Is fired when PlayPrompt action is completed. PlayPrompt action performs Text-to-Speech(TTS) conversion and plays back the supplied text to the caller. Once the playback is complete and if it is the last action in the workflow, then this event is raised. | OnRecordCompleted: Similar to above, this event is raised when Record action completes. Record action allows us to record the caller’s voice and gives us an audio stream. This is the primary way to receive the audio of caller. | OnHangupCompleted: As name suggests, is raised when we hangup. | . OnIncomingCallReceived . private Task OnIncomingCallReceived(IncomingCallEvent incomingCallEvent) { var id = Guid.NewGuid().ToString(); incomingCallEvent.ResultingWorkflow.Actions = new List&lt;ActionBase&gt; { new Answer { OperationId = id }, GetRecordForText(&quot;Welcome! How can I help you?&quot;) }; return Task.FromResult(true); } . Upon receiving a call, we get an IncomingCallEvent object as argument. To this, we can add next steps of actions to be executed in the workflow. We add 2 events to the workflow - Answer and Record. We first answer the call and then start a Record action to get the caller’s input. Skype will start recording after speaking welcome message. The recorded stream will be available to us in OnRecordCompleted event. A thing to note is that we must specify an OperationId to each action. It is used to correlate the outcome of the event. . OnRecordCompleted . private async Task OnRecordCompleted(RecordOutcomeEvent recordOutcomeEvent) { if (recordOutcomeEvent.RecordOutcome.Outcome == Outcome.Success) { var record = await recordOutcomeEvent.RecordedContent; BingSpeech bs = new BingSpeech(recordOutcomeEvent.ConversationResult, t =&gt; response.Add(t), s =&gt; sttFailed = s); bs.CreateDataRecoClient(); bs.SendAudioHelper(record); recordOutcomeEvent.ResultingWorkflow.Actions = new List&lt;ActionBase&gt; { GetSilencePrompt() }; } else { if (silenceTimes &gt; 1) { recordOutcomeEvent.ResultingWorkflow.Actions = new List&lt;ActionBase&gt; { GetPromptForText(&quot;Thank you for calling&quot;), new Hangup() { OperationId = Guid.NewGuid().ToString() } }; recordOutcomeEvent.ResultingWorkflow.Links = null; silenceTimes = 0; } else { silenceTimes++; recordOutcomeEvent.ResultingWorkflow.Actions = new List&lt;ActionBase&gt; { GetRecordForText(&quot;I didn&#39;t catch that, would you kinly repeat?&quot;) }; } } } . There are three sections in this method. The first if block is executed when we have successfully recorded the voice of the caller. We get the recorded content and pass it to BingSpeech class. It accepts 3 arguments in constructor, the first being the ConversationResult, the second and third being 2 delegates. The first delegate is used add a string to response property which is a List&lt;string&gt;. The response list maintains the list of messages which bot will send to the caller. The second delegate sets a flag if the STT conversion failed. In short this class calls the Bing Speech API and upon receiving the STT output, it goes ahead and passes it to our bot. Then we go ahead and add a PlayPrompt action which just keeps silence for specified period of time. This is required as we do not have result from bot immediately as we will see later. . If we do not receive a successful recoding, we give the caller a chance to speak again once more. If the recording fails again, we disconnect the call gracefully. The silenceTimes counter is used for this purpose. . OnPlayPromptCompleted . private Task OnPlayPromptCompleted(PlayPromptOutcomeEvent playPromptOutcomeEvent) { if (response.Count &gt; 0) { silenceTimes = 0; var actionList = new List&lt;ActionBase&gt;(); actionList.Add(GetPromptForText(response)); actionList.Add(GetRecordForText(string.Empty)); playPromptOutcomeEvent.ResultingWorkflow.Actions = actionList; response.Clear(); } else { if (sttFailed) { playPromptOutcomeEvent.ResultingWorkflow.Actions = new List&lt;ActionBase&gt; { GetRecordForText(&quot;I didn&#39;t catch that, would you kindly repeat?&quot;) }; sttFailed = false; silenceTimes = 0; } else if (silenceTimes &gt; 2) { playPromptOutcomeEvent.ResultingWorkflow.Actions = new List&lt;ActionBase&gt; { GetPromptForText(&quot;Something went wrong. Call again later.&quot;), new Hangup() { OperationId = Guid.NewGuid().ToString() } }; playPromptOutcomeEvent.ResultingWorkflow.Links = null; silenceTimes = 0; } else { silenceTimes++; playPromptOutcomeEvent.ResultingWorkflow.Actions = new List&lt;ActionBase&gt; { GetSilencePrompt(2000) }; } } return Task.CompletedTask; } . The first time this event is raised is when we have recorded the user’s input and have passed it to the BingSpeech class. At this point of time, we may or may not have any output from the bot itself. If there are any output(reply) from the bot, it will be added to response list. The response field contains the List&lt;string&gt; which are returned by bot to the user. If response is not empty, we get the PlayPrompt Action for the responses and add it to the workflow. We add a Record action after PlayPrompt to capture the next input from caller. In case the response is empty, it may mean one of the following two things, either the STT conversion failed or the processing of earlier input is yet not completed by the bot. If the STT conversion failed, we play a prompt to user and ask him to repeat and start the recording again. If the bot has not yet processed the previous input, then we start another silence prompt. We maintain a counter for how many times did we end up waiting for bot to complete processing, if it increases a threshold, we gracefully hangup. . OnHangupCompleted . private Task OnHangupCompleted(HangupOutcomeEvent hangupOutcomeEvent) { hangupOutcomeEvent.ResultingWorkflow = null; return Task.FromResult(true); } . Self-explanatory. Just set the workflow to null and return. . . Intercepting Bot response . Microsoft Bot Framework does not return the response/reply in-line to the HTTP request. Instead it sends a separate HTTP request to Bot Connector with the reply message. We can intercept this flow by implementing IBotToUser interface. The default implementation which sends the message to Bot Connector is called AlwaysSendDirect_BotToUser. We will create a class BotToUserSpeech and derive this interface. . public BotToUserSpeech(IMessageActivity toBot, Action&lt;string&gt; _callback) { SetField.NotNull(out this.toBot, nameof(toBot), toBot); this._callback = _callback; } public IMessageActivity MakeMessage() { return this.toBot; } public async Task PostAsync(IMessageActivity message, CancellationToken cancellationToken = default(CancellationToken)) { _callback(message.Text); if (message.Attachments?.Count &gt; 0) _callback(ButtonsToText(message.Attachments)); } . The constructor takes two parameters, the first being IMessageActivity and the second being a delegate to return the response to. This is the same delegate which was passed in BingSpeech class constructor in OnRecordCompleted event. The delegate just adds the string to response field. We need to implement just two method to MakeMessage and PostAsync. In MakeMessage we just return back the IMessageActivity object that we received from constructor. In PostAsync, we call the _callback delegate with the message text field. If the message has any attachment, we convert the buttons and cards in the attachment to plain string which is then passed to _callback. This ensures that buttons which are displayed to user normally in chat windows, gets converted to simple text so that the caller has all the options. . Once we have this class ready, we just need to wire it up in the dependency container which we do in BingSpeech class. . BingSpeech . This class performs three tasks (talk about SRP!!!). First it receives the audio stream and sends it in chunks to Bing Speech API. Second it receives the event which is raised once the Bing Speech completes the STT conversion. Third it takes the STT output, and sends it to our RentACar bot. For this step it must setup the required dependencies and get instances through container to pass the message in correct format. Let’s step through each of them one by one. But before that, put the Bing Speech API subscription key in SubscriptionKey property. . string SubscriptionKey { get; } = &quot;Bing Speech subscription key&quot;; . Perform Speech-To-Text . public void CreateDataRecoClient() { this.dataClient = SpeechRecognitionServiceFactory.CreateDataClient( SpeechRecognitionMode.ShortPhrase, this.DefaultLocale, this.SubscriptionKey); this.dataClient.OnResponseReceived += this.OnDataShortPhraseResponseReceivedHandler; } . First we ask SpeechRecognitionServiceFactory to give us a DataClient instance. SpeechRecognitionServiceFactory can give us 4 types of clients - . MicrophoneClient: Used to get audio stream by using device’s microphone and then perform STT conversion. | DataClient: No microphone support. You can use it to pass audio from Stream. | MicrophoneClientWithIntent: Same functionality as MicrophoneClient. Additionally it will also send the text to LUIS and return LUIS entities and intents along with the text. | DataClientWithIntent: Same as DataClient. Additionally it too will send the STT result to LUIS to perform intent and entity detection. | . In our scenario, we already receive voice stream from Skype and the NLP part will be done by our bot, therefore DataClient would work out for us. Next we subscribe to event OnResponseReceived, as this will be raised once STT processing is done by Bing Speech for complete stream. . public void SendAudioHelper(Stream recordedStream) { int bytesRead = 0; byte[] buffer = new byte[1024]; try { do { // Get more Audio data to send into byte buffer. bytesRead = recordedStream.Read(buffer, 0, buffer.Length); // Send of audio data to service. this.dataClient.SendAudio(buffer, bytesRead); } while (bytesRead &gt; 0); } catch (Exception ex) { WriteLine(&quot;Exception &quot; + ex.Message); } finally { // We are done sending audio. Final recognition results will arrive in OnResponseReceived event call. this.dataClient.EndAudio(); } } . SendAudioHelper will use dataClient to send the audio stream to Bing Speech Service. Once the entire stream is processed, the result will be available in OnResponseReceived event. . private async void OnDataShortPhraseResponseReceivedHandler(object sender, SpeechResponseEventArgs e) { if (e.PhraseResponse.RecognitionStatus == RecognitionStatus.RecognitionSuccess) { await SendToBot(e.PhraseResponse.Results .OrderBy(k =&gt; k.Confidence) .FirstOrDefault()); } else { _failedCallback(true); } } . If the STT conversion is successful, we order the result by confidence score and send it to our bot. Otherwise we call the callback for failure which sets a flag to true. This flag was then checked back at OnPlayPromptCompleted to either proceed or request caller to speak again. . Send to bot . Next challenge is to take the STT result and construct a valid Activity instance. Why? Because everything in Bot Builder depends upon a proper instance of IMessageActivity. Moreover we need to wire-in our BotToUserSpeech class. We do this by registering it into Autofac ConnectionBuilder while starting a new LifetimeScope. . private async Task SendToBot(RecognizedPhrase recognizedPhrase) { Activity activity = new Activity() { From = new ChannelAccount { Id = conversationResult.Id }, Conversation = new ConversationAccount { Id = conversationResult.Id }, Recipient = new ChannelAccount { Id = &quot;Bot&quot; }, ServiceUrl = &quot;https://skype.botframework.com&quot;, ChannelId = &quot;skype&quot;, }; activity.Text = recognizedPhrase.DisplayText; using (var scope = Microsoft.Bot.Builder.Dialogs.Conversation .Container.BeginLifetimeScope(DialogModule.LifetimeScopeTag, Configure)) { scope.Resolve&lt;IMessageActivity&gt; (TypedParameter.From((IMessageActivity)activity)); DialogModule_MakeRoot.Register (scope, () =&gt; new Dialogs.RentLuisDialog()); var postToBot = scope.Resolve&lt;IPostToBot&gt;(); await postToBot.PostAsync(activity, CancellationToken.None); } } private void Configure(ContainerBuilder builder) { builder.Register(c =&gt; new BotToUserSpeech(c.Resolve&lt;IMessageActivity&gt;(), _callback)) .As&lt;IBotToUser&gt;() .InstancePerLifetimeScope(); } . The Activity instance must be valid. At least the 3 IDs needs to be specified to get and set context from state service. For the IDs, we can use ConversationResult.Id which is a unique for each conversation. We also have ConversationResult.AppId which is AppId of the caller but for some reason it was always null for me. Along with them, ServiceUrl and ChannelId should also be correct, otherwise bot will throw exception. Once we have a valid Activity instance, we assign it’s text property to our STT output. . To send this Activity instance to the bot, we need to resolve instance of IPostToBot. Once we get it, we just call it’s PostAsync method and pass the Activity instance. This would kick start our bot, deserialize the Dialog State and resume/start the conversation. This is exact flow which happens when we call Conversation.SendAsync from MessageController. . CallingController . Finally in CallingController pass the instance of RentCarCallingBot when registering the calling bot in the constructor. . public CallingController() : base() { CallingConversation.RegisterCallingBot(c =&gt; new RentCarCallingBot(c)); } . Scalability Problems . The response from bot will eventually arrive at our BotToUserSpeech class, which would just pass the response text to our delegate which would add it to a list maintained in RentCarCallingBot. The list is then monitored when the workflow is finished and Skype API sends us a callback with result. We have put together everything in such a that once the bot finishes user recording, it then plays a silent prompt and monitors the response list. . This is where the problem lies. Our BotToUserSpeech class will capture the response and add it to the List. However in scenario where we have scaled out and have multiple bot services running behind a load balance, there is no knowing where the next callback from Skype API is going to land. Our current implementation locks us to only single bot service and prevents us from scaling. . We can resolve this issue by changing our implementation of BotToUserSpeech class. For example, instead of passing the response to a delegate, we can push it into a queue such as RabbitMQ. On the OnPlayPromptCompleted method, we can then check if there are any messages in the queue to play to the user. We must also take care of posting message to the queue when STT failed. So in short, both our delegates needs to be replaced by an out of process storing mechanism which can be accessed by multiple running services. Since RabbitMQ or any other queue can be monitored by multiple bot services, it solves our scalability issue. . Testing our bot . We can test our bot locally by using ngrok. Ngrok creates a secure tunnel to localhost and provides us a public URL. Any call to public url will be forwarded to a service running on localhost at our system. We create a tunnel ngrok http --host-header=localhost 3999 to forward request to localhost:3999 where we will host our bot. Ngrok will then generate a random public URL. Note the https forwarding URL. . . The first place we need to change is in the web.config. Replace the value of CallbackUrl key by ngrok URL. It should look like https://&lt;ngrokURL&gt;/api/calling/callback. Once we register our bot at Bot Framework Portal, click on Edit on Skype channel. We must enable 1:1 audio calls feature. In the Calling Webhook text box, enter the ngrok URL in format of https://&lt;ngrokURL&gt;/api/calling/call. . . That’s it. Run the bot locally on the same port that was tunneled by ngrok. We can then start making calls to our bot. Try speaking “Rent a car from London” . Conclusion . In the evolution of UI, and the advent of bot, it is only natural that the next logical step is to voice call the bot. Imagine just calling your self-driving car to pick you up from your current location. Can’t wait to live in such a world. The bot ecosystem is pretty new, and the voice call to bot feature itself is just emerging. The current platform is no where production ready. It’s messy and STT is not accurate especially for non-US accent. We may see drastic improvement in Bing Speech service and the new CRIS service looks promising. And with Microsoft achieving human parity in speech recognition, this dream may not be too far. .",
            "url": "https://ankitbko.github.io/blog/2016/11/skype-call-your-bot/",
            "relUrl": "/2016/11/skype-call-your-bot/",
            "date": " • Nov 9, 2016"
        }
        
    
  
    
        ,"post8": {
            "title": "Microsoft Bot Framework - Use Redis to store conversation state",
            "content": "Bots created using Microsoft Bot Framework are by default stateless. The conversation state and it’s associated context is stored by Bot State Service in cloud. The state service stores information in 3 distinct bags keyed by their associated ids - . Property Key Description . User | User Id | Remembering context for a user on a channel | . Conversation | Conversation Id | Remembering context all users in a conversation | . Private Conversation | Conversation Id + User Id | Remembering context for a user in a conversation | . Bot State Service documentation provides more detail explanation to them. Moreover all these property bags are scoped by the Bot id and Channel id, essentially making them unique. The Dialog Stack and Dialog Data are both stored in Private Conversation bag. . If we want to store these data in our database, Bot Framework provides two extension points to do that - . Create a REST layer by implementing IBotState interface | Implement IBotDataStore&lt;T&gt; in your bot | . In this post, we will implement IBotDataStore to store the context in Redis. However making a REST service by implementing IBotState should be similar. The source code is available here. . Redis Store . public interface IBotDataStore&lt;T&gt; { Task&lt;bool&gt; FlushAsync(BotDataKey key, CancellationToken cancellationToken); Task&lt;T&gt; LoadAsync(BotDataKey key, BotStoreType botStoreType, CancellationToken cancellationToken); Task SaveAsync(BotDataKey key, BotStoreType botStoreType, T data, CancellationToken cancellationToken); } . IBotDataStore is a simple interface with only three methods to implement, all of them being self explanatory. We will start with SaveAsync. We will use StackExchange.Redis for C# client. . public async Task SaveAsync(BotDataKey key, BotStoreType botStoreType, BotData data, CancellationToken cancellationToken) { Connect(); var redisKey = GetKey(key, botStoreType); var serializedData = Serialize(data.Data); var database = _connection.GetDatabase(_options.Database); var tran = database.CreateTransaction(); if (data.ETag != &quot;*&quot;) tran.AddCondition(Condition.HashEqual(redisKey, ETAG_KEY, data.ETag)); tran.HashSetAsync(redisKey, new HashEntry[] { new HashEntry(ETAG_KEY, DateTime.UtcNow.Ticks.ToString()), new HashEntry(DATA_KEY, serializedData) }); bool committed = await tran.ExecuteAsync(); if (!committed) throw new ConcurrencyException(&quot;Inconsistent SaveAsync based on ETag!&quot;); } . The critical part here is to maintain optimistic concurrency control for storing the data. This situation arises most commonly when the bot is in process of handling a user message and the user sends another message. The second message may end up in different bot instance which would start processing with older bot state. We will maintain optimistic concurrency using ETag property of BotData. ETag property will be set to DateTime.UtcNow.Ticks. If it differs while saving the new state, we will throw an exception. To achieve this we will use Transactions in Redis. Note that transactions in Redis works differently than your typical RDBMS. It gets more complicated due to how connection multiplexing is performed by StackExchange Redis client. An excellent explanation of this is given here. In our code, we add a “Condition” for the transaction to be successful. If the condition fails, the entire transaction is void and committed will be false. . The LoadAsync method is pretty simple. We return null if there is no value for a particular key (first time scenario), otherwise we return BotData. . public async Task&lt;BotData&gt; LoadAsync(BotDataKey key, BotStoreType botStoreType, CancellationToken cancellationToken) { Connect(); var database = _connection.GetDatabase(_options.Database); var redisKey = GetKey(key, botStoreType); var result = await database.HashGetAllAsync(redisKey); if (result == null || result.Count() == 0) { return null; } var botData = new BotData(); botData.ETag = result.Where(t =&gt; t.Name.Equals(ETAG_KEY)).FirstOrDefault().Value; botData.Data = Deserialize((byte[])result.Where(t =&gt; t.Name.Equals(DATA_KEY)).FirstOrDefault().Value); return botData; } . Integrating with Bot . To start using Redis Store instead of Bot State Service, we just need to override the existing Autofac registration of IBotDataStore with new one. The Bot Builder SDK uses CachingBotDataStore implementation for IBotDataStore which is just a decorator for ConnectorStore. We will replace ConnectorStore with RedisStore. Just call the RegisterBotDependencies in Application_Start() in Global.asax.cs and it will work. . private void RegisterBotDependencies() { var builder = new ContainerBuilder(); RedisStoreOptions redisOptions = new RedisStoreOptions() { Configuration = &quot;localhost&quot; }; builder.Register(c =&gt; new RedisStore(redisOptions)) .As&lt;RedisStore&gt;() .SingleInstance(); builder.Register(c =&gt; new CachingBotDataStore(c.Resolve&lt;RedisStore&gt;(), CachingBotDataStoreConsistencyPolicy.ETagBasedConsistency)) .As&lt;IBotDataStore&lt;BotData&gt;&gt;() .AsSelf() .InstancePerLifetimeScope(); builder.Update(Conversation.Container); DependencyResolver.SetResolver(new AutofacDependencyResolver(Conversation.Container)); } . Wrapping Up . As mentioned before, the other way to achieve the same is by creating a REST Api and implementing IBotState. However in essence, the way we do this would remain same. Microsoft Bot Builder is highly flexible when it comes to extending it with custom logics. Again the source code is at my github repo. I have also published it as a nuget package. . I hope you liked it. Post a comment if you have any question. .",
            "url": "https://ankitbko.github.io/blog/2016/10/Microsoft-Bot-Framework-Use-Redis-to-store-conversation-state/",
            "relUrl": "/2016/10/Microsoft-Bot-Framework-Use-Redis-to-store-conversation-state/",
            "date": " • Oct 17, 2016"
        }
        
    
  
    
        ,"post9": {
            "title": "Hidden Gem in Microsoft Bot Framework - QnA Maker",
            "content": "One of the most common use cases in Bot space is to create a bot to answer FAQ. And almost all businesses has an FAQ either in form of documents or web pages. Now it is not at all difficult to create a bot to answer simple questions. In fact there are hardly any context to maintain and most of the conversations are very shallow which makes it a very repetitive and quite boring task. All the FAQs are mostly same, well they are just list of questions and answers. Only if there would have been a way to upload this “knowledge” and create an NLP model based on the questions without us having to write any code. . Enter QnAMaker, one of the least documented and almost non-existent service offered by Microsoft. QnAMaker allows us to upload a FAQ document or just give a link to a FAQ page and it will create an NLP model and expose an endpoint to query. . QnA Maker . QnA Maker is provided as a service which is part of Microsoft Bot Framework. It is really hard to find as there are no external links to the page and absolutely no documentation. The only way to reach it by directly going to the sub-domain qnamaker.botframework.com. . . Once on the page, we can create a new service by clicking “Create a new QnA service”. We will be redirected a page with list of steps to create QnA Service. We will create a QnA service to answer questions about Bot Framework itself. The Bot Framework FAQ is available at it’s documentation. . . Name your service: The first step is to give a name to our service. Let’s name it “botframework”. | FAQ URL: This is one of the three steps to seed the QnA Maker with questions and answers. QnA Maker provides sample sites as how the FAQ page should look like. However it is not limited to the same format. Most of the FAQ pages, which clearly separates questions and answers, works with QnA Maker. Here we will provide “https://docs.botframework.com/en-us/faq/” as single line entry. | Question and Answer Pairs: This is the second way to provide questions and answers. The format is question:answer one per each line. We will leave this field blank. | Upload files: The third and last way to seed data is to upload a file(doc, docx, txt, tsv or pdf) containing questions and answers in a sequence. This too we will leave as it is. | . Click on “Extract” and wait a while. The QnA maker will extract all the questions and create an NLP model (probably LUIS). It would also show how many question-answer pair were extracted just above “Next” button. Clicking on it will download a tsv file with question-answer pair. . . Click on “Next” to go to fifth and last step which is to test and re-train our model. . . This window has three parts. In the middle is a chat bot embedded as an iframe. Enter a question from FAQ in the chat bot and it should respond back with the answer. The right side of chat bot allows us to enter alternate phrasings to a question. This will further reinforce the model and make it better at classifying the questions correctly. As you can see in the image, I have added another phrase “what is release timeline for bot framework” to this question. The left side can be used to choose a correct response in case the bot answers incorrectly. The QnA Maker will automatically display answers related to the question. When asked “when the bot framework be publicly available”, it returned wrong response. I selected the correct response from the list of responses which appeared on the left. Once satisfied with the responses, click “Re-Train” to train the model again. . Click on “Publish” to make the service available over an URL. . . Using the “Service URL” we can test the service to see what it returns. . . The question is supplied in the query string and the service returns a json containing an “answer” and a confidence “score”. The score tells us how confident is the QnA Maker that it has responded back with correct answer to the question. The score varies from 0-100, higher the number more confident it is. . Conclusion . QnA Maker is a powerful tool to quickly create an FAQ bot. However there are couple of limitations. First it does not expose the underlying NLP model. Most likely it uses LUIS internally and it creates an intent for each question. We do not get access to the LUIS or the trained model. Second it is very less documented and there are almost no mention of it anywhere. Which begs the question on how long will it be supported and whether there are any technical limitations and cost to the usage of the service. Overall this is a fine piece of work which lets us create a bot in minutes. . I hope this article was helpful. If you have any questions, please post a comment below. .",
            "url": "https://ankitbko.github.io/blog/2016/10/Hidden-Gem-in-Microsoft-Bot-Framework-QnA-Maker/",
            "relUrl": "/2016/10/Hidden-Gem-in-Microsoft-Bot-Framework-QnA-Maker/",
            "date": " • Oct 3, 2016"
        }
        
    
  
    
        ,"post10": {
            "title": "Chatbot using Microsoft Bot Framework - Part 4",
            "content": "I finally got time to write another post and with this I will finish of my blog series on Microsoft Bot Framework. In my last post, we saw how to use other features of LUIS such as entities and phrase list. We also saw how to nest Dialogs and how to maintain context between Dialogs. If you are new to Microsoft Bot Framework, I highly recommend you go through part 1, part 2 and part 3 of my blog series before continuing. As usual, you can find source code at my github repo. . In this post, we will delve into how FormFlow works and where it can be used. We will add another feature to our bot which will let user to send feedback to me through chat. . Adding Feedback Intent . We first enhance LUIS by adding another intent called “Feedback”. I have trained LUIS for sentences such as “I want to send a feedback”, I will not go into details as I have already covered LUIS aspects in my previous posts. There are no entities to return so we just leave it to this. . . FormFlow . Till now we have only created conversations which are very shallow. In other words, it is a simple QA scenario where conversation does not flow deep and their are no context to maintain. However, there are many scenarios where we would need to take a more guided approach, where we may require multiple inputs from user and bot may take different path based on previous inputs. In short, we will need to create a state machine. A good example is ordering a pizza. We will need to ask a lot of questions such as size, crust, toppings, etc. and we will need to maintain them in the context. We will also need to provide a way for user to change previously entered data and we must only complete order once we have all the information with us. All of this would require managing a lot of state and workflow. This is where FormFlow comes in. . FormFlow sacrifices some of the flexibility of Dialogs to provide an easy way to achieve all the above. FormFlow itself is derived from IDialog so it can be nested within another dialog. . The basic idea behind FormFlow is forms i.e. collection of fields. Think of it as filling a form in any website. To order a pizza online, you would go to your favorite pizza restaurant’s website, fill out a form with details such as type of pizza, crust, size etc, put down delivery address and then order it. At any point before placing the order, you can revisit and change any aspect of pizza. . To accomplish the same using FormFlow, we start with creating a class and adding public fields or properties. Each public field and property corresponds to a field in the form. So the user will be asked to input values for each field before completing the form. The way FormFlow achieves this is by creating a state machine in background and maintaining the transition between states. It also allows user to change any previously entered value for any field and view the current status of the form. You can read more about FormFlow in the docs here. . In our scenario of implementing feedback functionality, before allowing user to send a feedback, we will ask him to enter his name and contact info. Only when we have both the information, would we allow him to send a feedback message. To achieve this, we first create a class called FeedbackForm and properties for Name, Contact and Feedback. . public class FeedbackForm { [Prompt(new string[] { &quot;What is your name?&quot; })] public string Name { get; set; } [Prompt(&quot;How can Ankit contact you? You can enter either your email id or twitter handle (@something)&quot;)] public string Contact { get; set; } [Prompt(&quot;What&#39;s your feedback?&quot;)] public string Feedback { get; set; } public static IForm&lt;FeedbackForm&gt; BuildForm() { return new FormBuilder&lt;FeedbackForm&gt;() .Field(nameof(Contact), validate: ValidateContactInformation) .Field(nameof(Feedback), active: FeedbackEnabled) .AddRemainingFields() .Build(); } } . The Prompt attribute on top of fields allow us to specify what message would be shown to the user for asking him to enter value for the respective fields. Do note that FormFlow only accepts .NET primitive types, enum and List&lt;enum&gt; as Type for properties or fields. The BuildForm static method returns an IForm&lt;&gt; which would be used by FormDialog to build forms later. I will explain each line of the method - . new FormBuilder&lt;FeedbackForm&gt;(): Create a new FormBuilder of type FeedbackForm. FormBuilder has fluent api to help us build it. | .Field(nameof(Contact), validate: ValidateContactInformation): Add the property Contact to the form and set a delegate to validate the input. ValidateContactInformation delegate will be called whenever user inputs for this field. | .Field(nameof(Feedback), active: FeedbackEnabled): Add the property Feedback to the form and assign an ActiveDelegate to it. This means that this field will be visible only when ActiveDelegate returns true. | .AddRemainingFields(): Add any remaining valid public fields and properties to the form. In this case Name. | .Build();: Build the form and return an IForm&lt;FeedbackForm&gt;. | . The ValidateContactInformation delegate validates that the input is either a valid email address or starts with ‘@’ to signify twitter handle. . private static Task&lt;ValidateResult&gt; ValidateContactInformation(FeedbackForm state, object response) { var result = new ValidateResult(); string contactInfo = string.Empty; if(GetTwitterHandle((string)response, out contactInfo) || GetEmailAddress((string)response, out contactInfo)) { result.IsValid = true; result.Value = contactInfo; } else { result.IsValid = false; result.Feedback = &quot;You did not enter valid email address or twitter handle. Make sure twitter handle starts with @.&quot;; } return Task.FromResult(result); } . The ValidateAsyncDelegate must return a ValidateResult object whose property IsValid should be set appropriately. If IsValid is set to true, FormFlow will assign the field to the value in Value property. This gives us chance to transform the user input before assigning it to the form. If the IsValid is set to false, text in Feedback field will be displayed to the user. This allows us to notify user why validation failed and give clear instructions as to what to do next. If the validation fails, the FormFlow will ask user to enter the value again. . Each field can be controlled as to whether it is available to be filled or not by ActiveDelegate. The ActiveDelegate returns a bool, if it is true the field is available to be filled by the user else it will be not be shown. . private static bool FeedbackEnabled(FeedbackForm state) =&gt; !string.IsNullOrWhiteSpace(state.Contact) &amp;&amp; !string.IsNullOrWhiteSpace(state.Name); . This completes creation of our form, next we will add an intent handler. . Add handler for Feedback intent . [LuisIntent(&quot;Feedback&quot;)] public async Task Feedback(IDialogContext context, LuisResult result) { try { await context.PostAsync(&quot;That&#39;s great. You will need to provide few details about yourself before giving feedback.&quot;); var feedbackForm = new FormDialog&lt;FeedbackForm&gt;(new FeedbackForm(), FeedbackForm.BuildForm, FormOptions.PromptInStart); context.Call(feedbackForm, FeedbackFormComplete); } catch (Exception) { await context.PostAsync(&quot;Something really bad happened. You can try again later meanwhile I&#39;ll check what went wrong.&quot;); context.Wait(MessageReceived); } } . Here we create a new FormDialog object by passing the new instance of FeedbackForm and BuildFormDelegate which we have defined above. The BuildFormDelegate will be used by FormFlow to build the form. FormOptions.PromptInStart tells the bot to prompt user for the first field to be filled as soon as the dialog starts. FormDialog has another optional parameter which takes IEnumerable&lt;EntityRecommendation&gt;. This can be used to pass the entities returned by the LUIS and FormFlow will pre-populate the form and will not ask the user to fill in those fields. . Next we use context.Call to push our FormDialog to top of the DialogStack. Unlike context.Forward, context.Call will not pass the current message to the Dialog. Instead the next message from the user will be routed to the child dialog. . FeedbackFormComplete is called once all the fields in the our form is successfully filled and the form completes. I also get the completed form passed in the result parameter. . private async Task FeedbackFormComplete(IDialogContext context, IAwaitable&lt;FeedbackForm&gt; result) { try { var feedback = await result; string message = GenerateEmailMessage(feedback); var success = await EmailSender.SendEmail(recipientEmail, senderEmail, $&quot;Email from {feedback.Name}&quot;, message); if (!success) await context.PostAsync(&quot;I was not able to send your message. Something went wrong.&quot;); else { await context.PostAsync(&quot;Thanks for the feedback.&quot;); await context.PostAsync(&quot;What else would you like to do?&quot;); } } catch (FormCanceledException) { await context.PostAsync(&quot;Don&#39;t want to send feedback? That&#39;s ok. You can drop a comment below.&quot;); } catch (Exception) { await context.PostAsync(&quot;Something really bad happened. You can try again later meanwhile I&#39;ll check what went wrong.&quot;); } finally { context.Wait(MessageReceived); } } . I use SendGrid to send a mail to myself with the feedback message which I get from completed form. The interesting part here is the catch block for FormCanceledException. FormCanceledException is thrown when user quits or cancels the form. This is another feature of FormFlow. User can quit the form anytime by typing ‘quit’ or ‘bye’. Along with this, user can type ‘Help’ anytime to view all the available options if he feels stuck anywhere and ‘Status’ to view the current state of form. These commands are configurable and list of them is available in ‘Help’ menu. . . Wrapping up . This is it. We have created a bot and in the process I have explained fundamentals of bots and Microsoft Bot Framework. But in no way have I touched upon every feature of Bot Framework. There are many other features such as Scorable, BotState, IPostToBot, IBotToUser etc. which are very useful and you should definitely explore. Voice calling through Skype is an upcoming feature which can be integrated to the bot. There are many other cognitive services which can be integrated with bots to make it more smarter. Microsoft Bot Framework is a powerful and feature rich platform to build bots. The open source community around it is great and developers are quick to respond to any issues. . I will write more about above things in future. If you have any specific topic which you would like me to write about, drop a comment or send a feedback through bot :). .",
            "url": "https://ankitbko.github.io/blog/2016/09/ChatBot-using-Microsoft-Bot-Framework-Part-4/",
            "relUrl": "/2016/09/ChatBot-using-Microsoft-Bot-Framework-Part-4/",
            "date": " • Sep 23, 2016"
        }
        
    
  
    
        ,"post11": {
            "title": "Chatbot using Microsoft Bot Framework - Part 3",
            "content": "This is third part in my series on Chat Bots. In part one I discussed how chat bots worked and basics of Microsoft Bot Framework. In part two I talked about LUIS and how it provides intelligence to our bot. I also built a simple bot using LUIS in background which answers questions of who I am. In this post, we will add more features to our bot, and see how LUIS detects entities along with intent. Before we proceed, I would mention that I have added application insight to my bot. As usual, head over to my repo to get the source code. . Since my last post, I have added application insight to the code so that I can view telemetry in Azure. Also I have updated my BotBuilder nuget package to v3.2. . The next feature will let us ask the bot to fetch us articles for a particular topic. More specifically, we can ask bot to search my blog on a particular topic and return us the list posts associated with topic. An example query can be - “show me posts related to docker” should return all the articles having “docker” tag. . Enhancing LUIS . To achieve this, not only will LUIS have to classify the sentence to an intent but also return us entities from the sentence which will act as search terms eg. “docker”. First, we will create a new entity and call it “Tag”. Next, we will add another intent to LUIS named “BlogSearch”. This time when training LUIS for this intent, we can select any word or group of words from the utterance and assign it to our entity as shown below. Just click on the word to assign it to an entity and it should get highlighted with a color. . . We will train the system with few more utterances. However we quickly see that LUIS is able to recognize entities already trained, but is having hard time with new words such as “Microsoft Bot Framework” as we see in the image below. . . This is happening because . We have not trained our system extensively. . | LUIS has no way to know that “Microsoft Bot Framework” can be classified as a “Tag” entity since all our previous entities are not even similar to this one. . | We can quickly get around it by utilizing another feature of LUIS called “Phrase List Features”. It allow us to specify comma separated words which LUIS can use interchangeably when detecting an entity. In our case we will provide a list of tags from my blog. We will see that LUIS is now able to detect entities from phrase list we created. . . This is an advantage we have with LUIS as it uses Conditional Random Fields(CRF) for entity detection. CRF, unlike some other algorithms, takes neighboring words into account when detecting entities. That is, words preceding and succeeding are important when detecting an entity. With enough training, this allows LUIS to detect words as entities which were not trained before, just by looking at their neighboring words. Once we have sufficiently trained model, let’s go and make changes to the code. . . As before, we will add another method and decorate it with [LuisIntent(&quot;BlogSearch&quot;)]. I have written a class which will get my blog posts and get all the articles I have written along with it’s associated tags. Then I filter the posts based on the “Tag” entity detected by LUIS. My intent handler is pretty straightforward. I get the list of entities detected by LUIS in LuisResult. If I find an entity of type “Tag”, I filter the posts comparing its associated tags with the LUIS detected entity. I then pass the list of filtered posts and tag to a private method which formats the response and returns back a string. . [LuisIntent(&quot;BlogSearch&quot;)] public async Task BlogSearch(IDialogContext context, LuisResult result) { string tag = string.Empty; string replyText = string.Empty; List&lt;Post&gt; posts = new List&lt;Post&gt;(); try { if (result.Entities.Count &gt; 0) { tag = result.Entities.FirstOrDefault(e =&gt; e.Type == &quot;Tag&quot;).Entity; } if (!string.IsNullOrWhiteSpace(tag)) { var bs = new BlogSearch(); posts = bs.GetPostsWithTag(tag); } replyText = GenerateResponseForBlogSearch(posts, tag); await context.PostAsync(replyText); } catch (Exception) { await context.PostAsync(&quot;Something really bad happened. You can try again later meanwhile I&#39;ll check what went wrong.&quot;); } finally { context.Wait(MessageReceived); } } . Fireup emulator to check if everything is working as expected. We just added a new feature to our bot with few lines of code. Sweet!!! . . Greetings Problem . A new user would most likely start conversation with “Hi” or similar greetings. Currently our bot responds with “I’m sorry. I didn’t understand you.” for any greetings. Well it is not a very good response to give when someone says “Hi”. Let us do something about it. One way would be to create a “Greetings” intent in LUIS and train it to recognize “hi”, “hello” etc. This is what I have been doing till now. However recently I found an excellent blog post by Garry Petty. He created an implementation of IDialog to match incoming message to list of strings through regular expression and dispatch it to a handler. So let us go ahead and take his help to solve our little problem here. This approach would also allow me to demonstrate how we can create and use child dialog. . First add reference to his nuget package BestMatchDialog. Next we create GreetingsDialog and derive it from BestMatchDialog&lt;object&gt;. . [Serializable] public class GreetingsDialog: BestMatchDialog&lt;object&gt; { [BestMatch(new string[] { &quot;Hi&quot;, &quot;Hi There&quot;, &quot;Hello there&quot;, &quot;Hey&quot;, &quot;Hello&quot;, &quot;Hey there&quot;, &quot;Greetings&quot;, &quot;Good morning&quot;, &quot;Good afternoon&quot;, &quot;Good evening&quot;, &quot;Good day&quot; }, threshold: 0.5, ignoreCase: false, ignoreNonAlphaNumericCharacters: false)] public async Task WelcomeGreeting(IDialogContext context, string messageText) { await context.PostAsync(&quot;Hello there. How can I help you?&quot;); context.Done(true); } [BestMatch(new string[] { &quot;bye&quot;, &quot;bye bye&quot;, &quot;got to go&quot;, &quot;see you later&quot;, &quot;laters&quot;, &quot;adios&quot; })] public async Task FarewellGreeting(IDialogContext context, string messageText) { await context.PostAsync(&quot;Bye. Have a good day.&quot;); context.Done(true); } public override async Task NoMatchHandler(IDialogContext context, string messageText) { context.Done(false); } } . In principle BestMatchDialog works in same way as LuisDialog. It would check the message against each of the strings in BestMatch attribute and calculate a score. Then the handler for the highest score is executed passing in the required context and message. If no handler is found with score above the threshold, NoMatchHandler is called. Note in each handler we call Context.Done instead of Context.Wait. This is because we don’t want next message to arrive in this Dialog. Instead this Dialog should finish and return back to it’s parent Dialog which is MeBotLuisDialog. Context.Done will complete the current Dialog, pop it out of stack and return the result back to parent Dialog. We return True if we handled the greetings otherwise False. We then change the None intent handler in MeBotLuisDialog to one below - . [LuisIntent(&quot;None&quot;)] [LuisIntent(&quot;&quot;)] public async Task None(IDialogContext context, IAwaitable&lt;IMessageActivity&gt; message, LuisResult result) { var cts = new CancellationTokenSource(); await context.Forward(new GreetingsDialog(), GreetingDialogDone, await message, cts.Token); } private async Task GreetingDialogDone(IDialogContext context, IAwaitable&lt;bool&gt; result) { var success = await result; if(!success) await context.PostAsync(&quot;I&#39;m sorry. I didn&#39;t understand you.&quot;); context.Wait(MessageReceived); } . In None intent handler we call context.Forward which will create a child dialog of type GreetingsDialog, push it to top of stack and call it’s StartAsync method passing message as argument. GreetingDialogDone is called once the child dialog completes i.e. child dialog calls context.Done. . Well this solves our little problem of handling greetings. One last thing we need to do. There should be a way for user to ask for help. We will create another LUIS intent called “Help” and train it with few utterances such as “need help”. This will allow user flexibility to ask for help anytime. From our bot, we would return the functionality that our bot can do similar to what we return for ConversationUpdate ActivityType. . In this article we enhanced our bot to search through my blog and filter articles based on associated tags. We also created a child dialog to handle greetings and a way for user to get help. In next post, we will get into FormFlow and make our bot bit more conversational. Till then, if you have any questions or feedback post a comment. .",
            "url": "https://ankitbko.github.io/blog/2016/08/ChatBot-using-Microsoft-Bot-Framework-Part-3/",
            "relUrl": "/2016/08/ChatBot-using-Microsoft-Bot-Framework-Part-3/",
            "date": " • Aug 29, 2016"
        }
        
    
  
    
        ,"post12": {
            "title": "Chatbot using Microsoft Bot Framework - Part 2",
            "content": "This is second post in the series of building a chat bot. If you haven’t gone through Part 1, you can find it here. It sets the context and talks about basics of Microsoft Bot Framework. The source code for bot can be found at my github repo. . In this article, we will add first feature to our bot which is to answer question about me. The bot should answer questions such as “Who is Ankit”, “Who is author of this blog”, etc. As we saw previously, the bot in itself is dumb. To understand such questions we will need to take help from LUIS. . Language Understanding and Intelligence Service . LUIS Natural Language Processing Service is one of the cognitive services by Microsoft. In general, there are two things LUIS can possibly do - . Intent Recognition: Whenever a user sends a message to our bot, he has an intent. For instance if user types “I want to order a pizza” his intent is “OrderPizza”, “I want to rent a car” intent is “RentCar” etc. Given a sentence, LUIS will to classify the sentence into one of the trained intents and give us probability score for each intent. The way we achieve this is by defining the intents and training the LUIS with some sentences (called utterances) by manually classifying them. This type of learning is called Supervised Learning and the algorithm which LUIS uses to classify is Logistic Regression. . | Entity Detection: In a sentence, we might be interested in a word or group of words. For example in “I want to order a pepperoni pizza” text “pepperoni” is the word we are interested in. Another example, “Rent a car from London airport tomorrow” - “London airport” and “Tomorrow” are the words which are contextually important to us. LUIS can help us by recognizing these words (called entities) from the sentence. LUIS uses Conditional Random Fields (CRF) algorithm to detect entities, which falls under Supervised Learning. Therefore this is again achieved by training LUIS with some words manually before it can start detecting. . | . A great tutorial explaining these in detail is present at Luis Help. It is a short tutorial which I recommend you go through it later for better understanding. . Create a LUIS App . Go over to luis.ai and create a new App. By default, we get one intent called None. Any utterances which we feel does not classify into any other intent in our app should be trained under None. Training None is important, I have seen many people not training it sufficiently. . Training Luis . Let us create a new intent named AboutMe. While creating intent we have to enter an example sentence that would be classified to it. Enter “Who is Ankit” and created the intent. Click on Submit to classify the sentence to the intent. We can add more utterances by entering it into input box and classifying it to the intent as shown below. Add some utterances for None intent too. . . Train the LUIS by clicking on “Train” button on bottom left. Next, publish the app so that it is available via HTTP. We can test the app and see what result LUIS returns. LUIS will classify the query into each intent and return us probability score for each. . . I have exported the LUIS app and added the JSON to the solution. . . LuisDialog . Once we have created the LUIS app, next step is to integrate it with our bot. Fortunately Bot Builder SDK provides us an easy way to integrate with LUIS. Enter LuisDialog. It derives from IDialog and does the low level plumbing work of interfacing with LUIS and deserializing the result back to LuisResult. Let’s go ahead and create a new class called MeBotLuisDialog and derive it from LuisDialog. Next we add the following method to the class - . [LuisIntent(&quot;None&quot;)] public async Task None(IDialogContext context, LuisResult result) { await context.PostAsync(&quot;I&#39;m sorry. I didn&#39;t understand you.&quot;); context.Wait(MessageReceived); } . Let me explain each line in above - . [LuisIntent(&quot;None&quot;)]: Apart from calling LUIS API, LuisDialog also takes the result returned by LUIS, calculates the best intent based on probability score and calls the corresponding method defined in our dialog decorated with LuisIntent attribute matching the intent name passed as argument with the best intent detected. So, if LUIS classifies a sentence and scores it highest to “None” intent, our above method will get called automatically. . | public async Task None(IDialogContext context, LuisResult result): Our method accepts two parameters, first is of type IDialogContext which as discussed before contains the stack of active dialog. It also has helper methods to send reply back to the user which we do in the next line. The second parameter is the result returned by the LUIS which is deserialized as LuisResult. . | await context.PostAsync(&quot;I&#39;m sorry. I didn&#39;t understand you.&quot;): We use the the Dialog Context to send a reply back to the user. Since this method is called when our bot did not understand the user’s intent, we return back a friendly response. Later we will modify it to return more detailed response. . | context.Wait(MessageReceived): This is important. Before exiting from dialog, we must mention which method will be called when the next message arrives. If you forget it, you will get a very ambiguous runtime error something in the line of “need ‘Wait’ have ‘Done’”. We again use dialog context to specify it. MessageReceived method is defined in LuisDialog class and is the same method which calls the LUIS endpoint, calculates the best intent from the result and calls the relevant method for the intent. . | . So in short, we reply back to user saying that we didn’t understand and specify that next message should also be sent to the LUIS to understand the user intent. Let us add method to handle “AboutMe” intent. . [LuisIntent(&quot;AboutMe&quot;)] public async Task AboutMe(IDialogContext context, LuisResult result) { await context.PostAsync(@&quot;Ankit is a Software Engineer currently working in Microsoft Center of Excellence team at Mindtree. He started his professional career in 2013 after completing his graduation as Bachelor in Computer Science.&quot;); await context.PostAsync(@&quot;He is a technology enthusiast and loves to dig in emerging technologies. Most of his working hours are spent on creating architecture, evaluating upcoming products and developing frameworks.&quot;); context.Wait(MessageReceived); } . This is also similar to the “None” intent handler. Instead of sending only one response, I send two since the sentences are quite big. The response is quire simple but let us keep it this way. Decorate the MeBotLuisDialog class with [LuisModel(&quot;modelid&quot;, &quot;subskey&quot;)] with correct LUIS ModelId and Subscription Key. You can get the keys from published URL of your LUIS app. There is just one more place that we need to change before we can test our bot that is in MessageController. Replace the entire If section of the method with the one below - . if (activity.Type == ActivityTypes.Message) { await Conversation.SendAsync(activity, () =&gt; new MeBotLuisDialog()); } . Done. Press F5 to run the bot. Open the emulator and send a text to check if the bot is replying properly. . . One last feature to add. When a user add/open our bot for the first time, it is good practice to show a welcome text having information about what our bot can do and how to interact with it. Let us add a small help text and send it to the user when he first interacts with our bot. The place to do it is in ActivityTypes.ConversationUpdate block in MessageController. Microsoft Bot Framework supports Markdown, which we can utilize to give a richer experience to our user. I have added the relevant welcome text as below. . else if (message.Type == ActivityTypes.ConversationUpdate) { // Handle conversation state changes, like members being added and removed // Use Activity.MembersAdded and Activity.MembersRemoved and Activity.Action for info // Not available in all channels string replyMessage = string.Empty; replyMessage += $&quot;Hi there n n&quot;; replyMessage += $&quot;I am MeBot. Designed to answer questions about this blog. n&quot;; replyMessage += $&quot;Currently I have following features n&quot;; replyMessage += $&quot;* Ask question about the author of this blog: Try &#39;Who is Ankit&#39; n n&quot;; replyMessage += $&quot;I will get more intelligent in future.&quot;; return message.CreateReply(replyMessage); } . Registering the bot . Before registering, we need to publish our bot and make it accessible from internet over HTTPS. Once done, head over to bot registration portal. An excellent article on how to register the bot is here. Once registered, update the web.config with correct id and secret and publish the bot again. . Registering the bot will auto-configure it with skype. But let us go a step further and configure the Web Chat Channel. Configuring web chat gives us an iframe which we can include in our web site. I have added the iframe to my blog and the bot appears at the bottom right corner. This is so cool. . I have tagged the code till this point as part2 in my repo. In next post we will add more features to our bot. Meanwhile if you have any questions or feedbacks, post a comment below. .",
            "url": "https://ankitbko.github.io/blog/2016/08/ChatBot-using-Microsoft-Bot-Framework-Part-2/",
            "relUrl": "/2016/08/ChatBot-using-Microsoft-Bot-Framework-Part-2/",
            "date": " • Aug 23, 2016"
        }
        
    
  
    
        ,"post13": {
            "title": "Chatbot using Microsoft Bot Framework - Part 1",
            "content": "There is a lot of buzz in market regarding Chatbots. Microsoft, in Build 2016, showcased their own bot framework and released it on Github. So finally we had an open source and free platform to create our own bots. . In this and next few articles that will follow, I’ll talk about Microsoft Bot Framework and build a bot from scratch. Instead of explaining each and every feature of Bot Framework with code snippets, which would lead to a boring post, we will embark into a journey of building a silly bot to a bot that does something useful. On the way, I’ll explain some of the features of Bot SDK, and use it add more capabilities to the bot. Also I would link a lot to the official documentation wherever a deeper understanding is required. Documentation is pretty neat and it makes no sense to explain the detail here also, why to reinvent the wheel? However this is a new learning for me too, so if you find a better way than mine to do the same thing then comment below. . Microsoft Bot Framework . Microsoft Bot Framework consists of 3 parts - . Bot Builder SDK: Bot Builder SDK is open source and provides us with features to model our conversation, state management, rich attachments etc. SDK is available in C# and Nodejs. | Bot Connector: Bot connector acts as an adapter between our bot and numerous channels that it supports. It also has other features such as state management, storage service, message routing etc. | Bot Directory: Bot Directory is a public directory for published bots. Bots are reviewed before being listed and publicly available on Bot Directory. | . Excellent overview of individual pieces are available at their official documentation. . Note: While writing this article, Microsoft Bot Framework is in Preview. . Bot Framework Basics . Before we continue, let me explain basics of how a bot works. When we will create a new project using the bot template, we will see the bot is nothing but a simple Web Api Project. In fact, that is all the bot is, a dumb Web API service. This Web API will be hosted and will be registered with Microsoft Bot Connector. The Bot Connector acts as an adapter between our web service and different Channels. Channels such as skype, facebook messenger, etc are platforms which our user will use to chat with the bots. . I have put up a small diagram below showing how each component interacts. In short, a user uses a channel to send message to our bot. The message is routed through the Microsoft Bot Connector, which sends a POST request to our Bot Service. The POST request’s body will contain the original text typed by the user along with other meta-data which we will see later. Upon receiving the request, our bot can take any action such as querying database or replying back to the user. In itself, our bot is pretty dumb. The intelligence comes when we integrate with one of the Cognitive Services, in this case Language Understanding and Intelligence Service(LUIS). LUIS, Natural Language Processing as a Service is one of the Cognitive Services provided by Microsoft. We will see later how LUIS works. Going back to diagram, upon receiving the message from user, our bot may send the message text to LUIS to understand what user is saying and then reply back appropriately. . . We will get into more details later. For now, let’s get started . What are we building? . After a lot of thinking, I could just come up with a lousy idea of a bot that would answer questions about myself and this blog. So the bot will - . Answer questions about me. Essentially replacing About Me section. | Give results of recent posts I have written. | Allow users to send feedback to me. | . As you will see later, I am very bad at naming. So in lack of any good name, let’s call this bot MeBot (duh!). Source code of the bot can be found here. I will use C# to develop the bot as I am more familiar with it. . Setup Project . We will add features incrementally to the bot and over multiple blog posts. But first step is to create a project using Bot Application Template. You can download the Visual Studio Template here. Next, update the nuget package of Microsoft.Bot.Builder to latest version. Bot Template is not updated as frequently as the SDK, so always check and update the SDK to newer version when creating a new project from the template. While you are at it, also download and install Bot Framework Emulator from the above link. The emulator will help us to test our bot locally while development. . . Bot Builder SDK Basics . There are three critical pieces in SDK that we need to understand before proceeding. . Activity: Activity is the JSON data (POST Body) that we send to and receive from the Bot Connector. You can view Activity.cs class to see all the data which are reviewed and sent. The one which interests us most is Text property which will contain the message which user typed. You can get to know more about Activity in official documentation . | Dialog: Dialogs are building blocks of the bot. Dialogs model a conversation between user and the bot. It is a serializable class which has the state and the methods through which the interactions are managed. Dialogs are created by implementing IDialog interface. Dialogs can also be composed with other dialogs, making it reusable. . | Dialog Context: Dialog Context maintains a stack of active dialogs. When the bot replies, it serializes the Dialog stack and sends it to the Bot Connector along with the Activity in the POST Body. The Bot Connector will store the stack internally. When the user sends another message, the Bot Connector will attach the Dialog Stack for the particular conversation and send it to our bot. The Bot Builder, upon receiving the Dialog stack, deserializes it, pops the top most dialog and executes the next method. . | . You can read more details about Dialogs here. If any of it didn’t make sense don’t worry, we will see them in action soon. . Back to our project . Open the MessageController.cs and you will find single POST method which accepts Activity object. The first line if (activity.Type == ActivityTypes.Message) checks if the Activity is of type Message. Message ActivityType represents communication between a Bot &lt;–&gt; User. There are other ActivityType which are present in HandleSystemMessage(Activity message) method. The comments there are self explanatory and more information on ActivityTypes are mentioned in the documentation. . The If block handles the case when user has sent a text message to the bot. The bot will get the incoming text, count the length of the message, reply it back to the user. Note how the reply is created and sent to the Bot Connector. The reply is sent as a separate HTTP request rather than inline to current one. The Else block handles special ActivityType which we will ignore for the moment. . Run the project . The default template creates a simple bot which echoes back number of character user typed. Before proceeding let us check if everything is working. Press F5 and run the bot in IIS Express. Open the Bot Emulator and change the Bot Url to hosted one and send any message. If everything is working, the bot should reply back the number of characters you entered which we see on the left window. On the right we see the JSON request and response for the message. This is what gets deserialized into Activity object. . . Everything works fine. Good. . I will wrap up here. In the next post we will implement first feature i.e. answering questions about who I am. To do this we will need to understand how LUIS works and integrate it with our bot. . Meanwhile if you have any questions, post it in the comments. .",
            "url": "https://ankitbko.github.io/blog/2016/08/ChatBot-using-Microsoft-Bot-Framework-Part-1/",
            "relUrl": "/2016/08/ChatBot-using-Microsoft-Bot-Framework-Part-1/",
            "date": " • Aug 22, 2016"
        }
        
    
  
    
        ,"post14": {
            "title": "IdentityServer4 on Docker (ASP.NET Core 1.0)",
            "content": "In my previous article I showed how to run Identity Server 4 on Docker targeting ASP.NET Core RC1. In June .NET Core 1.0 and ASP.NET Core 1.0 was released which had some breaking changes. In this post I’ll show what changes are required to run Identity Server 4 targeting ASP.NET Core 1.0 on Docker. I will take up from where we left off on my previous post, so check that out before continuing. . What changed in ASP.NET Core 1.0? . There are some breaking changes in ASP.NET Core 1.0. In this guide I only focus on changes needed to run IdSrv4 on docker. For complete detail on how to migrate an application to ASP.NET Core 1.0 from RC1, check out official guide. . The first major change you’ll notice is that dnx is gone instead .NET Core 1.0 features new dotnet CLI. This change would affect how we build and publish our application and Dockerfile. | Another change is that dnx commands are gone. This directly affects how we host our applications. | There are also small changes in project.json and Program.cs which are not of great interest to us for this guide. | Apart from these, Microsoft has also released a new docker base image for .NET Core 1.0 applications called microsoft/dotnet:1.0.0-core. We will use this to create our docker image. | . I have changed my sample application to target ASP.NET Core 1.0 and made all the above changes to it. You can find the source code here. . Changes to the sample application . There are few changes I would like to point out before we continue. . I have updated all the projects to target ASP.NET Core 1.0. All the projects are fork of IdentityServer4 repository with some minor changes. | dnx web no longer exist. Instead we self-host the application using dotnet CLI. To configure port, we use environment variable ASPNETCORE_URLS present in Dockerfile. | I have included Dockerfile in each of the project directory. The Dockerfile will automatically be copied when we publish our applications. | There are changes in the ports in which applications are hosted - Identity Server is hosted on port 1941 | Javascript Client remains hosted on 7017 | Sample Api is now hosted on 3721 | . | . Let’s get started . Again before continuing, I recommend you read though my previous article. It would set up the context and fill in the gaps present in this post. Done! Good! . The first two steps remain same, download and install Docker Toolbox and create a Docker VM. If you have Windows 10 Pro or Enterprise, you may also give try to new Docker for Windows which has recently moved out of beta. . Change URLs in the code . You will have to change the URLs in your code to point to the new VM URL in the following places: . IdSrvHost Configuration Clients.cs: Change all the URL here to point to the VM. Leave the port as 7017. | SampleApi Startup.cs: Change the URL in app.UseIdentityServerAuthentication. Leave the port as 1941. | JavaScript Oidc wwwroot index.html: There are two places in this file where URL needs to be changed. Leave the ports as it is in each place. | . Publish the projects . Go to each project folder and run dotnet publish to publish in your desired folder. . dotnet publish -r debian.8-x64 -o &lt;Path to output directory&gt; . Changes to Dockerfile . I have already added Dockerfile to each of the project which should automatically get copied when you published each application in the previous step. Below I’ll explain the new Dockerfile. . FROM microsoft/dotnet:1.0.0-core # Copy the app COPY . /app # Set the Working Directory WORKDIR /app # Configure the listening port to 80 ENV ASPNETCORE_URLS http://*:80 # Start the app ENTRYPOINT dotnet &lt;DLLNAME&gt; . FROM microsoft/dotnet:1.0.0-core: We use the newer dotnet base image from Microsoft. Docker will run all the following commands on top of this base image. | COPY . /app: Copy the current folder to /app folder in container. | WORKDIR /app: Set the WORKDIR to /app folder. We now no longer have approot folder. Instead all the DLL lies here. This sets the working directory in container and executes remaining command from this directory. | ENV ASPNETCORE_URLS http://*:80: This adds an environment variable ASPNETCORE_URLS which directs kestrel to listen to port 80. | ENTRYPOINT dotnet &lt;DLLNAME&gt;: This instruction will host the application specified in . This is how we host application in `dotnet` CLI. | . Build Image . This step remains as it was. Just run docker build -t &lt;tag&gt; . command in each output directory to create images. . Create the container . There are minor changes in the port mapping. Now kestrel in each container will listen on port 80, to which we bind host port as specified below . docker run -d -p 1941:80 --name idsrv-host idsrvhost docker run -d -p 7017:80 --name client jsclient docker run -d -p 3721:80 --name api sampleapi . docker run: Creates and start a new container. | -d: Run the container in background. | -p &lt;host&gt;:&lt;container&gt;: Map the specified port of host to the port container. | --name &lt;ContainerName&gt;: Creates the container with the specified name. | The last parameter is the name of the image from which to create the container. | . That’s it. . These are all the changes required to run IdSrv 4 on docker targeting ASP.NET Core 1.0. Open the browser and go to the URL:PORT to view each of the site. . Leave a comment if you have any feedbacks. .",
            "url": "https://ankitbko.github.io/blog/2016/08/IdentityServer4-on-Docker-netcorertm/",
            "relUrl": "/2016/08/IdentityServer4-on-Docker-netcorertm/",
            "date": " • Aug 18, 2016"
        }
        
    
  
    
        ,"post15": {
            "title": "IdentityServer4 on Docker",
            "content": "Update - 18 August 2016 This article was written when ASP.NET Core was in RC1. ASP.NET Core 1.0 was released in June 2016 which had some breaking changes. I have updated my repo and written a new post which explains the changes required to target ASP.NET Core 1.0. You can find it here. With Microsoft supporting .NET on Linux and docker supporting running containers on Windows, its a great time to be working on .NET stack. Now you can develop and test .NET code on containers directly from Windows without having to switch OS. Moreover Docker is beta testing its new program which makes running containers on Windows much easier. For this post we will go oldschool and use docker toolbox. . What is IdentityServer? . IdentityServer is an open source .NET implementation of OpenId Connect protocol. I have been following its development deeply since I came to know about it last year. IdentityServer4 is being developed completely on ASP.NET Core which means if built on .NET Core, it would work cross platform. . Note: While writing this article, IdentityServer4 is in Beta. Some features such as session management is not implemented yet. . Below I would detail on how to host IdentityServer4(IdSrv in short), a sample API which checks for access token and a simple javascript client in docker running on Windows. The code can be found in my github repo. This repo is essentially a fork of IdentityServer4 Samples with few changes where I have deleted other clients and changed some configurations URLs (more detail below). Lets get started. . Get Docker . Install Docker Toolbox for Windows by following instructions here. . Create a Docker VM . Create a new Docker VM by writing following command in Command Prompt. . docker-machine create --driver virtualbox --virtualbox-no-vtx-check idsrv-demo . Docker Toolbox installs Oracle VirtualBox which has known issue if you have hyper-v installed. In case you are experiencing issues while creating Docker VM, follow Hanselman’s post on how to switch between hyper-v and virtualbox. . Lets break down the above command. . docker-machine: Docker Machine allows us to provision and manage our Dockerized hosts (hosts with Docker Engine on them). | create: Create command creates a Linux Virtual Machine and installs docker engine to it. | --driver virtualbox: Docker Machine supports multiple virtualization options and environment. We will be using virtualbox which comes installed with docker toolbox. Have a look at complete list of supported driver for more information. | --virtualbox-no-vtx: This is only required if you have Hyper-v installed and have disabled Hyper-v. This command disables checking for other hardware virtualization before VM is started. | idsrv-demo: Name of the virtual machine which will be created. | . Run docker-machine ls to verify if the VM is created and running. Note the URL of the VM. This URL will be used to access any application in containers hosted on this VM. . . Setup the environment by running docker-machine env --shell=cmd idsrv-demo and following the instructions at prompt. . . Change URLs in the code . You will have to change the URLs in your code to point to the new VM URL in the following places: . IdSrvHost Configuration Clients.cs: Change all the URL here to point to the VM. Leave the port to 7017 as we will host our client on the same port. | SampleApi Startup.cs: Change the URL in app.UseIdentityServerAuthentication. Leave the port as 22530. | JavaScript Oidc wwwroot index.html: There are two places in this file where URL needs to be changed. Leave the port number as it is in each place. | project.json in each project: Change the web command to pass option to Kestrel to listen to specific URL. This is required as by default the docker container will start the application and listen to 0.0.0.0 which is not same as localhost. Port number here specifies which port needs to be opened in docker container. This is already been done in my sample. In case you are using your own code, do the following changes. IdSrvHost: &quot;web&quot;: &quot;Microsoft.AspNet.Server.Kestrel --server.urls=http://0.0.0.0:22530 | Javascript Oidc: &quot;web&quot;: &quot;Microsoft.AspNet.Server.Kestrel --server.urls=http://0.0.0.0:7017 | SampleApi: &quot;web&quot;: &quot;Microsoft.AspNet.Server.Kestrel --server.urls=http://0.0.0.0:3860 | . | . Publish the projects . Go to each project folder and run dnu publish to publish in your desired folder. . dnu publish -o &lt;Path to output directory&gt; . Add a Dockerfile . Create a platintext file and name it as Dockerfile (without extension) in the root of output of each of the published project. It should sit together with approot, wwwroot and logs folder. Paste the following content in the Dockerfile. . FROM microsoft/aspnet:1.0.0-rc1-update1-coreclr COPY . /app WORKDIR /app/approot EXPOSE &lt;PORT&gt; ENTRYPOINT [&quot;./web&quot;] . FROM microsoft/aspnet:1.0.0-rc1-update1-coreclr: Docker creates the container on a base image. Docker runs each following instructions on top of this base image. Here we use aspnet image provided by Microsoft. To learn more visit the docker hub. | COPY . /app: Copy the current folder to /app folder in container. | WORKDIR /app/approot: Set the WORKDIR to /app/approot folder. This sets the working directory in container and executes remaining command from this directory. | EXPOSE &lt;PORT&gt;: EXPOSE instruction informs Docker that the container listens on the specified network ports at runtime. EXPOSE does not make the ports of the container accessible to the host. We will do that later during creating container. Substitute for appropriate port as mentioned in project.json above. IdSrvHost: 22530 | Javascript Oidc: 7017 | SampleApi: 3860 | . | ENTRYPOINT [&quot;./web&quot;]: This instruction will execute web script in current folder. Note that we had changed the working directory to /app/approot. | . Build Image . Go to the root of the published output of each project and run the following command to create a new image. This will download the base image from docker hub and may take time depending upon internet connection. . docker build -t idsrvhost . . docker build: Builds a new image from Dockerfile | -t idsrvhost: Sets the tag of the image. | .: The PATH to build the image from. By default docker searches for Dockerfile in PATH/Dockerfile. | . . Do the same for each of the projects but change the tag name. Run docker images to view all the generated image. . . Create the container . We will create one container for each image. Run the following commands to create and start the containers. . docker run -d -p 22530:22530 --name idsrv-host idsrvhost docker run -d -p 7017:7017 --name client jsclient docker run -d -p 3860:3860 --name api sampleapi . docker run: Creates and start a new container. | -d: Run the container in background. | -p &lt;host&gt;:&lt;container&gt;: Map the specified port of host to the port container. | --name &lt;ContainerName&gt;: Creates the container with the specified name. | The last parameter is the name of the image from which to create the container. | . Run docker ps to view all the created containers. . . Thats it. . Open the browser and go to the URL:PORT to view each of the site. Open URL:7017 to play with the javascript client. . . Conclusion . Docker is great and very easy once you get hang of it. Next step you can try -v command to mount the source code to container without having to publish the site. This is incredibly helpful during development where you want to avoid hassle of publishing and creating new images every time you make a change. .",
            "url": "https://ankitbko.github.io/blog/2016/03/IdentityServer4-on-Docker/",
            "relUrl": "/2016/03/IdentityServer4-on-Docker/",
            "date": " • Mar 28, 2016"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "My name is Ankit Sinha. I currently work at Microsoft as Software Developer. I started by career as a developer in 2013 and have thoroughly enjoyed the work. . I am a technology enthusiast and love to dig in emerging technologies. In my career, I have designed architecture and successfully delivered products for multiple companies. . Outside professional life, I spend most my time playing computer games, reading books, keeping myself up to date with new technologies and trying to break (into) stuffs.☺ . You can get in touch with me on twitter @ankitbko or at linkedin. .",
          "url": "https://ankitbko.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  
  

  

  
  

  

  
  

  

  
  

  
  

  

  
  

  
      ,"page12": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://ankitbko.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}