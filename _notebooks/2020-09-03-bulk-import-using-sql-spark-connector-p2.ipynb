{"cells":[{"cell_type":"markdown","source":["# Building large scale data ingestion solutions for Azure SQL using Azure databricks - Part 2\n> Find out how bulk insert performs with different indexing strategy in Azure SQL Database.\n\n- toc: false\n- badges: false\n- comments: true\n- categories: [spark, Azure Databricks, Azure SQL, data ingestion, SQL spark connector, big data, python]\n- hide: false\n- search_exclude: false\n- source_code: https://github.com/ankitbko/sql-spark-connector-sample\n- image: images/previews/spark-connector-2-preview.png\n- author: <a href='https://twitter.com/ankitbko', target='_blank'>Ankit Sinha</a>, <a href='https://srikantan67.blogspot.com/' target='_blank'>Srikantan Sankaran</a>"],"metadata":{}},{"cell_type":"markdown","source":["This is second part of 3 part blog series on importing large dataset in Azure SQL Database. In the [previous post](https://ankitbko.github.io/blog/2020/09/bulk-import-using-sql-spark-connector-p1/) we discussed how Microsoft SQL Spark Connector can be used to bulk insert data into Azure SQL Database. We will be reusing the dataset and code from the previous post so its recommended to read it first.\n\nIn this post we will take a look how data ingestion performs under different indexing strategies in database. We will benchmark the results and compare them to understand what impact indexes had. While writing this post I noticed that the new [new Microsoft SQL Spark Connector](https://github.com/microsoft/sql-spark-connector) was taking much more time than my experience with now deprecated [Azure SQL Spark connector](https://github.com/Azure/azure-sqldb-spark/). At the time of writing there is also an [open issue](https://github.com/microsoft/sql-spark-connector/issues/13) on performance of the new connector. So I decided to take this opportunity to compare and see how well the new connector fairs agains the old one."],"metadata":{}},{"cell_type":"markdown","source":["## Environment\n\nThe number of Databricks workers has been increased to 8 and databases have been scaled up to 8vCore. To compare with old sql spark connector we need to install `com.microsoft.azure:azure-sqldb-spark:1.0.2` from maven . Other than these changes the environment remains same as in previous post. \n\n## Indexing Strategies\n\nWe will discover how bulk insert performs against following 3 different indexing strategies - \n\n- **Rowstore Index**: Rowstore indexes are the conventional way to store relational data, into a table with rows and columns, and physically stored in a row-wise format. The `store_sales` table contains a clustered index (Primary Key). The table also has a non clustered index on `ss_store_sk` column. These indexes are suited for OLTP Scenarios that entail highly concurrent operations on a subset of rows in the table.\n- **Clustered Columnstore Index (CCI)**: With [Clustered Columnstore Index](https://docs.microsoft.com/en-us/sql/relational-databases/indexes/columnstore-indexes-overview?view=sql-server-ver15#what-is-a-columnstore-index), the data is stored in a *columnar* format. It is used in Data Warehousing scenarios to execute analytical queries. A columnstore index can provide a very high level of data compression and order of magnitude better performance than rowstore index when executing analytical workloads.\n- **Non-Clustered Columnstore Index (NCCI)**: A variant of CCI, the Nonclustered Columnstore index, is one that supports an Index in the columnar format, but over a rowstore table. This enables executing analytical queries on top of an OLTP Database, referred to as Operational Analytics. More details about the differences between the two Columnstore Indexes can be found [here](https://docs.microsoft.com/en-us/archive/blogs/sqlserverstorageengine/columnstore-index-differences-between-clusterednonclustered-columnstore-index)\n\nWe have different databases for each type of index. Approximately 55 million records from `store_sales` table will be inserted into them during benchmarking. The code for inserting records is same as in previous post except so I will skip the detail breakdown of it and few of the code blocks have been collapesd for brevity. \n\n> Note: All the timings displayed are in seconds."],"metadata":{}},{"cell_type":"code","source":["#hide\nfrom codetiming import Timer\nfrom pyspark.sql.types import *\nimport pandas as pd\nimport os\n\npath = \"/mnt/adls/adls7dataset7benchmark/tpcds1tb/parquet/\"\nserver_name = dbutils.secrets.get(scope = \"kvbenchmark\", key = \"db-server-url\")\nusername = dbutils.secrets.get(scope = \"kvbenchmark\", key = \"db-username\")\npassword = dbutils.secrets.get(scope = \"kvbenchmark\", key = \"db-password\")\nschema = \"dbo\"\n\ndef create_url(server_name, database_name):\n  return server_name + \";\" + \"databaseName=\" + database_name + \";\""],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["#hide_input\ndf = spark.read.parquet(f\"{path}/store_sales\").filter(\"ss_store_sk IS NOT null\").groupBy('ss_store_sk').count().orderBy('count', ascending=False).limit(10).toPandas()\nstores = df['ss_store_sk'].tolist()\ndf.append({'ss_store_sk':'Total', 'count': df['count'].sum(axis=0)}, ignore_index=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ss_store_sk</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>529</td>\n      <td>5512441</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>650</td>\n      <td>5510505</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>14</td>\n      <td>5508259</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>406</td>\n      <td>5506912</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>178</td>\n      <td>5506321</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>766</td>\n      <td>5506226</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>934</td>\n      <td>5505890</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>157</td>\n      <td>5505605</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>22</td>\n      <td>5505380</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>772</td>\n      <td>5504930</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Total</td>\n      <td>55072469</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["#collapse\n\n# List of table names\ntables = [\"store_sales\"]\ntable_name = tables[0]\n\n# Map between table names and store surrogate key\ntable_storesk_map = {\n  \"store_sales\": \"ss_store_sk\"\n}\n\n# Map between table names and schema\ntable_schema_map = {\n  \"store_sales\": [\n    StructField(\"ss_item_sk\", IntegerType(), False), \n    StructField(\"ss_ticket_number\", IntegerType(), False)\n  ]\n}\n\ndef truncate_tables(url, username, password, tables):\n  for table in tables:\n    query = f\"TRUNCATE TABLE {schema}.{table}\"\n\n    try:\n      t = Timer(text=f\"Truncated table {table} in: {{:0.2f}}\")\n      t.start()\n      driver_manager = spark._sc._gateway.jvm.java.sql.DriverManager\n      con = driver_manager.getConnection(url, username, password)\n\n      stmt = con.createStatement()\n      stmt.executeUpdate(query)\n      stmt.close()\n      t.stop()\n    except Exception as e:\n      print(f\"Failed to truncate table {table}\", e)\n      \n# Temporary workaround until Issue #5 gets fixed https://github.com/microsoft/sql-spark-connector/issues/5\ndef create_valid_table_schema(table_name, df_schema): \n  return StructType([x if x.name not in map(lambda n: n.name, table_schema_map[table_name]) else next(filter(lambda f: f.name == x.name ,table_schema_map[table_name])) for x in df_schema])\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["def import_table(url, table_name, stores, collapse_partitions=False): \n  try:\n      df = spark.read.parquet(f\"{path}/{table_name}\")\n      df = df.filter(df[table_storesk_map[table_name]].isin(stores))\n\n      # Temporary workaround until Issue #5 gets fixed https://github.com/microsoft/sql-spark-connector/issues/5\n      table_schema = create_valid_table_schema(table_name, df.schema)\n      df = spark.createDataFrame(df.rdd, table_schema)\n      \n      print(f\"Number of partitions: {df.rdd.getNumPartitions()}\")\n      if collapse_partitions:\n        df = df.coalesce(1)\n\n      t = Timer(text=f\"Imported into table {table_name} in : {{:0.2f}} \")    \n      t.start()\n      \n      df.write.format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n        .mode(\"append\") \\\n        .option(\"url\", url) \\\n        .option(\"dbtable\", f\"{schema}.{table_name}\") \\\n        .option(\"user\", username) \\\n        .option(\"password\", password) \\\n        .option(\"tableLock\", \"false\") \\\n        .option(\"batchsize\", \"1048576\") \\\n        .save()\n\n      elapsed = t.stop()\n      return elapsed\n  except Exception as e:\n    print(f\"Failed to import into table {table_name}\", e)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["The batchsize has been set to `1048576`. This particular value is important when inserting into columnstore index. 1048576 is the maximum number of rows contained in rowgroup. Having batch size > 102400 rows enables the data to go into a compressed rowgroup directly, bypassing the delta store which greatly improves performance when bulk inserting data into columnstore index.\n\nA boolean `collapse_partitions` argument is used to collapse the number of partitions to 1. This is done to avoid deadlock when inserting into rowstore index. When there are parititons in the dataframe, the SQL Spark Connector will initate bulk import for each of the partitions concurrently. This will result in multiple bulk inserts happening on same table which causes race conditions with Page Locks as more than one bulk import is writing to same page resulting in deadlock. We will discuss deadlock in more details later."],"metadata":{}},{"cell_type":"code","source":["#hide\np_df = pd.DataFrame(columns=['index_type','time'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"markdown","source":["### Rowstore index\n\n\n```sql\nCREATE INDEX idx_store_sales_s_store_sk ON dbo.store_sales (ss_store_sk) INCLUDE (\n\tss_sold_date_sk       \n   ,ss_sold_time_sk       \n   ,ss_item_sk            \n   ,ss_customer_sk        \n   ,ss_cdemo_sk           \n   ,ss_hdemo_sk           \n   ,ss_addr_sk         \n   ,ss_promo_sk           \n   ,ss_ticket_number      \n   ,ss_quantity           \n   ,ss_wholesale_cost     \n   ,ss_list_price         \n   ,ss_sales_price        \n   ,ss_ext_discount_amt   \n   ,ss_ext_sales_price    \n   ,ss_ext_wholesale_cost \n   ,ss_ext_list_price     \n   ,ss_ext_tax            \n   ,ss_coupon_amt         \n   ,ss_net_paid           \n   ,ss_net_paid_inc_tax   \n   ,ss_net_profit\n)\n```\n\nWe have created a nonclustered index on `ss_store_sk` and included all the columns in it. This is because in our hypothetical use case we wish to retrieve all the columns of sales for a particular store. We import the records by coalescing the partitions to avoid deadlock issue that we witnessed earlier."],"metadata":{}},{"cell_type":"code","source":["url = create_url(server_name, \"idx\")\ntruncate_tables(url, username, password, tables)\nelapsed = import_table(url, table_name, stores, True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Tuncated table store_sales in: 0.13\nNumber of partitions: 30\nImported into table store_sales in : 3876.29 \n</div>"]}}],"execution_count":11},{"cell_type":"code","source":["#hide\np_df = p_df.append({\"index_type\": \"rowstore\", \"time\": elapsed}, ignore_index=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"markdown","source":["![idx metrics](./assets/images/posts/spark-connector-2/idx.png)\n\nThe database metrics captured from Azure portal shows the database is not throttled. Both CPU and IO are in comfortable range to allow any other operations to be performed in parallel. \n\nBe mindful of [locking behaviour](https://www.sqlshack.com/lock-configurations-with-sql-bulk-insert/) of Bulk Insert. In the exmaples above in our database, page locks were acquired for each bulk insert. The page locks are held for the entirity of transaction of a batch (which is 1048576 records in this sample). This means any other *write* operation on same page will most likely fail or wait for the lock to be released. A lower batch size will mean locks are held for shorter period in exchange for increased number of batches and transactions. Depending upon your use case you will need to experiment with different batch sizes to determine what works best for you."],"metadata":{}},{"cell_type":"markdown","source":["### Clustered Columnstore Index\n\n```sql\nDROP TABLE IF EXISTS store_sales\n\nCREATE TABLE store_sales\n(\n    ss_sold_date_sk           integer                       ,\n    ss_sold_time_sk           integer                       ,\n    ss_item_sk                integer               not null,\n    ss_customer_sk            integer                       ,\n    ss_cdemo_sk               integer                       ,\n    ss_hdemo_sk               integer                       ,\n    ss_addr_sk                integer                       ,\n    ss_store_sk               integer                       ,\n    ss_promo_sk               integer                       ,\n    ss_ticket_number          integer               not null,\n    ss_quantity               integer                       ,\n    ss_wholesale_cost         decimal(7,2)                  ,\n    ss_list_price             decimal(7,2)                  ,\n    ss_sales_price            decimal(7,2)                  ,\n    ss_ext_discount_amt       decimal(7,2)                  ,\n    ss_ext_sales_price        decimal(7,2)                  ,\n    ss_ext_wholesale_cost     decimal(7,2)                  ,\n    ss_ext_list_price         decimal(7,2)                  ,\n    ss_ext_tax                decimal(7,2)                  ,\n    ss_coupon_amt             decimal(7,2)                  ,\n    ss_net_paid               decimal(7,2)                  ,\n    ss_net_paid_inc_tax       decimal(7,2)                  ,\n    ss_net_profit             decimal(7,2)                  \n);\n\nCREATE CLUSTERED COLUMNSTORE INDEX cl_store_sales ON store_sales;  \n```\n\nThe clustered columnstore index (CCI) cannot be created on a table already having a clustered index on PK. So we drop and recreate the `store_sales` table without PK followed by creating a clustered columnstore index. \n\nWith the CCI we no longer need to coalesce the partitions as concurrent bulk insert will work just fine. CCI supports parallel bulk inserts to the same table so we can fully utilize our partitioned dataset to load the data concurrently.\n\nThe batch size 1048756 also plays an important role over here. Our aim is to bypass writing to delta rowgroup and directly write to compressed columnstore. The [documentation](https://docs.microsoft.com/en-us/sql/relational-databases/indexes/columnstore-indexes-overview?view=sql-server-ver15#delta-rowgroup) has excellent explaination of this so I recommend reading it."],"metadata":{}},{"cell_type":"code","source":["url = create_url(server_name, \"cci\")\ntruncate_tables(url, username, password, tables)\nelapsed = import_table(url, table_name, stores, False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Tuncated table store_sales in: 0.08\nNumber of partitions: 30\nImported into table store_sales in : 246.92 \n</div>"]}}],"execution_count":15},{"cell_type":"code","source":["#hide\np_df=p_df.append({\"index_type\": \"cci\", \"time\": elapsed}, ignore_index=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"markdown","source":["![partition](./assets/images/posts/spark-connector-2/partn.png)\n\nSince we did not coalesce the partitions multiple jobs were execution at same time as shown in image above. This resulted in much faster insertion of records in the database. Moreoever CCI are meant for large scale injestion scenarios and works great with bulk inserts and reads.\n\n![cci metrics](./assets/images/posts/spark-connector-2/cci.png)\n\nThe CPU almost peaked during our run and that is because of multiple connections concurrently inserting large amount of data into the database. However the entire run completed in just over 4 minutes which is a very good performance."],"metadata":{}},{"cell_type":"markdown","source":["### Non-Clustered Columnstore Index\n\n```sql\nCREATE NONCLUSTERED COLUMNSTORE INDEX ncl_store_sales ON store_sales (\n\tss_sold_date_sk       \n   ,ss_sold_time_sk       \n   ,ss_item_sk            \n   ,ss_customer_sk        \n   ,ss_cdemo_sk           \n   ,ss_hdemo_sk           \n   ,ss_addr_sk         \n   ,ss_promo_sk           \n   ,ss_ticket_number      \n   ,ss_quantity           \n   ,ss_wholesale_cost     \n   ,ss_list_price         \n   ,ss_sales_price        \n   ,ss_ext_discount_amt   \n   ,ss_ext_sales_price    \n   ,ss_ext_wholesale_cost \n   ,ss_ext_list_price     \n   ,ss_ext_tax            \n   ,ss_coupon_amt         \n   ,ss_net_paid           \n   ,ss_net_paid_inc_tax   \n   ,ss_net_profit\n);  \n```\n\nSomething to keep in mind before deciding which column you want to include is that NCCI takes additional space to maintain, however the data is highly compressed. Here we create a non-clustered columnstore index (NCCI) with all the columns involved to benchmark worst case scenario. \n\nEven though we have nonclustered columnstore index the physical storage of the data is still rowstore as the table has a Clustered Index on the Primary Key. That means concurrent bulk insert on same page will result to deadlock. So once again we have to coalesce the partitions."],"metadata":{}},{"cell_type":"code","source":["url = create_url(server_name, \"ncci\")\ntruncate_tables(url, username, password, tables)\nelapsed = import_table(url, table_name, stores, True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Tuncated table store_sales in: 0.09\nNumber of partitions: 30\nImported into table store_sales in : 4324.18 \n</div>"]}}],"execution_count":19},{"cell_type":"code","source":["#hide\np_df=p_df.append({\"index_type\": \"ncci\", \"time\": elapsed}, ignore_index=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":20},{"cell_type":"markdown","source":["![ncci metrics](./assets/images/posts/spark-connector-2/ncci.png)\n\nThe database metrics for NCCI is very similar to that of rowstore. CPU or IO is not being throttled and are in comfortable range."],"metadata":{}},{"cell_type":"markdown","source":["### Comparing timings between different indexes\n\nAs we can see in the chart below there is drastic difference in time between clustered columnstore index and rowstore index. Because CCI is optimized for such workload and we are able to fully utilize the spark cluster to concurrently import the data, CCI performs bulk insert order of magnitude faster than rowstore index. Nonclustered Column Store Index does not have the same benefit as CCI. Even though both CCI and NCCI are based on same underlying *columnar* format, NCCI is a secondary index and the physical storage of data depends upon clustered rowstore index on Primary Key. So the performance of bulk import in NCCI is similar to that of rowstore. Inevitably either rowstore or NCCI would have performed better in this run however on average, when I ran this notebook multiple times, the rowstore and NCCI performed nearly identical. The real benefit of using NCCI is ability to perform real time analytics. Refer to [this guide](https://docs.microsoft.com/en-us/sql/relational-databases/indexes/columnstore-indexes-design-guidance?view=sql-server-ver15#choose-the-best-columnstore-index-for-your-needs) to choose best columnstore index for your needs."],"metadata":{}},{"cell_type":"code","source":["#hide_input\nimport altair as alt\n\nalt.Chart(p_df).mark_bar().encode(\n    x='index_type:N',\n    y='time:Q',\n    color='index_type:N',\n    #column='store_sk:N',\n    tooltip=[alt.Tooltip('time:Q')]\n).properties(\n    width=alt.Step(40)  # controls width of bar.\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["\n<div id=\"altair-viz-b2757a2b6dde4cb5af70d86ed2f65059\"></div>\n<script type=\"text/javascript\">\n  (function(spec, embedOpt){\n    let outputDiv = document.currentScript.previousElementSibling;\n    if (outputDiv.id !== \"altair-viz-b2757a2b6dde4cb5af70d86ed2f65059\") {\n      outputDiv = document.getElementById(\"altair-viz-b2757a2b6dde4cb5af70d86ed2f65059\");\n    }\n    const paths = {\n      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n    };\n\n    function loadScript(lib) {\n      return new Promise(function(resolve, reject) {\n        var s = document.createElement('script');\n        s.src = paths[lib];\n        s.async = true;\n        s.onload = () => resolve(paths[lib]);\n        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n        document.getElementsByTagName(\"head\")[0].appendChild(s);\n      });\n    }\n\n    function showError(err) {\n      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n      throw err;\n    }\n\n    function displayChart(vegaEmbed) {\n      vegaEmbed(outputDiv, spec, embedOpt)\n        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n    }\n\n    if(typeof define === \"function\" && define.amd) {\n      requirejs.config({paths});\n      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n    } else if (typeof vegaEmbed === \"function\") {\n      displayChart(vegaEmbed);\n    } else {\n      loadScript(\"vega\")\n        .then(() => loadScript(\"vega-lite\"))\n        .then(() => loadScript(\"vega-embed\"))\n        .catch(showError)\n        .then(() => displayChart(vegaEmbed));\n    }\n  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-d3ea0fe5d88c6fc0ac5e13a829b49417\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"index_type\"}, \"tooltip\": [{\"type\": \"quantitative\", \"field\": \"time\"}], \"x\": {\"type\": \"nominal\", \"field\": \"index_type\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"time\"}}, \"width\": {\"step\": 40}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-d3ea0fe5d88c6fc0ac5e13a829b49417\": [{\"index_type\": \"rowstore\", \"time\": 3876.2913843349997}, {\"index_type\": \"cci\", \"time\": 246.92076767599792}, {\"index_type\": \"ncci\", \"time\": 4324.18118408}]}}, {\"mode\": \"vega-lite\"});\n</script>"]}}],"execution_count":23},{"cell_type":"markdown","source":["## Benchmarking using old Azure SQL Spark Connector\n\nAs mentioned before there is an [open issue](https://github.com/microsoft/sql-spark-connector/issues/13) on poor performance of the new connector. I am following up with the developers of the connector to resolve it. Meanwhile lets run the bulk import on same three indexes to compare how well the new connector performs when compared to older one.\n\nTo get started we need to install the jar file from maven `com.microsoft.azure:azure-sqldb-spark:1.0.2`. The azure sqldb connector only works with Scala so we need to rewrite the above code in Scala. I will not get into details of the code but the following code is identical to what we have in python. At the end we will compare the run timings of old connector with new connector."],"metadata":{}},{"cell_type":"code","source":["%scala\nimport com.microsoft.azure.sqldb.spark.query._\nimport com.microsoft.azure.sqldb.spark.config.Config\nimport com.microsoft.azure.sqldb.spark.connect._\nimport org.apache.spark.sql.functions._\n\nval path = \"/mnt/adls/adls7dataset7benchmark/tpcds1tb/parquet\"\n\nvar configMap = Map(\n  \"url\"            -> dbutils.secrets.get(scope = \"kvbenchmark\", key = \"db-server-name\"),\n  \"user\"           -> dbutils.secrets.get(scope = \"kvbenchmark\", key = \"db-username\"),\n  \"password\"       -> dbutils.secrets.get(scope = \"kvbenchmark\", key = \"db-password\")\n)\n\nvar df = spark.read\n  .parquet(path + \"/store_sales\")\n  .filter(\"ss_store_sk IS NOT null\")\n  .groupBy(\"ss_store_sk\")\n  .count()\n  .orderBy(desc(\"count\"))\n  .limit(10)\n\nval stores = df.select(\"ss_store_sk\").collect.map(_.getInt(0))\n\ndef truncate_table(db:String, table_name: String) = {\n  val query = \"TRUNCATE TABLE \" + \"dbo.\" + table_name\n  val config = Config(configMap ++ Map(\n    \"queryCustom\"  -> query,\n    \"databaseName\" -> db\n  ))\n  var start_table = System.nanoTime().toDouble\n  sqlContext.sqlDBQuery(config)\n  var end_table = System.nanoTime().toDouble\n  var run_time_table = (end_table - start_table) / 1000000000\n  println(\"Truncated table: \" + table_name + \" took: \" + run_time_table)\n}\n\ndef import_sales(db:String, table_name: String, coalesce: Boolean): Double = {\n  val config = Config(configMap ++ Map(\n    \"databaseName\"      -> db,  \n    \"bulkCopyBatchSize\" -> \"1048576\",\n    \"bulkCopyTableLock\" -> \"false\",\n    \"bulkCopyTimeout\"   -> \"7200\",\n    \"dbTable\"           -> table_name\n  ))\n\n  var df = spark.read.parquet(path + \"/\" + table_name)\n  df = df.filter($\"ss_store_sk\".isInCollection(stores))\n\n  var tempdf = sqlContext.read.sqlDB(config)\n  var reorderedColumnNames = tempdf.schema.fields.map(_.name)\n  df = df.select(reorderedColumnNames.head, reorderedColumnNames.tail: _*)\n\n  println(\"Number of partitions: \" + df.rdd.getNumPartitions)\n  \n  if (coalesce == true) {\n    df = df.coalesce(1)\n  }\n  \n  var start_table = System.nanoTime().toDouble\n  df.bulkCopyToSqlDB(config)\n  var end_table = System.nanoTime().toDouble\n  var run_time_table = (end_table - start_table) / 1000000000\n  println(\"Imported into\" + table_name + \" took: \" + run_time_table)\n  return run_time_table\n}"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">import com.microsoft.azure.sqldb.spark.query._\nimport com.microsoft.azure.sqldb.spark.config.Config\nimport com.microsoft.azure.sqldb.spark.connect._\nimport org.apache.spark.sql.functions._\npath: String = /mnt/adls/adls7dataset7benchmark/tpcds1tb/parquet\nconfigMap: scala.collection.immutable.Map[String,String] = Map(url -&gt; [REDACTED], user -&gt; [REDACTED], password -&gt; [REDACTED])\ndf: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [ss_store_sk: int, count: bigint]\nstores: Array[Int] = Array(529, 650, 14, 406, 178, 766, 934, 157, 22, 772)\ntruncate_table: (db: String, table_name: String)Unit\nimport_sales: (db: String, table_name: String, coalesce: Boolean)Double\n</div>"]}}],"execution_count":25},{"cell_type":"code","source":["%scala\nprintln(\"--- Starting import in rowstore index ---\")\ntruncate_table(\"idx\", \"store_sales\")\nvar elapsed = import_sales(\"idx\", \"store_sales\", true)\nvar o_df = Map(\"rowstore\"-> elapsed).toSeq.toDF(\"index_type\", \"time\")\n\nprintln(\"--- Starting import in CCI ---\")\ntruncate_table(\"cci\", \"store_sales\")\nelapsed = import_sales(\"cci\", \"store_sales\", false)\no_df = o_df.union(Map(\"cci\"->elapsed).toSeq.toDF())\n\nprintln(\"--- Starting import in NCCI ---\")\ntruncate_table(\"ncci\", \"store_sales\")\nelapsed = import_sales(\"ncci\", \"store_sales\", true)\no_df = o_df.union(Map(\"ncci\"->elapsed).toSeq.toDF())\n\no_df.createOrReplaceTempView(\"o_df\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">--- Starting import in rowstore index ---\nTruncated table: store_sales took: 0.089774135\nNumber of partitions: 30\nImported intostore_sales took: 1798.744563592\n--- Starting import in CCI ---\nTruncated table: store_sales took: 0.107795881\nNumber of partitions: 30\nImported intostore_sales took: 225.057509767\n--- Starting import in NCCI ---\nTruncated table: store_sales took: 0.096099101\nNumber of partitions: 30\nImported intostore_sales took: 2419.880703759\nelapsed: Double = 2419.880703759\no_df: org.apache.spark.sql.DataFrame = [index_type: string, time: double]\nelapsed: Double = 2419.880703759\no_df: org.apache.spark.sql.DataFrame = [index_type: string, time: double]\nelapsed: Double = 2419.880703759\no_df: org.apache.spark.sql.DataFrame = [index_type: string, time: double]\n</div>"]}}],"execution_count":26},{"cell_type":"code","source":["#hide_input\no_df = sqlContext.table(\"o_df\").toPandas()\n\npf_df = p_df\nof_df = o_df\n\npf_df[\"connector\"] = \"new\"\nof_df[\"connector\"] = \"old\"\n\nf_df = pf_df\nf_df = f_df.append(of_df)\n\nalt.Chart(f_df).mark_bar().encode(\n    x='connector:N',\n    y='time:Q',\n    color='connector:N',\n    column='index_type:N',\n    tooltip=[alt.Tooltip('index_type:N'),\n             alt.Tooltip('connector:N'),\n             alt.Tooltip('time:Q')]\n).properties(\n    width=alt.Step(40)  # controls width of bar.\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["\n<div id=\"altair-viz-ad08791485f14f4fa95b02e62c9652fb\"></div>\n<script type=\"text/javascript\">\n  (function(spec, embedOpt){\n    let outputDiv = document.currentScript.previousElementSibling;\n    if (outputDiv.id !== \"altair-viz-ad08791485f14f4fa95b02e62c9652fb\") {\n      outputDiv = document.getElementById(\"altair-viz-ad08791485f14f4fa95b02e62c9652fb\");\n    }\n    const paths = {\n      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n    };\n\n    function loadScript(lib) {\n      return new Promise(function(resolve, reject) {\n        var s = document.createElement('script');\n        s.src = paths[lib];\n        s.async = true;\n        s.onload = () => resolve(paths[lib]);\n        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n        document.getElementsByTagName(\"head\")[0].appendChild(s);\n      });\n    }\n\n    function showError(err) {\n      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n      throw err;\n    }\n\n    function displayChart(vegaEmbed) {\n      vegaEmbed(outputDiv, spec, embedOpt)\n        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n    }\n\n    if(typeof define === \"function\" && define.amd) {\n      requirejs.config({paths});\n      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n    } else if (typeof vegaEmbed === \"function\") {\n      displayChart(vegaEmbed);\n    } else {\n      loadScript(\"vega\")\n        .then(() => loadScript(\"vega-lite\"))\n        .then(() => loadScript(\"vega-embed\"))\n        .catch(showError)\n        .then(() => displayChart(vegaEmbed));\n    }\n  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-9667fbb2e569c23b609dc735037f4d15\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"connector\"}, \"column\": {\"type\": \"nominal\", \"field\": \"index_type\"}, \"tooltip\": [{\"type\": \"nominal\", \"field\": \"index_type\"}, {\"type\": \"nominal\", \"field\": \"connector\"}, {\"type\": \"quantitative\", \"field\": \"time\"}], \"x\": {\"type\": \"nominal\", \"field\": \"connector\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"time\"}}, \"width\": {\"step\": 40}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-9667fbb2e569c23b609dc735037f4d15\": [{\"index_type\": \"rowstore\", \"time\": 3876.2913843349997, \"connector\": \"new\"}, {\"index_type\": \"cci\", \"time\": 246.92076767599792, \"connector\": \"new\"}, {\"index_type\": \"ncci\", \"time\": 4324.18118408, \"connector\": \"new\"}, {\"index_type\": \"rowstore\", \"time\": 1798.744563592, \"connector\": \"old\"}, {\"index_type\": \"cci\", \"time\": 225.057509767, \"connector\": \"old\"}, {\"index_type\": \"ncci\", \"time\": 2419.880703759, \"connector\": \"old\"}]}}, {\"mode\": \"vega-lite\"});\n</script>"]}}],"execution_count":27},{"cell_type":"markdown","source":["We can see that the old connector performance is much better than the new one when inserting into rowstore or NCCI but performs equally in case of CCI. I cannot emphasize enough that the old connector is deprecated and no more actively maintained. The new Microsoft SQL Spark connector is the future and just as with any new software it has bugs and issues. As it becomes mature it will be on par or exceed performance of the old connector. If you are already using old connector or have a dire need of best performance when inserting into rowstore index then you can continue using it before transitioning to new connector once the performance issue is fixed. There are also a lot of options that can be specified in connector to control the behaviour of bulk insert. Experiment with them and choose what fits best with your use case.\n\nIn the next post we will delve deeper into the issue of deadlock and discuss some solutions for it. Leave a comment if you have any questions or suggestions."],"metadata":{}}],"metadata":{"name":"2020-09-03-bulk-import-using-sql-spark-connector-p2","notebookId":3251470539879974},"nbformat":4,"nbformat_minor":0}