<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Building large scale data ingestion solutions for Azure SQL using Azure databricks - Part 2 | F5 - Squashing Bugs</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Building large scale data ingestion solutions for Azure SQL using Azure databricks - Part 2" />
<meta name="author" content="<a href='https://twitter.com/ankitbko', target='_blank'>Ankit Sinha</a>, <a href='https://srikantan67.blogspot.com/' target='_blank'>Srikantan Sankaran</a>" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Find out how bulk insert performs with different indexing strategy in Azure SQL Database." />
<meta property="og:description" content="Find out how bulk insert performs with different indexing strategy in Azure SQL Database." />
<link rel="canonical" href="https://ankitbko.github.io/blog/2020/09/bulk-import-using-sql-spark-connector-p2/" />
<meta property="og:url" content="https://ankitbko.github.io/blog/2020/09/bulk-import-using-sql-spark-connector-p2/" />
<meta property="og:site_name" content="F5 - Squashing Bugs" />
<meta property="og:image" content="https://ankitbko.github.io/blog/images/previews/spark-connector-2-preview.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-09-03T00:00:00-05:00" />
<script type="application/ld+json">
{"headline":"Building large scale data ingestion solutions for Azure SQL using Azure databricks - Part 2","dateModified":"2020-09-03T00:00:00-05:00","datePublished":"2020-09-03T00:00:00-05:00","author":{"@type":"Person","name":"<a href='https://twitter.com/ankitbko', target='_blank'>Ankit Sinha</a>, <a href='https://srikantan67.blogspot.com/' target='_blank'>Srikantan Sankaran</a>"},"image":"https://ankitbko.github.io/blog/images/previews/spark-connector-2-preview.png","description":"Find out how bulk insert performs with different indexing strategy in Azure SQL Database.","mainEntityOfPage":{"@type":"WebPage","@id":"https://ankitbko.github.io/blog/2020/09/bulk-import-using-sql-spark-connector-p2/"},"@type":"BlogPosting","url":"https://ankitbko.github.io/blog/2020/09/bulk-import-using-sql-spark-connector-p2/","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://ankitbko.github.io/blog/feed.xml" title="F5 - Squashing Bugs" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-75679348-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Building large scale data ingestion solutions for Azure SQL using Azure databricks - Part 2 | F5 - Squashing Bugs</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Building large scale data ingestion solutions for Azure SQL using Azure databricks - Part 2" />
<meta name="author" content="<a href='https://twitter.com/ankitbko', target='_blank'>Ankit Sinha</a>, <a href='https://srikantan67.blogspot.com/' target='_blank'>Srikantan Sankaran</a>" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Find out how bulk insert performs with different indexing strategy in Azure SQL Database." />
<meta property="og:description" content="Find out how bulk insert performs with different indexing strategy in Azure SQL Database." />
<link rel="canonical" href="https://ankitbko.github.io/blog/2020/09/bulk-import-using-sql-spark-connector-p2/" />
<meta property="og:url" content="https://ankitbko.github.io/blog/2020/09/bulk-import-using-sql-spark-connector-p2/" />
<meta property="og:site_name" content="F5 - Squashing Bugs" />
<meta property="og:image" content="https://ankitbko.github.io/blog/images/previews/spark-connector-2-preview.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-09-03T00:00:00-05:00" />
<script type="application/ld+json">
{"headline":"Building large scale data ingestion solutions for Azure SQL using Azure databricks - Part 2","dateModified":"2020-09-03T00:00:00-05:00","datePublished":"2020-09-03T00:00:00-05:00","author":{"@type":"Person","name":"<a href='https://twitter.com/ankitbko', target='_blank'>Ankit Sinha</a>, <a href='https://srikantan67.blogspot.com/' target='_blank'>Srikantan Sankaran</a>"},"image":"https://ankitbko.github.io/blog/images/previews/spark-connector-2-preview.png","description":"Find out how bulk insert performs with different indexing strategy in Azure SQL Database.","mainEntityOfPage":{"@type":"WebPage","@id":"https://ankitbko.github.io/blog/2020/09/bulk-import-using-sql-spark-connector-p2/"},"@type":"BlogPosting","url":"https://ankitbko.github.io/blog/2020/09/bulk-import-using-sql-spark-connector-p2/","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://ankitbko.github.io/blog/feed.xml" title="F5 - Squashing Bugs" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-75679348-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>


    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">F5 - Squashing Bugs</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Building large scale data ingestion solutions for Azure SQL using Azure databricks - Part 2</h1><p class="page-description">Find out how bulk insert performs with different indexing strategy in Azure SQL Database.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-09-03T00:00:00-05:00" itemprop="datePublished">
        Sep 3, 2020
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name"><a href='https://twitter.com/ankitbko', target='_blank'>Ankit Sinha</a>, <a href='https://srikantan67.blogspot.com/' target='_blank'>Srikantan Sankaran</a></span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      13 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#spark">spark</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#Azure Databricks">Azure Databricks</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#Azure SQL">Azure SQL</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#data ingestion">data ingestion</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#SQL spark connector">SQL spark connector</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#big data">big data</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#python">python</a>
        
      
      </p>
    

    
      
		<div class="d-flex flex-wrap flex-justify-start flex-items-center">
			<p class="page-description" style="margin-right: .5rem;">Source Code </p>
			<div class="page-description">
				<div class="px-2">
    <a href="https://github.com/ankitbko/sql-spark-connector-sample" role="button" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

			</div>
		</div>
	</header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-09-03-bulk-import-using-sql-spark-connector-p2.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is second part of 3 part blog series on importing large dataset in Azure SQL Database. In the <a href="https://ankitbko.github.io/blog/2020/09/bulk-import-using-sql-spark-connector-p1/">previous post</a> we discussed how Microsoft SQL Spark Connector can be used to bulk insert data into Azure SQL Database. We will be reusing the dataset and code from the previous post so its recommended to read it first.</p>
<p>In this post we will take a look how data ingestion performs under different indexing strategies in database. We will benchmark the results and compare them to understand what impact indexes had. While writing this post I noticed that the new <a href="https://github.com/microsoft/sql-spark-connector">new Microsoft SQL Spark Connector</a> was taking much more time than my experience with now deprecated <a href="https://github.com/Azure/azure-sqldb-spark/">Azure SQL Spark connector</a>. At the time of writing there is also an <a href="https://github.com/microsoft/sql-spark-connector/issues/13">open issue</a> on performance of the new connector. So I decided to take this opportunity to compare and see how well the new connector fairs agains the old one.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Environment">Environment<a class="anchor-link" href="#Environment"> </a></h2><p>The number of Databricks workers has been increased to 8 and databases have been scaled up to 8vCore. To compare with old sql spark connector we need to install <code>com.microsoft.azure:azure-sqldb-spark:1.0.2</code> from maven . Other than these changes the environment remains same as in previous post.</p>
<h2 id="Indexing-Strategies">Indexing Strategies<a class="anchor-link" href="#Indexing-Strategies"> </a></h2><p>We will discover how bulk insert performs against following 3 different indexing strategies -</p>
<ul>
<li><strong>Rowstore Index</strong>: Rowstore indexes are the conventional way to store relational data, into a table with rows and columns, and physically stored in a row-wise format. The <code>store_sales</code> table contains a clustered index (Primary Key). The table also has a non clustered index on <code>ss_store_sk</code> column. These indexes are suited for OLTP Scenarios that entail highly concurrent operations on a subset of rows in the table.</li>
<li><strong>Clustered Columnstore Index (CCI)</strong>: With <a href="https://docs.microsoft.com/en-us/sql/relational-databases/indexes/columnstore-indexes-overview?view=sql-server-ver15#what-is-a-columnstore-index">Clustered Columnstore Index</a>, the data is stored in a <em>columnar</em> format. It is used in Data Warehousing scenarios to execute analytical queries. A columnstore index can provide a very high level of data compression and order of magnitude better performance than rowstore index when executing analytical workloads.</li>
<li><strong>Non-Clustered Columnstore Index (NCCI)</strong>: A variant of CCI, the Nonclustered Columnstore index, is one that supports an Index in the columnar format, but over a rowstore table. This enables executing analytical queries on top of an OLTP Database, referred to as Operational Analytics. More details about the differences between the two Columnstore Indexes can be found <a href="https://docs.microsoft.com/en-us/archive/blogs/sqlserverstorageengine/columnstore-index-differences-between-clusterednonclustered-columnstore-index">here</a></li>
</ul>
<p>We have different databases for each type of index. Approximately 55 million records from <code>store_sales</code> table will be inserted into them during benchmarking. The code for inserting records is same as in previous post except so I will skip the detail breakdown of it and few of the code blocks have been collapesd for brevity. 
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg>
    <strong>Note: </strong>All the timings displayed are in seconds.
</div></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ss_store_sk</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>529</td>
      <td>5512441</td>
    </tr>
    <tr>
      <th>1</th>
      <td>650</td>
      <td>5510505</td>
    </tr>
    <tr>
      <th>2</th>
      <td>14</td>
      <td>5508259</td>
    </tr>
    <tr>
      <th>3</th>
      <td>406</td>
      <td>5506912</td>
    </tr>
    <tr>
      <th>4</th>
      <td>178</td>
      <td>5506321</td>
    </tr>
    <tr>
      <th>5</th>
      <td>766</td>
      <td>5506226</td>
    </tr>
    <tr>
      <th>6</th>
      <td>934</td>
      <td>5505890</td>
    </tr>
    <tr>
      <th>7</th>
      <td>157</td>
      <td>5505605</td>
    </tr>
    <tr>
      <th>8</th>
      <td>22</td>
      <td>5505380</td>
    </tr>
    <tr>
      <th>9</th>
      <td>772</td>
      <td>5504930</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Total</td>
      <td>55072469</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse</span>

<span class="c1"># List of table names</span>
<span class="n">tables</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;store_sales&quot;</span><span class="p">]</span>
<span class="n">table_name</span> <span class="o">=</span> <span class="n">tables</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># Map between table names and store surrogate key</span>
<span class="n">table_storesk_map</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s2">&quot;store_sales&quot;</span><span class="p">:</span> <span class="s2">&quot;ss_store_sk&quot;</span>
<span class="p">}</span>

<span class="c1"># Map between table names and schema</span>
<span class="n">table_schema_map</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s2">&quot;store_sales&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;ss_item_sk&quot;</span><span class="p">,</span> <span class="n">IntegerType</span><span class="p">(),</span> <span class="kc">False</span><span class="p">),</span> 
    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;ss_ticket_number&quot;</span><span class="p">,</span> <span class="n">IntegerType</span><span class="p">(),</span> <span class="kc">False</span><span class="p">)</span>
  <span class="p">]</span>
<span class="p">}</span>

<span class="k">def</span> <span class="nf">truncate_tables</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">username</span><span class="p">,</span> <span class="n">password</span><span class="p">,</span> <span class="n">tables</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">table</span> <span class="ow">in</span> <span class="n">tables</span><span class="p">:</span>
    <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;TRUNCATE TABLE </span><span class="si">{</span><span class="n">schema</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">table</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="k">try</span><span class="p">:</span>
      <span class="n">t</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Truncated table </span><span class="si">{</span><span class="n">table</span><span class="si">}</span><span class="s2"> in: </span><span class="se">{{</span><span class="s2">:0.2f</span><span class="se">}}</span><span class="s2">&quot;</span><span class="p">)</span>
      <span class="n">t</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
      <span class="n">driver_manager</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">_sc</span><span class="o">.</span><span class="n">_gateway</span><span class="o">.</span><span class="n">jvm</span><span class="o">.</span><span class="n">java</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">DriverManager</span>
      <span class="n">con</span> <span class="o">=</span> <span class="n">driver_manager</span><span class="o">.</span><span class="n">getConnection</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">username</span><span class="p">,</span> <span class="n">password</span><span class="p">)</span>

      <span class="n">stmt</span> <span class="o">=</span> <span class="n">con</span><span class="o">.</span><span class="n">createStatement</span><span class="p">()</span>
      <span class="n">stmt</span><span class="o">.</span><span class="n">executeUpdate</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
      <span class="n">stmt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
      <span class="n">t</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to truncate table </span><span class="si">{</span><span class="n">table</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>
      
<span class="c1"># Temporary workaround until Issue #5 gets fixed https://github.com/microsoft/sql-spark-connector/issues/5</span>
<span class="k">def</span> <span class="nf">create_valid_table_schema</span><span class="p">(</span><span class="n">table_name</span><span class="p">,</span> <span class="n">df_schema</span><span class="p">):</span> 
  <span class="k">return</span> <span class="n">StructType</span><span class="p">([</span><span class="n">x</span> <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">n</span><span class="p">:</span> <span class="n">n</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">table_schema_map</span><span class="p">[</span><span class="n">table_name</span><span class="p">])</span> <span class="k">else</span> <span class="nb">next</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">f</span><span class="p">:</span> <span class="n">f</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="n">x</span><span class="o">.</span><span class="n">name</span> <span class="p">,</span><span class="n">table_schema_map</span><span class="p">[</span><span class="n">table_name</span><span class="p">]))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df_schema</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<style scoped="">
  .ansiout {
    display: block;
    unicode-bidi: embed;
    white-space: pre-wrap;
    word-wrap: break-word;
    word-break: break-all;
    font-family: "Source Code Pro", "Menlo", monospace;;
    font-size: 13px;
    color: #555;
    margin-left: 4px;
    line-height: 19px;
  }
</style>
<div class="ansiout"></div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">import_table</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">table_name</span><span class="p">,</span> <span class="n">stores</span><span class="p">,</span> <span class="n">collapse_partitions</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span> 
  <span class="k">try</span><span class="p">:</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">table_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">table_storesk_map</span><span class="p">[</span><span class="n">table_name</span><span class="p">]]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">stores</span><span class="p">))</span>

      <span class="c1"># Temporary workaround until Issue #5 gets fixed https://github.com/microsoft/sql-spark-connector/issues/5</span>
      <span class="n">table_schema</span> <span class="o">=</span> <span class="n">create_valid_table_schema</span><span class="p">(</span><span class="n">table_name</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">schema</span><span class="p">)</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">rdd</span><span class="p">,</span> <span class="n">table_schema</span><span class="p">)</span>
      
      <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of partitions: </span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">rdd</span><span class="o">.</span><span class="n">getNumPartitions</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">collapse_partitions</span><span class="p">:</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">coalesce</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

      <span class="n">t</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Imported into table </span><span class="si">{</span><span class="n">table_name</span><span class="si">}</span><span class="s2"> in : </span><span class="se">{{</span><span class="s2">:0.2f</span><span class="se">}}</span><span class="s2"> &quot;</span><span class="p">)</span>    
      <span class="n">t</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
      
      <span class="n">df</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;com.microsoft.sqlserver.jdbc.spark&quot;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="s2">&quot;append&quot;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;url&quot;</span><span class="p">,</span> <span class="n">url</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;dbtable&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">schema</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">table_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="n">username</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;password&quot;</span><span class="p">,</span> <span class="n">password</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;tableLock&quot;</span><span class="p">,</span> <span class="s2">&quot;false&quot;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;batchsize&quot;</span><span class="p">,</span> <span class="s2">&quot;1048576&quot;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">save</span><span class="p">()</span>

      <span class="n">elapsed</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
      <span class="k">return</span> <span class="n">elapsed</span>
  <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to import into table </span><span class="si">{</span><span class="n">table_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<style scoped="">
  .ansiout {
    display: block;
    unicode-bidi: embed;
    white-space: pre-wrap;
    word-wrap: break-word;
    word-break: break-all;
    font-family: "Source Code Pro", "Menlo", monospace;;
    font-size: 13px;
    color: #555;
    margin-left: 4px;
    line-height: 19px;
  }
</style>
<div class="ansiout"></div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The batchsize has been set to <code>1048576</code>. This particular value is important when inserting into columnstore index. 1048576 is the maximum number of rows contained in rowgroup. Having batch size &gt; 102400 rows enables the data to go into a compressed rowgroup directly, bypassing the delta store which greatly improves performance when bulk inserting data into columnstore index.</p>
<p>A boolean <code>collapse_partitions</code> argument is used to collapse the number of partitions to 1. This is done to avoid deadlock when inserting into rowstore index. When there are parititons in the dataframe, the SQL Spark Connector will initate bulk import for each of the partitions concurrently. This will result in multiple bulk inserts happening on same table which causes race conditions with Page Locks as more than one bulk import is writing to same page resulting in deadlock. We will discuss deadlock in more details later.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Rowstore-index">Rowstore index<a class="anchor-link" href="#Rowstore-index"> </a></h3><div class="highlight"><pre><span></span><span class="k">CREATE</span> <span class="k">INDEX</span> <span class="n">idx_store_sales_s_store_sk</span> <span class="k">ON</span> <span class="n">dbo</span><span class="p">.</span><span class="n">store_sales</span> <span class="p">(</span><span class="n">ss_store_sk</span><span class="p">)</span> <span class="n">INCLUDE</span> <span class="p">(</span>
    <span class="n">ss_sold_date_sk</span>       
   <span class="p">,</span><span class="n">ss_sold_time_sk</span>       
   <span class="p">,</span><span class="n">ss_item_sk</span>            
   <span class="p">,</span><span class="n">ss_customer_sk</span>        
   <span class="p">,</span><span class="n">ss_cdemo_sk</span>           
   <span class="p">,</span><span class="n">ss_hdemo_sk</span>           
   <span class="p">,</span><span class="n">ss_addr_sk</span>         
   <span class="p">,</span><span class="n">ss_promo_sk</span>           
   <span class="p">,</span><span class="n">ss_ticket_number</span>      
   <span class="p">,</span><span class="n">ss_quantity</span>           
   <span class="p">,</span><span class="n">ss_wholesale_cost</span>     
   <span class="p">,</span><span class="n">ss_list_price</span>         
   <span class="p">,</span><span class="n">ss_sales_price</span>        
   <span class="p">,</span><span class="n">ss_ext_discount_amt</span>   
   <span class="p">,</span><span class="n">ss_ext_sales_price</span>    
   <span class="p">,</span><span class="n">ss_ext_wholesale_cost</span> 
   <span class="p">,</span><span class="n">ss_ext_list_price</span>     
   <span class="p">,</span><span class="n">ss_ext_tax</span>            
   <span class="p">,</span><span class="n">ss_coupon_amt</span>         
   <span class="p">,</span><span class="n">ss_net_paid</span>           
   <span class="p">,</span><span class="n">ss_net_paid_inc_tax</span>   
   <span class="p">,</span><span class="n">ss_net_profit</span>
<span class="p">)</span>
</pre></div>
<p>We have created a nonclustered index on <code>ss_store_sk</code> and included all the columns in it. This is because in our hypothetical use case we wish to retrieve all the columns of sales for a particular store. We import the records by coalescing the partitions to avoid deadlock issue that we witnessed earlier.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">url</span> <span class="o">=</span> <span class="n">create_url</span><span class="p">(</span><span class="n">server_name</span><span class="p">,</span> <span class="s2">&quot;idx&quot;</span><span class="p">)</span>
<span class="n">truncate_tables</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">username</span><span class="p">,</span> <span class="n">password</span><span class="p">,</span> <span class="n">tables</span><span class="p">)</span>
<span class="n">elapsed</span> <span class="o">=</span> <span class="n">import_table</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">table_name</span><span class="p">,</span> <span class="n">stores</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<style scoped="">
  .ansiout {
    display: block;
    unicode-bidi: embed;
    white-space: pre-wrap;
    word-wrap: break-word;
    word-break: break-all;
    font-family: "Source Code Pro", "Menlo", monospace;;
    font-size: 13px;
    color: #555;
    margin-left: 4px;
    line-height: 19px;
  }
</style>
<div class="ansiout">Tuncated table store_sales in: 0.13
Number of partitions: 30
Imported into table store_sales in : 3876.29 
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/blog/images/copied_from_nb/./assets/images/posts/spark-connector-2/idx.png" alt="idx metrics" /></p>
<p>The database metrics captured from Azure portal shows the database is not throttled. Both CPU and IO are in comfortable range to allow any other operations to be performed in parallel.</p>
<p>Be mindful of <a href="https://www.sqlshack.com/lock-configurations-with-sql-bulk-insert/">locking behaviour</a> of Bulk Insert. In the exmaples above in our database, page locks were acquired for each bulk insert. The page locks are held for the entirity of transaction of a batch (which is 1048576 records in this sample). This means any other <em>write</em> operation on same page will most likely fail or wait for the lock to be released. A lower batch size will mean locks are held for shorter period in exchange for increased number of batches and transactions. Depending upon your use case you will need to experiment with different batch sizes to determine what works best for you.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Clustered-Columnstore-Index">Clustered Columnstore Index<a class="anchor-link" href="#Clustered-Columnstore-Index"> </a></h3><div class="highlight"><pre><span></span><span class="k">DROP</span> <span class="k">TABLE</span> <span class="k">IF</span> <span class="k">EXISTS</span> <span class="n">store_sales</span>

<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">store_sales</span>
<span class="p">(</span>
    <span class="n">ss_sold_date_sk</span>           <span class="nb">integer</span>                       <span class="p">,</span>
    <span class="n">ss_sold_time_sk</span>           <span class="nb">integer</span>                       <span class="p">,</span>
    <span class="n">ss_item_sk</span>                <span class="nb">integer</span>               <span class="k">not</span> <span class="k">null</span><span class="p">,</span>
    <span class="n">ss_customer_sk</span>            <span class="nb">integer</span>                       <span class="p">,</span>
    <span class="n">ss_cdemo_sk</span>               <span class="nb">integer</span>                       <span class="p">,</span>
    <span class="n">ss_hdemo_sk</span>               <span class="nb">integer</span>                       <span class="p">,</span>
    <span class="n">ss_addr_sk</span>                <span class="nb">integer</span>                       <span class="p">,</span>
    <span class="n">ss_store_sk</span>               <span class="nb">integer</span>                       <span class="p">,</span>
    <span class="n">ss_promo_sk</span>               <span class="nb">integer</span>                       <span class="p">,</span>
    <span class="n">ss_ticket_number</span>          <span class="nb">integer</span>               <span class="k">not</span> <span class="k">null</span><span class="p">,</span>
    <span class="n">ss_quantity</span>               <span class="nb">integer</span>                       <span class="p">,</span>
    <span class="n">ss_wholesale_cost</span>         <span class="nb">decimal</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>                  <span class="p">,</span>
    <span class="n">ss_list_price</span>             <span class="nb">decimal</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>                  <span class="p">,</span>
    <span class="n">ss_sales_price</span>            <span class="nb">decimal</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>                  <span class="p">,</span>
    <span class="n">ss_ext_discount_amt</span>       <span class="nb">decimal</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>                  <span class="p">,</span>
    <span class="n">ss_ext_sales_price</span>        <span class="nb">decimal</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>                  <span class="p">,</span>
    <span class="n">ss_ext_wholesale_cost</span>     <span class="nb">decimal</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>                  <span class="p">,</span>
    <span class="n">ss_ext_list_price</span>         <span class="nb">decimal</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>                  <span class="p">,</span>
    <span class="n">ss_ext_tax</span>                <span class="nb">decimal</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>                  <span class="p">,</span>
    <span class="n">ss_coupon_amt</span>             <span class="nb">decimal</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>                  <span class="p">,</span>
    <span class="n">ss_net_paid</span>               <span class="nb">decimal</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>                  <span class="p">,</span>
    <span class="n">ss_net_paid_inc_tax</span>       <span class="nb">decimal</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>                  <span class="p">,</span>
    <span class="n">ss_net_profit</span>             <span class="nb">decimal</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>                  
<span class="p">);</span>

<span class="k">CREATE</span> <span class="n">CLUSTERED</span> <span class="n">COLUMNSTORE</span> <span class="k">INDEX</span> <span class="n">cl_store_sales</span> <span class="k">ON</span> <span class="n">store_sales</span><span class="p">;</span>
</pre></div>
<p>The clustered columnstore index (CCI) cannot be created on a table already having a clustered index on PK. So we drop and recreate the <code>store_sales</code> table without PK followed by creating a clustered columnstore index.</p>
<p>With the CCI we no longer need to coalesce the partitions as concurrent bulk insert will work just fine. CCI supports parallel bulk inserts to the same table so we can fully utilize our partitioned dataset to load the data concurrently.</p>
<p>The batch size 1048756 also plays an important role over here. Our aim is to bypass writing to delta rowgroup and directly write to compressed columnstore. The <a href="https://docs.microsoft.com/en-us/sql/relational-databases/indexes/columnstore-indexes-overview?view=sql-server-ver15#delta-rowgroup">documentation</a> has excellent explaination of this so I recommend reading it.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">url</span> <span class="o">=</span> <span class="n">create_url</span><span class="p">(</span><span class="n">server_name</span><span class="p">,</span> <span class="s2">&quot;cci&quot;</span><span class="p">)</span>
<span class="n">truncate_tables</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">username</span><span class="p">,</span> <span class="n">password</span><span class="p">,</span> <span class="n">tables</span><span class="p">)</span>
<span class="n">elapsed</span> <span class="o">=</span> <span class="n">import_table</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">table_name</span><span class="p">,</span> <span class="n">stores</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<style scoped="">
  .ansiout {
    display: block;
    unicode-bidi: embed;
    white-space: pre-wrap;
    word-wrap: break-word;
    word-break: break-all;
    font-family: "Source Code Pro", "Menlo", monospace;;
    font-size: 13px;
    color: #555;
    margin-left: 4px;
    line-height: 19px;
  }
</style>
<div class="ansiout">Tuncated table store_sales in: 0.08
Number of partitions: 30
Imported into table store_sales in : 246.92 
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/blog/images/copied_from_nb/./assets/images/posts/spark-connector-2/partn.png" alt="partition" /></p>
<p>Since we did not coalesce the partitions multiple jobs were execution at same time as shown in image above. This resulted in much faster insertion of records in the database. Moreoever CCI are meant for large scale injestion scenarios and works great with bulk inserts and reads.</p>
<p><img src="/blog/images/copied_from_nb/./assets/images/posts/spark-connector-2/cci.png" alt="cci metrics" /></p>
<p>The CPU almost peaked during our run and that is because of multiple connections concurrently inserting large amount of data into the database. However the entire run completed in just over 4 minutes which is a very good performance.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Non-Clustered-Columnstore-Index">Non-Clustered Columnstore Index<a class="anchor-link" href="#Non-Clustered-Columnstore-Index"> </a></h3><div class="highlight"><pre><span></span><span class="k">CREATE</span> <span class="n">NONCLUSTERED</span> <span class="n">COLUMNSTORE</span> <span class="k">INDEX</span> <span class="n">ncl_store_sales</span> <span class="k">ON</span> <span class="n">store_sales</span> <span class="p">(</span>
    <span class="n">ss_sold_date_sk</span>       
   <span class="p">,</span><span class="n">ss_sold_time_sk</span>       
   <span class="p">,</span><span class="n">ss_item_sk</span>            
   <span class="p">,</span><span class="n">ss_customer_sk</span>        
   <span class="p">,</span><span class="n">ss_cdemo_sk</span>           
   <span class="p">,</span><span class="n">ss_hdemo_sk</span>           
   <span class="p">,</span><span class="n">ss_addr_sk</span>         
   <span class="p">,</span><span class="n">ss_promo_sk</span>           
   <span class="p">,</span><span class="n">ss_ticket_number</span>      
   <span class="p">,</span><span class="n">ss_quantity</span>           
   <span class="p">,</span><span class="n">ss_wholesale_cost</span>     
   <span class="p">,</span><span class="n">ss_list_price</span>         
   <span class="p">,</span><span class="n">ss_sales_price</span>        
   <span class="p">,</span><span class="n">ss_ext_discount_amt</span>   
   <span class="p">,</span><span class="n">ss_ext_sales_price</span>    
   <span class="p">,</span><span class="n">ss_ext_wholesale_cost</span> 
   <span class="p">,</span><span class="n">ss_ext_list_price</span>     
   <span class="p">,</span><span class="n">ss_ext_tax</span>            
   <span class="p">,</span><span class="n">ss_coupon_amt</span>         
   <span class="p">,</span><span class="n">ss_net_paid</span>           
   <span class="p">,</span><span class="n">ss_net_paid_inc_tax</span>   
   <span class="p">,</span><span class="n">ss_net_profit</span>
<span class="p">);</span>
</pre></div>
<p>Something to keep in mind before deciding which column you want to include is that NCCI takes additional space to maintain, however the data is highly compressed. Here we create a non-clustered columnstore index (NCCI) with all the columns involved to benchmark worst case scenario.</p>
<p>Even though we have nonclustered columnstore index the physical storage of the data is still rowstore as the table has a Clustered Index on the Primary Key. That means concurrent bulk insert on same page will result to deadlock. So once again we have to coalesce the partitions.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">url</span> <span class="o">=</span> <span class="n">create_url</span><span class="p">(</span><span class="n">server_name</span><span class="p">,</span> <span class="s2">&quot;ncci&quot;</span><span class="p">)</span>
<span class="n">truncate_tables</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">username</span><span class="p">,</span> <span class="n">password</span><span class="p">,</span> <span class="n">tables</span><span class="p">)</span>
<span class="n">elapsed</span> <span class="o">=</span> <span class="n">import_table</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">table_name</span><span class="p">,</span> <span class="n">stores</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<style scoped="">
  .ansiout {
    display: block;
    unicode-bidi: embed;
    white-space: pre-wrap;
    word-wrap: break-word;
    word-break: break-all;
    font-family: "Source Code Pro", "Menlo", monospace;;
    font-size: 13px;
    color: #555;
    margin-left: 4px;
    line-height: 19px;
  }
</style>
<div class="ansiout">Tuncated table store_sales in: 0.09
Number of partitions: 30
Imported into table store_sales in : 4324.18 
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/blog/images/copied_from_nb/./assets/images/posts/spark-connector-2/ncci.png" alt="ncci metrics" /></p>
<p>The database metrics for NCCI is very similar to that of rowstore. CPU or IO is not being throttled and are in comfortable range.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Comparing-timings-between-different-indexes">Comparing timings between different indexes<a class="anchor-link" href="#Comparing-timings-between-different-indexes"> </a></h3><p>As we can see in the chart below there is drastic difference in time between clustered columnstore index and rowstore index. Because CCI is optimized for such workload and we are able to fully utilize the spark cluster to concurrently import the data, CCI performs bulk insert order of magnitude faster than rowstore index. Nonclustered Column Store Index does not have the same benefit as CCI. Even though both CCI and NCCI are based on same underlying <em>columnar</em> format, NCCI is a secondary index and the physical storage of data depends upon clustered rowstore index on Primary Key. So the performance of bulk import in NCCI is similar to that of rowstore. Inevitably either rowstore or NCCI would have performed better in this run however on average, when I ran this notebook multiple times, the rowstore and NCCI performed nearly identical. The real benefit of using NCCI is ability to perform real time analytics. Refer to <a href="https://docs.microsoft.com/en-us/sql/relational-databases/indexes/columnstore-indexes-design-guidance?view=sql-server-ver15#choose-the-best-columnstore-index-for-your-needs">this guide</a> to choose best columnstore index for your needs.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

<div id="altair-viz-b2757a2b6dde4cb5af70d86ed2f65059"></div>
<script type="text/javascript">
  (function(spec, embedOpt){
    let outputDiv = document.currentScript.previousElementSibling;
    if (outputDiv.id !== "altair-viz-b2757a2b6dde4cb5af70d86ed2f65059") {
      outputDiv = document.getElementById("altair-viz-b2757a2b6dde4cb5af70d86ed2f65059");
    }
    const paths = {
      "vega": "https://cdn.jsdelivr.net/npm//vega@5?noext",
      "vega-lib": "https://cdn.jsdelivr.net/npm//vega-lib?noext",
      "vega-lite": "https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext",
      "vega-embed": "https://cdn.jsdelivr.net/npm//vega-embed@6?noext",
    };

    function loadScript(lib) {
      return new Promise(function(resolve, reject) {
        var s = document.createElement('script');
        s.src = paths[lib];
        s.async = true;
        s.onload = () => resolve(paths[lib]);
        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);
        document.getElementsByTagName("head")[0].appendChild(s);
      });
    }

    function showError(err) {
      outputDiv.innerHTML = `<div class="error" style="color:red;">${err}</div>`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === "function" && define.amd) {
      requirejs.config({paths});
      require(["vega-embed"], displayChart, err => showError(`Error loading script: ${err.message}`));
    } else if (typeof vegaEmbed === "function") {
      displayChart(vegaEmbed);
    } else {
      loadScript("vega")
        .then(() => loadScript("vega-lite"))
        .then(() => loadScript("vega-embed"))
        .catch(showError)
        .then(() => displayChart(vegaEmbed));
    }
  })({"config": {"view": {"continuousWidth": 400, "continuousHeight": 300}}, "data": {"name": "data-d3ea0fe5d88c6fc0ac5e13a829b49417"}, "mark": "bar", "encoding": {"color": {"type": "nominal", "field": "index_type"}, "tooltip": [{"type": "quantitative", "field": "time"}], "x": {"type": "nominal", "field": "index_type"}, "y": {"type": "quantitative", "field": "time"}}, "width": {"step": 40}, "$schema": "https://vega.github.io/schema/vega-lite/v4.8.1.json", "datasets": {"data-d3ea0fe5d88c6fc0ac5e13a829b49417": [{"index_type": "rowstore", "time": 3876.2913843349997}, {"index_type": "cci", "time": 246.92076767599792}, {"index_type": "ncci", "time": 4324.18118408}]}}, {"mode": "vega-lite"});
</script>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Benchmarking-using-old-Azure-SQL-Spark-Connector">Benchmarking using old Azure SQL Spark Connector<a class="anchor-link" href="#Benchmarking-using-old-Azure-SQL-Spark-Connector"> </a></h2><p>As mentioned before there is an <a href="https://github.com/microsoft/sql-spark-connector/issues/13">open issue</a> on poor performance of the new connector. I am following up with the developers of the connector to resolve it. Meanwhile lets run the bulk import on same three indexes to compare how well the new connector performs when compared to older one.</p>
<p>To get started we need to install the jar file from maven <code>com.microsoft.azure:azure-sqldb-spark:1.0.2</code>. The azure sqldb connector only works with Scala so we need to rewrite the above code in Scala. I will not get into details of the code but the following code is identical to what we have in python. At the end we will compare the run timings of old connector with new connector.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">sc</span>ala
<span class="kn">import</span> <span class="nn">com.microsoft.azure.sqldb.spark.query._</span>
<span class="kn">import</span> <span class="nn">com.microsoft.azure.sqldb.spark.config.Config</span>
<span class="kn">import</span> <span class="nn">com.microsoft.azure.sqldb.spark.connect._</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.functions._</span>

<span class="n">val</span> <span class="n">path</span> <span class="o">=</span> <span class="s2">&quot;/mnt/adls/adls7dataset7benchmark/tpcds1tb/parquet&quot;</span>

<span class="n">var</span> <span class="n">configMap</span> <span class="o">=</span> <span class="n">Map</span><span class="p">(</span>
  <span class="s2">&quot;url&quot;</span>            <span class="o">-&gt;</span> <span class="n">dbutils</span><span class="o">.</span><span class="n">secrets</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">scope</span> <span class="o">=</span> <span class="s2">&quot;kvbenchmark&quot;</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="s2">&quot;db-server-name&quot;</span><span class="p">),</span>
  <span class="s2">&quot;user&quot;</span>           <span class="o">-&gt;</span> <span class="n">dbutils</span><span class="o">.</span><span class="n">secrets</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">scope</span> <span class="o">=</span> <span class="s2">&quot;kvbenchmark&quot;</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="s2">&quot;db-username&quot;</span><span class="p">),</span>
  <span class="s2">&quot;password&quot;</span>       <span class="o">-&gt;</span> <span class="n">dbutils</span><span class="o">.</span><span class="n">secrets</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">scope</span> <span class="o">=</span> <span class="s2">&quot;kvbenchmark&quot;</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="s2">&quot;db-password&quot;</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">var</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span>
  <span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="s2">&quot;/store_sales&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="s2">&quot;ss_store_sk IS NOT null&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;ss_store_sk&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">count</span><span class="p">()</span>
  <span class="o">.</span><span class="n">orderBy</span><span class="p">(</span><span class="n">desc</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">))</span>
  <span class="o">.</span><span class="n">limit</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>

<span class="n">val</span> <span class="n">stores</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;ss_store_sk&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">_</span><span class="o">.</span><span class="n">getInt</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">truncate_table</span><span class="p">(</span><span class="n">db</span><span class="p">:</span><span class="n">String</span><span class="p">,</span> <span class="n">table_name</span><span class="p">:</span> <span class="n">String</span><span class="p">)</span> <span class="o">=</span> <span class="p">{</span>
  <span class="n">val</span> <span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;TRUNCATE TABLE &quot;</span> <span class="o">+</span> <span class="s2">&quot;dbo.&quot;</span> <span class="o">+</span> <span class="n">table_name</span>
  <span class="n">val</span> <span class="n">config</span> <span class="o">=</span> <span class="n">Config</span><span class="p">(</span><span class="n">configMap</span> <span class="o">++</span> <span class="n">Map</span><span class="p">(</span>
    <span class="s2">&quot;queryCustom&quot;</span>  <span class="o">-&gt;</span> <span class="n">query</span><span class="p">,</span>
    <span class="s2">&quot;databaseName&quot;</span> <span class="o">-&gt;</span> <span class="n">db</span>
  <span class="p">))</span>
  <span class="n">var</span> <span class="n">start_table</span> <span class="o">=</span> <span class="n">System</span><span class="o">.</span><span class="n">nanoTime</span><span class="p">()</span><span class="o">.</span><span class="n">toDouble</span>
  <span class="n">sqlContext</span><span class="o">.</span><span class="n">sqlDBQuery</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
  <span class="n">var</span> <span class="n">end_table</span> <span class="o">=</span> <span class="n">System</span><span class="o">.</span><span class="n">nanoTime</span><span class="p">()</span><span class="o">.</span><span class="n">toDouble</span>
  <span class="n">var</span> <span class="n">run_time_table</span> <span class="o">=</span> <span class="p">(</span><span class="n">end_table</span> <span class="o">-</span> <span class="n">start_table</span><span class="p">)</span> <span class="o">/</span> <span class="mi">1000000000</span>
  <span class="n">println</span><span class="p">(</span><span class="s2">&quot;Truncated table: &quot;</span> <span class="o">+</span> <span class="n">table_name</span> <span class="o">+</span> <span class="s2">&quot; took: &quot;</span> <span class="o">+</span> <span class="n">run_time_table</span><span class="p">)</span>
<span class="p">}</span>

<span class="k">def</span> <span class="nf">import_sales</span><span class="p">(</span><span class="n">db</span><span class="p">:</span><span class="n">String</span><span class="p">,</span> <span class="n">table_name</span><span class="p">:</span> <span class="n">String</span><span class="p">,</span> <span class="n">coalesce</span><span class="p">:</span> <span class="n">Boolean</span><span class="p">):</span> <span class="n">Double</span> <span class="o">=</span> <span class="p">{</span>
  <span class="n">val</span> <span class="n">config</span> <span class="o">=</span> <span class="n">Config</span><span class="p">(</span><span class="n">configMap</span> <span class="o">++</span> <span class="n">Map</span><span class="p">(</span>
    <span class="s2">&quot;databaseName&quot;</span>      <span class="o">-&gt;</span> <span class="n">db</span><span class="p">,</span>  
    <span class="s2">&quot;bulkCopyBatchSize&quot;</span> <span class="o">-&gt;</span> <span class="s2">&quot;1048576&quot;</span><span class="p">,</span>
    <span class="s2">&quot;bulkCopyTableLock&quot;</span> <span class="o">-&gt;</span> <span class="s2">&quot;false&quot;</span><span class="p">,</span>
    <span class="s2">&quot;bulkCopyTimeout&quot;</span>   <span class="o">-&gt;</span> <span class="s2">&quot;7200&quot;</span><span class="p">,</span>
    <span class="s2">&quot;dbTable&quot;</span>           <span class="o">-&gt;</span> <span class="n">table_name</span>
  <span class="p">))</span>

  <span class="n">var</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span> <span class="o">+</span> <span class="n">table_name</span><span class="p">)</span>
  <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="err">$</span><span class="s2">&quot;ss_store_sk&quot;</span><span class="o">.</span><span class="n">isInCollection</span><span class="p">(</span><span class="n">stores</span><span class="p">))</span>

  <span class="n">var</span> <span class="n">tempdf</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">sqlDB</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
  <span class="n">var</span> <span class="n">reorderedColumnNames</span> <span class="o">=</span> <span class="n">tempdf</span><span class="o">.</span><span class="n">schema</span><span class="o">.</span><span class="n">fields</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">_</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
  <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">reorderedColumnNames</span><span class="o">.</span><span class="n">head</span><span class="p">,</span> <span class="n">reorderedColumnNames</span><span class="o">.</span><span class="n">tail</span><span class="p">:</span> <span class="n">_</span><span class="o">*</span><span class="p">)</span>

  <span class="n">println</span><span class="p">(</span><span class="s2">&quot;Number of partitions: &quot;</span> <span class="o">+</span> <span class="n">df</span><span class="o">.</span><span class="n">rdd</span><span class="o">.</span><span class="n">getNumPartitions</span><span class="p">)</span>
  
  <span class="k">if</span> <span class="p">(</span><span class="n">coalesce</span> <span class="o">==</span> <span class="n">true</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">coalesce</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
  <span class="p">}</span>
  
  <span class="n">var</span> <span class="n">start_table</span> <span class="o">=</span> <span class="n">System</span><span class="o">.</span><span class="n">nanoTime</span><span class="p">()</span><span class="o">.</span><span class="n">toDouble</span>
  <span class="n">df</span><span class="o">.</span><span class="n">bulkCopyToSqlDB</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
  <span class="n">var</span> <span class="n">end_table</span> <span class="o">=</span> <span class="n">System</span><span class="o">.</span><span class="n">nanoTime</span><span class="p">()</span><span class="o">.</span><span class="n">toDouble</span>
  <span class="n">var</span> <span class="n">run_time_table</span> <span class="o">=</span> <span class="p">(</span><span class="n">end_table</span> <span class="o">-</span> <span class="n">start_table</span><span class="p">)</span> <span class="o">/</span> <span class="mi">1000000000</span>
  <span class="n">println</span><span class="p">(</span><span class="s2">&quot;Imported into&quot;</span> <span class="o">+</span> <span class="n">table_name</span> <span class="o">+</span> <span class="s2">&quot; took: &quot;</span> <span class="o">+</span> <span class="n">run_time_table</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">run_time_table</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<style scoped="">
  .ansiout {
    display: block;
    unicode-bidi: embed;
    white-space: pre-wrap;
    word-wrap: break-word;
    word-break: break-all;
    font-family: "Source Code Pro", "Menlo", monospace;;
    font-size: 13px;
    color: #555;
    margin-left: 4px;
    line-height: 19px;
  }
</style>
<div class="ansiout">import com.microsoft.azure.sqldb.spark.query._
import com.microsoft.azure.sqldb.spark.config.Config
import com.microsoft.azure.sqldb.spark.connect._
import org.apache.spark.sql.functions._
path: String = /mnt/adls/adls7dataset7benchmark/tpcds1tb/parquet
configMap: scala.collection.immutable.Map[String,String] = Map(url -&gt; [REDACTED], user -&gt; [REDACTED], password -&gt; [REDACTED])
df: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [ss_store_sk: int, count: bigint]
stores: Array[Int] = Array(529, 650, 14, 406, 178, 766, 934, 157, 22, 772)
truncate_table: (db: String, table_name: String)Unit
import_sales: (db: String, table_name: String, coalesce: Boolean)Double
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">sc</span>ala
<span class="n">println</span><span class="p">(</span><span class="s2">&quot;--- Starting import in rowstore index ---&quot;</span><span class="p">)</span>
<span class="n">truncate_table</span><span class="p">(</span><span class="s2">&quot;idx&quot;</span><span class="p">,</span> <span class="s2">&quot;store_sales&quot;</span><span class="p">)</span>
<span class="n">var</span> <span class="n">elapsed</span> <span class="o">=</span> <span class="n">import_sales</span><span class="p">(</span><span class="s2">&quot;idx&quot;</span><span class="p">,</span> <span class="s2">&quot;store_sales&quot;</span><span class="p">,</span> <span class="n">true</span><span class="p">)</span>
<span class="n">var</span> <span class="n">o_df</span> <span class="o">=</span> <span class="n">Map</span><span class="p">(</span><span class="s2">&quot;rowstore&quot;</span><span class="o">-&gt;</span> <span class="n">elapsed</span><span class="p">)</span><span class="o">.</span><span class="n">toSeq</span><span class="o">.</span><span class="n">toDF</span><span class="p">(</span><span class="s2">&quot;index_type&quot;</span><span class="p">,</span> <span class="s2">&quot;time&quot;</span><span class="p">)</span>

<span class="n">println</span><span class="p">(</span><span class="s2">&quot;--- Starting import in CCI ---&quot;</span><span class="p">)</span>
<span class="n">truncate_table</span><span class="p">(</span><span class="s2">&quot;cci&quot;</span><span class="p">,</span> <span class="s2">&quot;store_sales&quot;</span><span class="p">)</span>
<span class="n">elapsed</span> <span class="o">=</span> <span class="n">import_sales</span><span class="p">(</span><span class="s2">&quot;cci&quot;</span><span class="p">,</span> <span class="s2">&quot;store_sales&quot;</span><span class="p">,</span> <span class="n">false</span><span class="p">)</span>
<span class="n">o_df</span> <span class="o">=</span> <span class="n">o_df</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">Map</span><span class="p">(</span><span class="s2">&quot;cci&quot;</span><span class="o">-&gt;</span><span class="n">elapsed</span><span class="p">)</span><span class="o">.</span><span class="n">toSeq</span><span class="o">.</span><span class="n">toDF</span><span class="p">())</span>

<span class="n">println</span><span class="p">(</span><span class="s2">&quot;--- Starting import in NCCI ---&quot;</span><span class="p">)</span>
<span class="n">truncate_table</span><span class="p">(</span><span class="s2">&quot;ncci&quot;</span><span class="p">,</span> <span class="s2">&quot;store_sales&quot;</span><span class="p">)</span>
<span class="n">elapsed</span> <span class="o">=</span> <span class="n">import_sales</span><span class="p">(</span><span class="s2">&quot;ncci&quot;</span><span class="p">,</span> <span class="s2">&quot;store_sales&quot;</span><span class="p">,</span> <span class="n">true</span><span class="p">)</span>
<span class="n">o_df</span> <span class="o">=</span> <span class="n">o_df</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">Map</span><span class="p">(</span><span class="s2">&quot;ncci&quot;</span><span class="o">-&gt;</span><span class="n">elapsed</span><span class="p">)</span><span class="o">.</span><span class="n">toSeq</span><span class="o">.</span><span class="n">toDF</span><span class="p">())</span>

<span class="n">o_df</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;o_df&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<style scoped="">
  .ansiout {
    display: block;
    unicode-bidi: embed;
    white-space: pre-wrap;
    word-wrap: break-word;
    word-break: break-all;
    font-family: "Source Code Pro", "Menlo", monospace;;
    font-size: 13px;
    color: #555;
    margin-left: 4px;
    line-height: 19px;
  }
</style>
<div class="ansiout">--- Starting import in rowstore index ---
Truncated table: store_sales took: 0.089774135
Number of partitions: 30
Imported intostore_sales took: 1798.744563592
--- Starting import in CCI ---
Truncated table: store_sales took: 0.107795881
Number of partitions: 30
Imported intostore_sales took: 225.057509767
--- Starting import in NCCI ---
Truncated table: store_sales took: 0.096099101
Number of partitions: 30
Imported intostore_sales took: 2419.880703759
elapsed: Double = 2419.880703759
o_df: org.apache.spark.sql.DataFrame = [index_type: string, time: double]
elapsed: Double = 2419.880703759
o_df: org.apache.spark.sql.DataFrame = [index_type: string, time: double]
elapsed: Double = 2419.880703759
o_df: org.apache.spark.sql.DataFrame = [index_type: string, time: double]
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

<div id="altair-viz-ad08791485f14f4fa95b02e62c9652fb"></div>
<script type="text/javascript">
  (function(spec, embedOpt){
    let outputDiv = document.currentScript.previousElementSibling;
    if (outputDiv.id !== "altair-viz-ad08791485f14f4fa95b02e62c9652fb") {
      outputDiv = document.getElementById("altair-viz-ad08791485f14f4fa95b02e62c9652fb");
    }
    const paths = {
      "vega": "https://cdn.jsdelivr.net/npm//vega@5?noext",
      "vega-lib": "https://cdn.jsdelivr.net/npm//vega-lib?noext",
      "vega-lite": "https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext",
      "vega-embed": "https://cdn.jsdelivr.net/npm//vega-embed@6?noext",
    };

    function loadScript(lib) {
      return new Promise(function(resolve, reject) {
        var s = document.createElement('script');
        s.src = paths[lib];
        s.async = true;
        s.onload = () => resolve(paths[lib]);
        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);
        document.getElementsByTagName("head")[0].appendChild(s);
      });
    }

    function showError(err) {
      outputDiv.innerHTML = `<div class="error" style="color:red;">${err}</div>`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === "function" && define.amd) {
      requirejs.config({paths});
      require(["vega-embed"], displayChart, err => showError(`Error loading script: ${err.message}`));
    } else if (typeof vegaEmbed === "function") {
      displayChart(vegaEmbed);
    } else {
      loadScript("vega")
        .then(() => loadScript("vega-lite"))
        .then(() => loadScript("vega-embed"))
        .catch(showError)
        .then(() => displayChart(vegaEmbed));
    }
  })({"config": {"view": {"continuousWidth": 400, "continuousHeight": 300}}, "data": {"name": "data-9667fbb2e569c23b609dc735037f4d15"}, "mark": "bar", "encoding": {"color": {"type": "nominal", "field": "connector"}, "column": {"type": "nominal", "field": "index_type"}, "tooltip": [{"type": "nominal", "field": "index_type"}, {"type": "nominal", "field": "connector"}, {"type": "quantitative", "field": "time"}], "x": {"type": "nominal", "field": "connector"}, "y": {"type": "quantitative", "field": "time"}}, "width": {"step": 40}, "$schema": "https://vega.github.io/schema/vega-lite/v4.8.1.json", "datasets": {"data-9667fbb2e569c23b609dc735037f4d15": [{"index_type": "rowstore", "time": 3876.2913843349997, "connector": "new"}, {"index_type": "cci", "time": 246.92076767599792, "connector": "new"}, {"index_type": "ncci", "time": 4324.18118408, "connector": "new"}, {"index_type": "rowstore", "time": 1798.744563592, "connector": "old"}, {"index_type": "cci", "time": 225.057509767, "connector": "old"}, {"index_type": "ncci", "time": 2419.880703759, "connector": "old"}]}}, {"mode": "vega-lite"});
</script>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can see that the old connector performance is much better than the new one when inserting into rowstore or NCCI but performs equally in case of CCI. I cannot emphasize enough that the old connector is deprecated and no more actively maintained. The new Microsoft SQL Spark connector is the future and just as with any new software it has bugs and issues. As it becomes mature it will be on par or exceed performance of the old connector. If you are already using old connector or have a dire need of best performance when inserting into rowstore index then you can continue using it before transitioning to new connector once the performance issue is fixed. There are also a lot of options that can be specified in connector to control the behaviour of bulk insert. Experiment with them and choose what fits best with your use case.</p>
<p>In the next post we will delve deeper into the issue of deadlock and discuss some solutions for it. Leave a comment if you have any questions or suggestions.</p>

</div>
</div>
</div>
</div>



  </div>
  <div class="PageNavigation">
  
  <div class="prevDiv">
    <a class="prev" href="/blog/2020/09/bulk-import-using-sql-spark-connector-p1/">&laquo; Building large scale data ingestion solutions for Azure SQL using Azure databricks - Part 1</a>
  </div>
  
  
</div>
<!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="ankitbko/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/2020/09/bulk-import-using-sql-spark-connector-p2/" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
        <ul class="contact-list">
          <li class="p-name">Ankit Sinha</li>
          
        </ul>
      </div>
      <div class="footer-col">
        <p>A technology blog focusing on random stuff</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/ankitbko" title="ankitbko"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/ankitbko" title="ankitbko"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
